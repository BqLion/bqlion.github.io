<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>kaggle/Pytorch基本操作 ~ 刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/archive.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              <br>
              
                <p class="mt-3">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>&nbsp;
                  星期二, 二月 25日 2020, 12:19 中午
                </p>
              

              <p>
                
                  
                  &nbsp;<i class="far fa-chart-bar"></i>
                  <span class="post-count">
                    1.9k 字
                  </span>&nbsp;
                

                
                  
                  &nbsp;<i class="far fa-clock"></i>
                  <span class="post-count">
                      8 分钟
                  </span>&nbsp;
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  &nbsp;<i class="far fa-eye" aria-hidden="true"></i>&nbsp;
                  <span id="busuanzi_container_page_pv">
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>&nbsp;
                
              </p>
            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="py-5 z-depth-3" id="board">
        <div class="post-content mx-auto" id="post">
          <div class="markdown-body">
            <h1 id="1-Variable变量"><a href="#1-Variable变量" class="headerlink" title="1.Variable变量"></a>1.Variable变量</h1><p>variable可以想象成是篮子，tensor是鸡蛋。鸡蛋从一个篮子pass到另一个篮子时，就会构建一个计算图纸。</p>
<p>目前的深度学习框架大部分都基于计算图</p>
<p>一张计算图谱就是一个有向无环图，图中的节点主要是Variable。</p>
<p>想要让tensor作为一个神经网络的参数，首要就是把tensor转换为Variable类型。</p>
<p>只有variable节点可以被神经网络反向传播优化到，其他的占位符和常亮节点不可以被优化到。</p>
<p>如下代码中，requires_grad 这个参数代表此节点是需要反向传播优化，通常都选True。</p>
<pre><code class="python">import torch
from torch.autograd import Variable

tensor = torch.FloatTensor([[1,2],[3,4]])
variable = Variable(tensor,requires_grad=True)</code></pre>
<h1 id="2-激励函数"><a href="#2-激励函数" class="headerlink" title="2.激励函数"></a>2.激励函数</h1><p><img src="http://bqlab-pic.test.upcdn.net/pic/20200225_1220_34_168.png" alt=""></p>
<p>如上，激励函数是一个非线性的函数，是神经网络中非线性化的手段。每一层神经网络的输出结果都进入激励函数，激励函数将它们映射到下一层的输入中。</p>
<pre><code>from torch.autograd import Variable
import matplotlib.pyplot as plt

#fake data
x = torch.linspace(-5,5,200) #linspace可以将-5到5之间均匀的取200个点
x = Variable(x)   #将x从点集转换为Variable
x_np = x.data.numpy()

y_relu = F.relu(x).data.numpy()
y_sigmoid = F.sigmoid(x).data.numpy()
y_tanh = F.tanh(x).data.numpy()
y_softplus = F.softplus(x).data.numpy()
#y_softmax = F.softmax(x)
# 分别求出各激励函数的y值list

plt.figure(1,figsize=(8,6))
plt.subplot(221)
plt.plot(x_np,y_relu,c=&#39;red&#39;,label=&#39;relu&#39;)
plt.ylim((-1,5))
plt.legend(loc=&#39;best&#39;)

plt.subplot(222)
plt.plot(x_np,y_sigmod,c=&#39;red&#39;,label=&#39;sigmod&#39;)
plt.ylim((-0.2,1.2))
plt.legend(loc=&#39;best&#39;)

plt.subplot(223)
plt.plot(x_np,y_tanh,c=&#39;red&#39;,label=&#39;tanh&#39;)
plt.ylim((-1.2,1.2))
plt.legend(loc=&#39;best&#39;)

plt.subplot(224)
plt.plot(x_np,y_softplus,c=&#39;red&#39;,label=&#39;softplus&#39;)
plt.ylim((-0.2,6))
plt.legend(loc=&#39;best&#39;)</code></pre><h1 id="3-回归"><a href="#3-回归" class="headerlink" title="3.回归"></a>3.回归</h1><pre><code class="python">import torch
from torch.autograd import Variable
import torch.nn.functional as F
import matplotlib.pyplot as plt

x = torch.unsqueeze(torch.linspace(-1,1,100),dim=1)
#为什么要用.unsqueeze？因为torch只能处理二维的数据，unsqueeze可以把一维的数据转换成二维的

y = x.pow(2) + 0.2*torch.rand(x.size())
#y是x的二次方加上一些随机噪声

x,y = Variable(x),Variable(y)
# x和y都只能转换成Variable才能被torch处理
# 新版torch已经不需要转换成Variable了，可以直接处理

plt.scatter(x.data.numpy(),y.data.numpy())
#plt.scatter就是打印散点图
plt.show()
</code></pre>
<pre><code class="python">#定义神经网络的层
class Net(torch.nn.Module):
    def __init__(self,n_features,n_hidden,n_output):
    #self后边三个参数分别是输入、隐藏层、输出个数
        super(Net,self).__init__()
        self.hidden = torch.nn.Linear(n_features,n_hidden)
        self.predict = torch.nn.Linear(n_hidden,n_output) 
        #预测是接受hidden层的输入，输出1个值就是y    </code></pre>
<pre><code class="python">#具体搭建步骤在这里，接上代码
    def forward(self,x):
    x = F.relu(self.hidden(x)) #接受隐藏层输出，然后套进激励函数
    x = self.predict(x)
    return x</code></pre>
<pre><code class="python">net = Net(1,10,1)  #如init函数的参数结构，输入值1个，隐藏层10层，输出值1个
print(net) 
# print是pytorch的一个功能，可以这接打印出来神经网络的结构，如下图所示</code></pre>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200226_1224_32_431.png" alt=""></p>
<pre><code>#优化
optimizer = torch.optim.SGD(net.parameters(),lr=0.5)
#lr是学习率，一般小于1，越大学越快。SGD是随机梯度下降法，是求解方法中最简单适用的一种
loss_func = torch.nn.MESLoss()
#误差函数是torch中计算误差的手段，这里用MSELoss均方差，来处理回归问题
#多提一句，分类问题的误差函数通常是交叉熵
for t in range(100):
    prediction = net(x)

    loss = loss_func(prediction,y)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

</code></pre><h1 id="4-分类"><a href="#4-分类" class="headerlink" title="4.分类"></a>4.分类</h1><pre><code class="python">import torch
import torch.autograd import Variable
import torch.nn.functional as F
import matplotlib.pyplot as plt

x,y = Variable(x),Variable(y)
n_data = torch.ones(100,2)   # 初始矩阵，全部是ones
x0 = torch.normal(2*n_data,1) # 初始化，图中上堆数据都在这里了
y0 = torch.zeros(100) # x0分类标签，初始值都是0
x1 = torch.normal(-2*n_data,1) # 初始化，图中下堆数据都在这里了
y1 = torch.zeros(100) # x1分类标签，初始值都是1
x = torch.cat((x0,x1),0).type(torch.FloatTensor)
y = torch.cat((y0,y1),).type(torch.LongTensor)

x,y = Variable(x),Variable(y)
#把数据都放在篮子里

class Net(torch.nn.Module):
    def __init__(self,n_feature,n_hidden,n_output)；
        super(Net,self).__init__()
        self.hidden = torch.nn.Linear(n_feature,n_hidden)
        self.predict = torch.nn.Linear(n_hidden,n_output)

    def forward(self,x):
        x = F.relu(self.hidden(x))
        x = self.predict(x)
        return x

net = Net(2,10,1)
print(net)

plt.ion()
plt.show()

optimizer = torch.optim.SGD(net.parameters(),lr=0.02)
loss_func = torch.nn.CrossEntropyLoss()

for t in range(100)：   #学习一百步
    prediction = net(x)

    loss = loss_func(prediction,y)
    # 用交叉熵函数计算出误差
    optimizer.zero_grad()
    # optimizer清楚上一批的梯度
    loss.backward()
    # 误差反响传递 
    optimizer.step()
    if t % 5 == 0:
        pass

</code></pre>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200226_1319_47_305.png" alt=""></p>
<h1 id="5-快速搭建神经网络"><a href="#5-快速搭建神经网络" class="headerlink" title="5.快速搭建神经网络"></a>5.快速搭建神经网络</h1><p>两个代码块对比，做的事情是一样的，明显第二个代码块简单的多。torch.nn.Linear(2,10)就是一个输入10，输出2的神经网络层,torch.nn.ReLU()就是一层激励函数</p>
<pre><code class="python"># method 1
class Net(torch.nn.Module):
    def __init__(self,n_features,n_hidden,n_output)；
    super(Net,self).__init__()
    self.hidden = torch.nn.Linear(n_feature,n_hidden)
    self.predict = torch.nn.Linear(n_hidden,n_output)

    def forward(self,x):
    x = F.relu(self.hidden(x))
    x = self.predict(x)
    return x

net1 = Net(2,10,2)</code></pre>
<pre><code class="python">net2 = torch.nn.Sequential(    #Sequential的意思是在这个括号里一层一层的累神经层就OK了
    torch.nn.Linear(2,10),
    torch.nn.ReLU(),
    torch.nn.Linear(10,2)
) </code></pre>
<h1 id="6-保存和提取"><a href="#6-保存和提取" class="headerlink" title="6.保存和提取"></a>6.保存和提取</h1><p>假设现在已经快速搭建并且训练好了神经网络。接下来想做的就是提取并保存现在的状态，以便以后继续训练。（不可能让电脑一直开着神经网络hold在那里）。</p>
<p>要实现的是</p>
<ul>
<li>保存功能def save（）</li>
<li>提取功能def restore_net()</li>
<li>提取功能def restore_params()</li>
</ul>
<p>import lib</p>
<pre><code class="python">import torch
from torch.autograd import Variable
import matplotlib.pyplot as plt</code></pre>
<p>生成随机数种子，构造数据</p>
<pre><code class="python">torch.manual_seed(1)

x = torch.unsqueeze(torch.linspace(-1,1,100),dim=1)
y = x.pow(2) + 0.2*torch.rand(x.size())
x,y = Variable(x,requires_grad = False),Variable(y,requires_grad=False)</code></pre>
<p>构造保存功能def save（）</p>
<pre><code class="python">def save():
net1 = torch.nn.Sequential(    
    torch.nn.Linear(2,10),
    torch.nn.ReLU(),
    torch.nn.Linear(10,2)
) 
optimizer = torch.optim.SGD(net1.parameters(),lr = 0.5) #SGD训练parameters
loss_func = torch.nn.MSELoss()

for  t in range(100)：
    prediction = net1(x)
    loss = loss_func(prediction,y)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
#以上是快速构建+训练神经网络
#以下是保存神经网络
torch.save(net1,&#39;net.pkl&#39;) #保存entire net
torch.save(net1.state_dict()，&#39;net_params.pkl&#39;) #仅保存parameters</code></pre>
<p>构造提取整个网络的功能def restore_net()</p>
<pre><code class="python">def restore_net():
    net2 = torch.load(&#39;net.pkl&#39;)
</code></pre>
<p>构造提取网络参数的功能def restore_params()</p>
<pre><code class="python">#只提取参数，那就需要先构造一个和net1一样的网络，然后把参数传进去
def restore_params():
net3 = torch.nn.Sequential(    
    torch.nn.Linear(2,10),
    torch.nn.ReLU(),
    torch.nn.Linear(10,2)
)
net3.load_state_dict(torch.load(&#39;net_params.pkl&#39;))     #和上上个代码块中的最后一行呼应
</code></pre>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h1 id="7-批训练"><a href="#7-批训练" class="headerlink" title="7.批训练"></a>7.批训练</h1><p>神经网络有时候需要训练的数据量太大，所以把数据量分割成小batch再训练，效果会好很多。 </p>
<pre><code class="python">import 
import torch.utils.data as Data
# data就是进行小批训练的模块

BATCH_SIZE = 5
#定义批的大小

x = torch.linspace(1,10,10)
y = torch.linsapce(10,1,10)
#x和y都是数据，从1到10，分均十份的数据

torch_dataset = Data.TensorDataset(data_tensor = x,target_tensor = y)
# data_tensor是要算的tensor，target_tensor是计算目标的时候对比用的tensor
loader =  Data.DataLoader(
    dataset = torch_dataset,
    batch_size = BATCH_SIZE,
    shuffle = True            #shuffle决定每次训练是否打乱顺序
)

for epoch in range(3):    # epoch：整体训练次数，这里是三次,。因为批大小是5，数据量是10，所以分2批训练
                        # 下面的enumerate(loader)决定训练三次是否要打乱次序
    for step,(batch_x,batch_y) in enumerate(loader): 
        # training
        print(&#39;Epoch: &#39;,epoch,&quot; Step: &quot;,step,&#39; batch x:&#39;,batch_x.numpy(),&#39; batch                       y:&#39;,batch_y.numpy())
</code></pre>
<p>output:</p>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200226_1552_30_717.png" alt=""></p>
<h1 id="8-Optimizer"><a href="#8-Optimizer" class="headerlink" title="8.Optimizer"></a>8.Optimizer</h1><p><img src="http://bqlab-pic.test.upcdn.net/pic/20200226_1559_37_263.png" alt=""></p>
<p>如图，SGD并不是效果最好的优化器。</p>

            <hr>
          </div>
          <br>
          <div>
            <p>
            
              <span>
                <i class="iconfont icon-inbox"></i>
                
                  <a class="hover-with-bg" href="/categories/kaggle">kaggle</a>
                  &nbsp;
                
              </span>&nbsp;&nbsp;
            
            
              <span>
                <i class="iconfont icon-tag"></i>
                
                  <a class="hover-with-bg" href="/tags/PyTorch">PyTorch</a>
                
              </span>
            
            </p>
            
              <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
            
          </div>
        </div>
      </div>
    </div>
    <div class="d-none d-lg-block col-lg-2 toc-container">
      
  <div id="toc">
    <p class="h4"><i class="far fa-list-alt"></i>&nbsp;目录</p>
    <div id="tocbot"></div>
  </div>

    </div>
  </div>
</div>

<!-- custom -->


<!-- Comments -->
<div class="col-lg-7 mx-auto nopadding-md">
  <div class="container comments mx-auto" id="comments">
    
  </div>
</div>

    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>




  
    <script src="/lib/tocbot/tocbot.min.js" ></script>
  
  <script src="/js/post.js" ></script>



  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "kaggle/Pytorch基本操作&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
