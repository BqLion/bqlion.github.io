<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>0.概念/0.文章/NLP_词袋模型应用 ~ 刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/archive.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              <br>
              
                <p class="mt-3">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>&nbsp;
                  星期五, 五月 8日 2020, 4:01 下午
                </p>
              

              <p>
                
                  
                  &nbsp;<i class="far fa-chart-bar"></i>
                  <span class="post-count">
                    1.6k 字
                  </span>&nbsp;
                

                
                  
                  &nbsp;<i class="far fa-clock"></i>
                  <span class="post-count">
                      8 分钟
                  </span>&nbsp;
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  &nbsp;<i class="far fa-eye" aria-hidden="true"></i>&nbsp;
                  <span id="busuanzi_container_page_pv">
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>&nbsp;
                
              </p>
            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="py-5 z-depth-3" id="board">
        <div class="post-content mx-auto" id="post">
          <div class="markdown-body">
            <h1 id="词袋模型的应用"><a href="#词袋模型的应用" class="headerlink" title="词袋模型的应用"></a>词袋模型的应用</h1><p>1.引入训练数据</p>
<pre><code class="python">import pandas as pd
train = pd.read_csv(&quot;labeledTrainData.tsv&quot;, header=0,delimiter=&quot;\t&quot;, quoting=3)</code></pre>
<p>2.确定引入数据是否正确 – 看一下shape和列标签</p>
<pre><code class="python">&gt;&gt;&gt; train.shape
(25000, 3)

&gt;&gt;&gt; train.columns.values
array([id, sentiment, review], dtype=object)</code></pre>
<p>3.glipise</p>
<pre><code class="python">print train[&quot;review&quot;][0]</code></pre>
<p>4.用beautiful soap清洗掉HTML标签</p>
<pre><code class="python"># Import BeautifulSoup into your workspace
from bs4 import BeautifulSoup             

# Initialize the BeautifulSoup object on a single movie review     
example1 = BeautifulSoup(train[&quot;review&quot;][0])  

# Print the raw review and then the output of get_text(), for 
# comparison
print train[&quot;review&quot;][0]
print example1.get_text()</code></pre>
<p>对比图如下，beautifulsoup确实清理了HTML标签</p>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200510_1531_48_363.png" alt=""></p>
<p>5.正则表达式清洗所有非英文单词</p>
<pre><code class="python">import re
# Use regular expressions to do a find-and-replace
letters_only = re.sub(&quot;[^a-zA-Z]&quot;,           # The pattern to search for
                      &quot; &quot;,                   # The pattern to replace it with
                      example1.get_text() )  # The text to search
print letters_only</code></pre>
<p>如下截图，正则表达式把所有的标点和数字都替换成了空格。</p>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200510_1536_13_005.png" alt=""></p>
<p>6.大小写统一，句子分割成单词</p>
<pre><code class="python">lower_case = letters_only.lower()        # Convert to lower case
words = lower_case.split()               # Split into words</code></pre>
<p>效果如下截图，已经区分了大小写，并分隔开为各个单词</p>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200510_1539_03_534.png" alt=""></p>
<p>7.用 nltk 去除停止词</p>
<pre><code class="python">import nltk
nltk.download()  # Download text data sets, including stop words

from nltk.corpus import stopwords # Import the stop word list
print stopwords.words(&quot;english&quot;) 

# Remove stop words from &quot;words&quot;
words = [w for w in words if not w in stopwords.words(&quot;english&quot;)]
print words


&gt;&gt;&gt;····
[u&#39;stuff&#39;, u&#39;going&#39;, u&#39;moment&#39;, u&#39;mj&#39;, u&#39;ve&#39;, u&#39;started&#39;, u&#39;listening&#39;, u&#39;music&#39;, u&#39;watching&#39;, u&#39;odd&#39;, u&#39;documentary&#39;, u&#39;watched&#39;, u&#39;wiz&#39;, u&#39;watched&#39;, u&#39;moonwalker&#39;, u&#39;maybe&#39;, u&#39;want&#39;, u&#39;get&#39;, u&#39;certain&#39;, u&#39;insight&#39;, u&#39;guy&#39;, u&#39;thought&#39;, u&#39;really&#39;, u&#39;cool&#39;, u&#39;eighties&#39;, u&#39;maybe&#39;, u&#39;make&#39;, u&#39;mind&#39;, u&#39;whether&#39;, u&#39;guilty&#39;, u&#39;innocent&#39;, u&#39;moonwalker&#39;, u&#39;part&#39;, u&#39;biography&#39;, u&#39;part&#39;, u&#39;feature&#39;, u&#39;film&#39;, u&#39;remember&#39;, u&#39;going&#39;, u&#39;see&#39;, u&#39;cinema&#39;, u&#39;originally&#39;, u&#39;released&#39;, u&#39;subtle&#39;, u&#39;messages&#39;, u&#39;mj&#39;, u&#39;feeling&#39;, u&#39;towards&#39;, u&#39;press&#39;, u&#39;also&#39;, u&#39;obvious&#39;, u&#39;message&#39;, u&#39;drugs&#39;, u&#39;bad&#39;, u&#39;m&#39;, u&#39;kay&#39;,.....]
</code></pre>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200511_1329_57_787.png" alt=""></p>
<p>8.至此，完成了对一条数据的清洗工作。把上述功能整理到下边的函数中，后边被其他数据复用</p>
<pre><code class="python">def review_to_words( raw_review ):
    # Function to convert a raw review to a string of words
    # The input is a single string (a raw movie review), and 
    # the output is a single string (a preprocessed movie review)
    #
    # 1. Remove HTML
    review_text = BeautifulSoup(raw_review).get_text() 
    #
    # 2. Remove non-letters        
    letters_only = re.sub(&quot;[^a-zA-Z]&quot;, &quot; &quot;, review_text) 
    #
    # 3. Convert to lower case, split into individual words
    words = letters_only.lower().split()                             
    #
    # 4. In Python, searching a set is much faster than searching
    #   a list, so convert the stop words to a set
    stops = set(stopwords.words(&quot;english&quot;))                  
    # 
    # 5. Remove stop words
    meaningful_words = [w for w in words if not w in stops]   
    #
    # 6. Join the words back into one string separated by space, 
    # and return the result.
    return( &quot; &quot;.join( meaningful_words ))   </code></pre>
<p>9.清洗剩下的数据</p>
<pre><code class="python"># test
clean_review = review_to_words( train[&quot;review&quot;][0] )
print clean_review

# 查看一共要清理多少数据
num_reviews = train[&quot;review&quot;].size

# 带进度条的数据清洗
print &quot;Cleaning and parsing the training set movie reviews...\n&quot;
clean_train_reviews = []
for i in xrange( 0, num_reviews ):
    # If the index is evenly divisible by 1000, print a message
    if( (i+1)%1000 == 0 ):
        print &quot;Review %d of %d\n&quot; % ( i+1, num_reviews )                                                                    
    clean_train_reviews.append( review_to_words( train[&quot;review&quot;][i] ))</code></pre>
<p>10.用词袋模型构建征</p>
<p>简单例子演：</p>
<ul>
<li>输入如下两个句子：</li>
</ul>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200510_1510_20_882.png" alt=""></p>
<ul>
<li>两个句子组成的词汇表如下：</li>
</ul>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200510_1511_31_799.png" alt=""></p>
<ul>
<li>两个句子用词汇表表示的向量如下：</li>
</ul>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200510_1512_15_583.png" alt=""></p>
<p>如下是复杂例子，步骤严格相同。把输入的25000个句子打散，组成词汇表（按照词频降序排列），然后每一句都按照词汇表的前五千个词汇向量表示（max_features = 5000）</p>
<pre><code class="python">print &quot;Creating the bag of words...\n&quot;
from sklearn.feature_extraction.text import CountVectorizer

# Initialize the &quot;CountVectorizer&quot; object, which is scikit-learn&#39;s
# bag of words tool.  
vectorizer = CountVectorizer(analyzer = &quot;word&quot;,   \
                             tokenizer = None,    \
                             preprocessor = None, \
                             stop_words = None,   \
                             max_features = 5000) 

# fit_transform() does two functions: First, it fits the model
# and learns the vocabulary; second, it transforms our training data
# into feature vectors. The input to fit_transform should be a list of 
# strings.
train_data_features = vectorizer.fit_transform(clean_train_reviews)

# Numpy arrays are easy to work with, so convert the result to an 
# array
train_data_features = train_data_features.toarray()</code></pre>
<p>查看特征数组第一行的结果：</p>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200511_1419_47_515.png" alt=""></p>
<p>11.观察词典 - feature表的形状，观察词汇表，观察各个词汇出现的频次</p>
<pre><code class="python">&gt;&gt;&gt; print (train_data_features.shape)
(25000, 5000)

# Take a look at the words in the vocabulary
vocab = vectorizer.get_feature_names()
print (vocab)

import numpy as np

# Sum up the counts of each vocabulary word
dist = np.sum(train_data_features, axis=0)

# For each, print the vocabulary word and the number of times it 
# appears in the training set
for tag, count in zip(vocab, dist):
    print (count, tag)</code></pre>
<p>词汇表</p>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200511_1423_46_822.png" alt=""></p>
<p> 词汇表中各词在训练集中使用频率</p>
<p><img src="http://bqlab-pic.test.upcdn.net/pic/20200511_1424_03_671.png" alt=""></p>
<h3 id="至此，已经把训练集中的所有单词都打散和清洗完毕，构建了词汇表，并将所有词汇都根据词汇表中最常用五千词的特征表示为五千维的向量。"><a href="#至此，已经把训练集中的所有单词都打散和清洗完毕，构建了词汇表，并将所有词汇都根据词汇表中最常用五千词的特征表示为五千维的向量。" class="headerlink" title="至此，已经把训练集中的所有单词都打散和清洗完毕，构建了词汇表，并将所有词汇都根据词汇表中最常用五千词的特征表示为五千维的向量。"></a>至此，已经把训练集中的所有单词都打散和清洗完毕，构建了词汇表，并将所有词汇都根据词汇表中最常用五千词的特征表示为五千维的向量。</h3><p>12.使用随机森林有监督学习向量化的train set，得到训练好的模型“forest”</p>
<pre><code class="python">print (&quot;Training the random forest...&quot;)
from sklearn.ensemble import RandomForestClassifier

# Initialize a Random Forest classifier with 100 trees
forest = RandomForestClassifier(n_estimators = 100) 
# 设置随机森林的区分器是100个

# Fit the forest to the training set, using the bag of words as 
# features and the sentiment labels as the response variable
#
# This may take a few minutes to run
forest = forest.fit( train_data_features, train[&quot;sentiment&quot;] )
#                     我是向量化的评论         我是情绪的正确结果</code></pre>
<p>13.提交结果</p>
<p>和上边的步骤一样，把test集用pd.read读入，清洗数据，构建词汇表，转换成array，然后套进forest，得到输出。</p>
<pre><code class="python"># Read the test data
test = pd.read_csv(&quot;testData.tsv&quot;, header=0, delimiter=&quot;\t&quot;, \
                   quoting=3 )

# Verify that there are 25,000 rows and 2 columns
print (test.shape)

# Create an empty list and append the clean reviews one by one
num_reviews = len(test[&quot;review&quot;])
clean_test_reviews = [] 

print (&quot;Cleaning and parsing the test set movie reviews...\n&quot;)
for i in range(0,num_reviews):
    if( (i+1) % 1000 == 0 ):
        print (&quot;Review %d of %d\n&quot; % (i+1, num_reviews))
    clean_review = review_to_words( test[&quot;review&quot;][i] )
    clean_test_reviews.append( clean_review )

# Get a bag of words for the test set, and convert to a numpy array
test_data_features = vectorizer.transform(clean_test_reviews)
test_data_features = test_data_features.toarray()

# Use the random forest to make sentiment label predictions
result = forest.predict(test_data_features)

# Copy the results to a pandas dataframe with an &quot;id&quot; column and
# a &quot;sentiment&quot; column
output = pd.DataFrame( data={&quot;id&quot;:test[&quot;id&quot;], &quot;sentiment&quot;:result} )

# Use pandas to write the comma-separated output file
output.to_csv( &quot;Bag_of_Words_model.csv&quot;, index=False, quoting=3 )</code></pre>
<pre><code>for i in range( 0, num_reviews ):
    clean_train_reviews.append( review_to_words( train[&quot;review&quot;][i] ) )</code></pre>
            <hr>
          </div>
          <br>
          <div>
            <p>
            
              <span>
                <i class="iconfont icon-inbox"></i>
                
                  <a class="hover-with-bg" href="/categories/%E6%96%87%E7%AB%A0">文章</a>
                  &nbsp;
                
              </span>&nbsp;&nbsp;
            
            
              <span>
                <i class="iconfont icon-tag"></i>
                
                  <a class="hover-with-bg" href="/tags/%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B">词袋模型</a>
                
              </span>
            
            </p>
            
              <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
            
          </div>
        </div>
      </div>
    </div>
    <div class="d-none d-lg-block col-lg-2 toc-container">
      
  <div id="toc">
    <p class="h4"><i class="far fa-list-alt"></i>&nbsp;目录</p>
    <div id="tocbot"></div>
  </div>

    </div>
  </div>
</div>

<!-- custom -->


<!-- Comments -->
<div class="col-lg-7 mx-auto nopadding-md">
  <div class="container comments mx-auto" id="comments">
    
  </div>
</div>

    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>




  
    <script src="/lib/tocbot/tocbot.min.js" ></script>
  
  <script src="/js/post.js" ></script>



  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "0.概念/0.文章/NLP_词袋模型应用&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
