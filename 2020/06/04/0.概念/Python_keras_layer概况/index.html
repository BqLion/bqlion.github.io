<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>0.概念/Python_keras_layer概况 ~ 刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/archive.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              <br>
              
                <p class="mt-3">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>&nbsp;
                  星期四, 六月 4日 2020, 10:48 上午
                </p>
              

              <p>
                
                  
                  &nbsp;<i class="far fa-chart-bar"></i>
                  <span class="post-count">
                    3.1k 字
                  </span>&nbsp;
                

                
                  
                  &nbsp;<i class="far fa-clock"></i>
                  <span class="post-count">
                      12 分钟
                  </span>&nbsp;
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  &nbsp;<i class="far fa-eye" aria-hidden="true"></i>&nbsp;
                  <span id="busuanzi_container_page_pv">
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>&nbsp;
                
              </p>
            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="py-5 z-depth-3" id="board">
        <div class="post-content mx-auto" id="post">
          <div class="markdown-body">
            <h1 id="Keras-Layer"><a href="#Keras-Layer" class="headerlink" title="Keras_Layer"></a>Keras_Layer</h1><p>keras的层包括：</p>
<p>常用层，卷积层，池化层，局部连接层，递归层，嵌入层，高级激活层，规范层，噪声层，包装层，and，也可以编写自己的层。</p>
<p>对于层的通用操作</p>
<pre><code class="python">layer.get_weights()  #返回该层的权重
layer.set_weigths(weights) #将权重加到该层
config = layer.get_config() #保存该层的配置
layer =  layer_from_config(config) # 加载一个配置到该层

#如果该层不是共享层而是一个计算节点，那么可以通过如下方法获得输入、输出张量。输入和输出张量的形状
layer.input
layer.output
layer.input_shape
layer.output_shape

#如果该层有多个计算节点。可以使用下面的方法
layer.get_input_at(node_index)
layer.get_output_at(node_index)
layer.get_input_shape_at(node_index)
layer.get_output_shape_at(node_index)</code></pre>
<h2 id="1-常用网络层"><a href="#1-常用网络层" class="headerlink" title="1.常用网络层"></a>1.常用网络层</h2><h4 id="1-1-Dense层（全连接层）"><a href="#1-1-Dense层（全连接层）" class="headerlink" title="1.1 Dense层（全连接层）"></a>1.1 Dense层（全连接层）</h4><p><code>keras.layers.core.Dense(units,activation=None,use_bias=True,kernel_initializer=&#39;glorot_uniform&#39;,bias_initializer=&#39;zeros&#39;,kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None)</code></p>
<p>参数：</p>
<ul>
<li>units：大于0的整数，代表该层的输出维度。</li>
<li>use_bias：布尔值，是否使用偏置项</li>
<li>kernel_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。</li>
<li>bias_initializer：偏置向量初始化方法，为预定义初始化方法名的字符串，或用于初始化偏置向量的初始化器。</li>
<li>regularizer：正则项，kernel为权重的、bias为偏执的，activity为输出的</li>
<li>constraints：约束项，kernel为权重的，bias为偏执的。</li>
<li>activation：激活函数，为预定义的激活函数名（参考激活函数），或逐元素（element-wise）的Theano函数。如果不指定该参数，将不会使用任何激活函数（即使用线性激活函数：a(x)=x）</li>
<li>input_dim：该层输入的维度</li>
</ul>
<p>本层实现的运算为</p>
<p><strong>o</strong>u<strong>t</strong>p<strong>u</strong>t<em>=</em>a<strong>c</strong>t<strong>i</strong>v<strong>a</strong>t<strong>i</strong>o<strong>n<em>(</em>d</strong>o<strong>t<em>(</em>i</strong>n<strong>p</strong>u<strong>t<em>,</em>k</strong>e<strong>r</strong>n<strong>e</strong>l<em>)+<em>b*</em>i<strong>a</strong>s</em>)output=activation(dot(input,kernel)+bias**</p>
<h4 id="1-2-Activation层"><a href="#1-2-Activation层" class="headerlink" title="1.2 Activation层"></a>1.2 Activation层</h4><p>激活层，对一个层的输出施加激活函数</p>
<p>参数：</p>
<ul>
<li>activation：将要使用的激活函数，是一个预定义的函数名。例如Relu等。</li>
</ul>
<p>输入输出shape：任意</p>
<h3 id="1-3-Dropout层"><a href="#1-3-Dropout层" class="headerlink" title="1.3 Dropout层"></a>1.3 Dropout层</h3><p><code>keras.layers.core.Dropout(rate, noise_shape=None, seed=None)</code></p>
<p>为输入数据增加dropout，dropout在训练过程中随机按照一定的概率（rate）断开输入神经元，dropout层用于防止过拟合。</p>
<p>参数：</p>
<ul>
<li>rate：0~1的浮点数，控制需要断开的神经元的比例</li>
<li>noise_shape：整数张量，为将要应用在输入上的二值Dropout mask的shape，例如你的输入为(batch_size, timesteps, features)，并且你希望在各个时间步上的Dropout mask都相同，则可传入noise_shape=(batch_size, 1, features)。</li>
<li>seed：整数，使用的随机数种子</li>
</ul>
<h3 id="1-4-Flatten层"><a href="#1-4-Flatten层" class="headerlink" title="1.4 Flatten层"></a>1.4 Flatten层</h3><p><code>keras.layers.core.Flatten()</code></p>
<p>flatten层用来将输入“压平”，即把多维的输入一维化，通常用在卷积层全连接层的过度。Flatten不影响bathc的大小。</p>
<p>demo：</p>
<pre><code class="python">model = Sequential()
model.add(Convolution2D(64, 3, 3,
            border_mode=&#39;same&#39;,
            input_shape=(3, 32, 32)))
# now: model.output_shape == (None, 64, 32, 32)

model.add(Flatten())
# now: model.output_shape == (None, 65536)</code></pre>
<h4 id="1-5-reshape层"><a href="#1-5-reshape层" class="headerlink" title="1.5 reshape层"></a>1.5 reshape层</h4><p><code>keras.layers.core.Reshape(target_shape)</code></p>
<p>reshape层用来将输入转换为特定的shape。</p>
<p>参数</p>
<ul>
<li>target_shape：目标shape，为整数的tuple，不包含样本数目的维度（batch大小）</li>
</ul>
<p>输入输出shape：任意</p>
<p>demo：</p>
<pre><code class="python"># as first layer in a Sequential model
model = Sequential()
model.add(Reshape((3, 4), input_shape=(12,)))
# now: model.output_shape == (None, 3, 4)
# note: `None` is the batch dimension

# as intermediate layer in a Sequential model
model.add(Reshape((6, 2)))
# now: model.output_shape == (None, 6, 2)

# also supports shape inference using `-1` as dimension
model.add(Reshape((-1, 2, 2)))
# now: model.output_shape == (None, 3, 2, 2)</code></pre>
<h4 id="1-6-Permute层"><a href="#1-6-Permute层" class="headerlink" title="1.6 Permute层"></a>1.6 Permute层</h4><p><code>keras.layers.core.Permute(dims)</code></p>
<p>permute层将输入维度按照给定模式进行重排（变形），例如，需要将RNN和CNN相连接的时候，会用到该层。所谓的重排也就是交换两行。</p>
<p>参数：</p>
<ul>
<li>dims：整数tuple，指定重排的模式，不包含样本数的维度。重拍模式的下标从1开始。例如（2，1）代表将输入的第二个维度重排到输出的第一个维度，而将输入的第一个维度重排到第二个维度</li>
</ul>
<p>demo：</p>
<pre><code class="python">model = Sequential()
model.add(Permute((2, 1), input_shape=(10, 64)))
# now: model.output_shape == (None, 64, 10)
# note: `None` is the batch dimension

# 本层的目的是交换维度，经过上边代码permute(2,1)，input的1，2维进行了对换。
# 形状从（10，64） 变成了（64,10）</code></pre>
<h4 id="1-7-repeatVector层"><a href="#1-7-repeatVector层" class="headerlink" title="1.7 repeatVector层"></a>1.7 repeatVector层</h4><p><code>keras.layers.core.RepeatVector(n)</code></p>
<p>参数</p>
<ul>
<li>n：整数，重复的次数</li>
</ul>
<p>输入shape：形如（nb_samples, features）的2D张量</p>
<p>输出shape：形如（nb_samples, n, features）的3D张量</p>
<p>demo:</p>
<pre><code class="python">model = Sequential()
model.add(Dense(32, input_dim=32))
# now: model.output_shape == (None, 32)
# note: `None` is the batch dimension

model.add(RepeatVector(3))
# now: model.output_shape == (None, 3, 32)</code></pre>
<h4 id="1-8-Lamada层"><a href="#1-8-Lamada层" class="headerlink" title="1.8 Lamada层"></a>1.8 Lamada层</h4><p><code>keras.layers.core.Lambda(function, output_shape=None, mask=None, arguments=None)</code></p>
<p>lamada层可以对上一层的任何输出进行任何theano或者tensorflow表达式的变换。</p>
<ul>
<li>function：要实现的函数，该函数仅接受一个变量，即上一层的输出</li>
<li>output_shape：函数应该返回的值的shape，可以是一个tuple，也可以是一个根据输入shape计算输出shape的函数</li>
<li>mask: 掩盖值</li>
<li>arguments：可选，字典，用来记录向函数中传递的其他关键字参数</li>
</ul>
<p>输入shape：任意，当使用该层作为第一层时，要指定input_shape<br>输出shape：由output_shape参数指定的输出shape，当使用tensorflow时可自动推断</p>
<p>lamada层我的理解是收到了上一层的输入，然后对它进行了一个lamada表达式的整体变换。这个表达式可以是任意一个数学表达式，比如y = x^3 + x^2 +45这样。</p>
<p>demo:</p>
<pre><code class="python"># add a x -&gt; x^2 layer
model.add(Lambda(lambda x: x ** 2))

# add a layer that returns the concatenation
# of the positive part of the input and
# the opposite of the negative part

def antirectifier(x):
    x -= K.mean(x, axis=1, keepdims=True)
    x = K.l2_normalize(x, axis=1)
    pos = K.relu(x)
    neg = K.relu(-x)
    return K.concatenate([pos, neg], axis=1)

def antirectifier_output_shape(input_shape):
    shape = list(input_shape)
    assert len(shape) == 2  # only valid for 2D tensors
    shape[-1] *= 2
    return tuple(shape)

model.add(Lambda(antirectifier,
         output_shape=antirectifier_output_shape))</code></pre>
<p><strong>1.9、ActivityRegularizer层</strong></p>
<p>经过本层的数据不会有任何变化，但是会基于激活值更新损失函数值。</p>
<p>参数</p>
<ul>
<li>l1：1范数正则因子（正浮点数）</li>
<li>l2：2范数正则因子（正浮点数）</li>
</ul>
<p>输入shape：任意，当使用该层作为第一层时，要指定input_shape<br>输出shape：与输入shape相同</p>
<h2 id="2-卷积层convolutional"><a href="#2-卷积层convolutional" class="headerlink" title="2 卷积层convolutional"></a>2 卷积层convolutional</h2><h4 id="2-1-Conv1D层"><a href="#2-1-Conv1D层" class="headerlink" title="2.1 Conv1D层"></a>2.1 Conv1D层</h4><p><code>keras.layers.convolutional.Conv1D(filters, kernel_size, strides=1, padding=&#39;valid&#39;, dilation_rate=1, activation=None, use_bias=True, kernel_initializer=&#39;glorot_uniform&#39;, bias_initializer=&#39;zeros&#39;, kernel_regularizer=None, bias_regularizer=None, activity_regul128arizer=None, kernel_constraint=None, bias_constraint=None)</code></p>
<p>一维卷积层(时域卷积)，用以在一维输入上进行邻域滤波，当使用该层为首层时，需要提供关键字参数input_shape,例如 (10,128)代表了长度为10的序列，序列中每个信号为128向量。而(None,128)表示了信号序列是变长、每个信号是128维的向量。</p>
<p>该层将输入信号与卷积核按照单一的空域方向进行卷积。</p>
<p>参数：</p>
<ul>
<li>filters：卷积核的数目（即输出的维度）</li>
<li>kernel_size：整数或由单个整数构成的list/tuple，卷积核的空域或时域窗长度</li>
<li>strides：整数或由单个整数构成的list/tuple，为卷积的步长。任何不为1的strides均与任何不为1的dilation_rate均不兼容</li>
<li>padding：补0策略，为“valid”, “same” 或“causal”，“causal”将产生因果（膨胀的）卷积，即output[t]不依赖于input[t+1：]。当对不能违反时间顺序的时序信号建模时有用。参考WaveNet: A Generative Model for Raw Audio, section 2.1.。“valid”代表只进行有效的卷积，即对边界数据不处理。“same”代表保留边界处的卷积结果，通常会导致输出shape与输入shape相同。</li>
<li>activation：激活函数，为预定义的激活函数名（参考激活函数），或逐元素（element-wise）的Theano函数。如果不指定该参数，将不会使用任何激活函数（即使用线性激活函数：a(x)=x）</li>
<li>dilation_rate：整数或由单个整数构成的list/tuple，指定dilated convolution中的膨胀比例。任何不为1的dilation_rate均与任何不为1的strides均不兼容。</li>
<li>use_bias:布尔值，是否使用偏置项</li>
<li>kernel_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers</li>
<li>bias_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers</li>
<li>kernel_regularizer：施加在权重上的正则项，为Regularizer对象</li>
<li>bias_regularizer：施加在偏置向量上的正则项，为Regularizer对象</li>
<li>activity_regularizer：施加在输出上的正则项，为Regularizer对象</li>
<li>kernel_constraints：施加在权重上的约束项，为Constraints对象</li>
<li>bias_constraints：施加在偏置上的约束项，为Constraints对象</li>
</ul>
<p>输入shape：形如（samples，steps，input_dim）的3D张量<br>输出shape：形如（samples，new_steps，nb_filter）的3D张量，因为有向量填充的原因，steps的值会改变</p>
<p>【Tips】可以将Convolution1D看作Convolution2D的快捷版，对例子中（10，32）的信号进行1D卷积相当于对其进行卷积核为（filter_length, 32）的2D卷积。</p>
<h4 id="2-2-Conv2D层"><a href="#2-2-Conv2D层" class="headerlink" title="2.2 Conv2D层"></a>2.2 Conv2D层</h4><p><code>keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding=&#39;valid&#39;, data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer=&#39;glorot_uniform&#39;, bias_initializer=&#39;zeros&#39;, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)</code></p>
<p>二维卷积层，是对图像的空域卷积，该层对二维输入进行滑动窗卷积。当该层为第一层时，应该提供input_shape参数。例如input_shape = （128,128,3）。代表了128*128的彩色RGB图像。</p>
<h4 id="2-3-Conv3D层"><a href="#2-3-Conv3D层" class="headerlink" title="2.3 Conv3D层"></a>2.3 Conv3D层</h4><p><code>keras.layers.convolutional.Conv3D(filters, kernel_size, strides=(1, 1, 1), padding=&#39;valid&#39;, data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, kernel_initializer=&#39;glorot_uniform&#39;, bias_initializer=&#39;zeros&#39;, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)</code></p>
<p>三维卷积对三维的输入进行滑动窗卷积。当使用该层为第一层时，应该提供input_shape参数。</p>
<p>例如input_shape = (3,10,128,128)代表对10帧128*128彩色RGB图像进行卷积。数据通道位置仍然有data_format参数指定。</p>
<h4 id="2-4-Cropping1D层"><a href="#2-4-Cropping1D层" class="headerlink" title="2.4 Cropping1D层"></a>2.4 Cropping1D层</h4><p><code>keras.layers.convolutional.Cropping1D(cropping=(1, 1))</code></p>
<p>在时间轴上对1D输入进行裁剪</p>
<p>参数：</p>
<ul>
<li>cropping：长为2的tuple，指定在序列的首尾要裁剪掉多少个元素</li>
</ul>
<p>输入shape：形如（samples，axis_to_crop，features）的3D张量<br>输出shape：形如（samples，cropped_axis，features）的3D张量。</p>
<h4 id="2-5-UpSampling1D层"><a href="#2-5-UpSampling1D层" class="headerlink" title="2.5 UpSampling1D层"></a>2.5 <strong>UpSampling1D层</strong></h4><p><code>keras.layers.convolutional.UpSampling1D(size=2)</code></p>
<p>在时间轴上，将每个时间步重复length次</p>
<p>参数</p>
<ul>
<li>size：上采样因子</li>
</ul>
<p>输入shape：形如（samples，steps，features）的3D张量<br>输出shape：形如（samples，upsampled_steps，features）的3D张量</p>
<h4 id="2-6-ZeroPadding1D层"><a href="#2-6-ZeroPadding1D层" class="headerlink" title="2.6 ZeroPadding1D层"></a>2.6 <strong>ZeroPadding1D层</strong></h4><p><code>keras.layers.convolutional.ZeroPadding1D(padding=1)</code></p>
<p>对输入的首位端填充0</p>
<h2 id="3-池化层"><a href="#3-池化层" class="headerlink" title="3.池化层"></a>3.池化层</h2><h4 id="3-1-Maxpooling-1D层"><a href="#3-1-Maxpooling-1D层" class="headerlink" title="3.1 Maxpooling 1D层"></a>3.1 Maxpooling 1D层</h4><p><code>keras.layers.pooling.MaxPooling1D(pool_size=2, strides=None, padding=&#39;valid&#39;)</code></p>
<p>对时域1D信号进行最大值池化。</p>
<p>也就是揪出一系列向量中最长的哪一个，然后把所有向量的长度都扩充到和最长的向量一样长。</p>
<h2 id="4-递归层"><a href="#4-递归层" class="headerlink" title="4. 递归层"></a>4. 递归层</h2><p>递归层包括三种模型：LSTM,GRU和SimpleRNN</p>
<h4 id="4-1-抽象层，不能直接使用"><a href="#4-1-抽象层，不能直接使用" class="headerlink" title="4.1 抽象层，不能直接使用"></a>4.1 抽象层，不能直接使用</h4><p><code>keras.layers.recurrent.Recurrent(weights=None, return_sequences=False, go_backwards=False, stateful=False, unroll=False, consume_less=&#39;cpu&#39;, input_dim=None, input_length=None)</code></p>
<p>return_sequences：True返回整个序列，false返回输出序列的最后一个输出</p>
<p>go_backwards：True，逆向处理输入序列，默认为False</p>
<p>stateful：布尔值，默认为False，若为True，则一个batch中下标为i的样本的最终状态将会用作下一个batch同样下标的样本的初始状态</p>
<h4 id="4-2-全连接RNN网络层"><a href="#4-2-全连接RNN网络层" class="headerlink" title="4.2 全连接RNN网络层"></a>4.2 全连接RNN网络层</h4><p><code>keras.layers.recurrent.SimpleRNN(output_dim, init=&#39;glorot_uniform&#39;, inner_init=&#39;orthogonal&#39;, activation=&#39;tanh&#39;, W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)</code></p>
<p>inner_init：内部单元的初始化方法</p>
<p>dropout_W：0~1之间的浮点数，控制输入单元到输入门的连接断开比例</p>
<p>dropout_U：0~1之间的浮点数，控制输入单元到递归连接的断开比例</p>
<h4 id="4-3-LSTM层"><a href="#4-3-LSTM层" class="headerlink" title="4.3 LSTM层"></a>4.3 LSTM层</h4><p><code>keras.layers.recurrent.LSTM(output_dim, init=&#39;glorot_uniform&#39;, inner_init=&#39;orthogonal&#39;, forget_bias_init=&#39;one&#39;, activation=&#39;tanh&#39;, inner_activation=&#39;hard_sigmoid&#39;, W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)</code></p>
<p>forget_bias_init：遗忘门偏置的初始化函数，Jozefowicz et al.建议初始化为全1元素</p>
<p>inner_activation：内部单元激活函数</p>
<h4 id="4-4-嵌入层"><a href="#4-4-嵌入层" class="headerlink" title="4.4 嵌入层"></a>4.4 嵌入层</h4><p><code>keras.layers.embeddings.Embedding(input_dim, output_dim, init=&#39;uniform&#39;, input_length=None, W_regularizer=None, activity_regularizer=None, W_constraint=None, mask_zero=False, weights=None, dropout=0.0)</code></p>
<p>embedding。只能作为模型的第一层。</p>
<p>mask_zero：布尔值，确定是否将输入中的‘0’看作是应该被忽略的‘填充’（padding）值，该参数在使用递归层处理变长输入时有用。设置为True的话，模型中后续的层必须都支持masking，否则会抛出异常</p>

            <hr>
          </div>
          <br>
          <div>
            <p>
            
              <span>
                <i class="iconfont icon-inbox"></i>
                
                  <a class="hover-with-bg" href="/categories/%E6%A6%82%E5%BF%B5">概念</a>
                  &nbsp;
                
              </span>&nbsp;&nbsp;
            
            
              <span>
                <i class="iconfont icon-tag"></i>
                
                  <a class="hover-with-bg" href="/tags/Keras">Keras</a>
                
              </span>
            
            </p>
            
              <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
            
          </div>
        </div>
      </div>
    </div>
    <div class="d-none d-lg-block col-lg-2 toc-container">
      
  <div id="toc">
    <p class="h4"><i class="far fa-list-alt"></i>&nbsp;目录</p>
    <div id="tocbot"></div>
  </div>

    </div>
  </div>
</div>

<!-- custom -->


<!-- Comments -->
<div class="col-lg-7 mx-auto nopadding-md">
  <div class="container comments mx-auto" id="comments">
    
  </div>
</div>

    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>




  
    <script src="/lib/tocbot/tocbot.min.js" ></script>
  
  <script src="/js/post.js" ></script>



  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "0.概念/Python_keras_layer概况&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
