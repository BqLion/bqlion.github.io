<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/index.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_1.JVM,%E6%96%B9%E6%B3%95%E5%8C%BA,%E5%A0%86/">
        <p class="h4 index-header">0.文章/Java_1.JVM,方法区,堆</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">JVM
JAVA虚拟机的生命周期
java虚拟机用于执行java程序,一个java程序对应一个虚拟机
java虚拟机总是开始于一个main方法,返回void,接受一个args[]参数
main()方法是程序的起点,他被执行的线程初始化为程序的初始线程
java中的线程分两种
守护线程daemon:java虚拟机自己使用的,比如垃圾回收
非守护线程:non-daemon:包含main()方法的初始线程不是守护线程






运行时数据区域


1.程序计数器
内存空间小,线程私有,字节码解释器就是依赖程序计数器工作的:改变计数器的值来选取下一条需要执行的指令,分支,循环,跳转,异常处理等.
如果线程正在执行一个java方法,这个计数器就记录正在执行的虚拟机字节码地址.
如果这个方法是native方法,则计数器的值为underfined


程序计数器这个区域是java虚拟机中唯一没有规定任何OutOfMemoryError情况的区域


2.java虚拟机栈
线程私有,生命周期和线程一致
线程(thread)
是操作系统能够进行运算调度的最小单位
被包含在进程中,是进程的实际运作单位
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%96%87%E7%AB%A0">文章</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/java">java</a>&nbsp;
          
            <a href="/tags/JVM">JVM</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_D3NER/">
        <p class="h4 index-header">0.概念/NLP_D3NER</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">D3NER:biomedical named entity recognition using CRF-biLSTM improved with fine-tuned embedding of various linguistic information找有代码的论文读，复现作者的工作
1.标题D3NER:一种使用[被精细调整过”多种语言信息embedding”所提升性能的条件随机场-双向长短时记忆网络]的生物医学命名实体识别工具

embedding

CRF

biLSTM
均另起文章讨论


2.abstract2.1Motivation
生物医学命名实体识别技术,是从生物医学文本信息(unstructured text)中提取知识的先决条件,最近LSTM网络被应用到这个问题上,表现很好,不过我们有更改进的地方.
2.2Result
我们使用D3NER,一种使用了CRF+biLSTM网络+精调语言信息embedding的生物医学命名实体识别技术
D3NER和同方向的七种实体识别技术做了充分对比,结论是性能确实有提高
3.Introduction
特征工程做NER
Named En</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/D3NER">D3NER</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_CRF%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/">
        <p class="h4 index-header">0.概念/NLP_CRF条件随机场</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">条件随机场
概率统计图概览


马尔科夫假设/马尔科夫性

马尔科夫假设
马尔科夫链  里的  总是只受  一个人的影响。马尔科夫假设这里相当于就是个2-gram。
马尔科夫过程
在一个过程中，每个状态的转移只依赖于前n个状态




马尔科夫性
马尔科夫性是保证或者判断概率图是否为概率无向图的条件
成对性
局部性
全局性






条件随机场定义

条件随机场是在给定的随机变量 （具体，对应观测序列  ）条件下，随机变量  （具体，对应隐状态序列  的马尔科夫随机场。
广义的CRF的定义是： 满足  的马尔科夫随机场叫做条件随机场（CRF）
条件随机场是一种特殊的马尔科夫随机场
马尔科夫随机场
首先我们有无向图G=(V,E)， 图G中每个节点v上都有一个随机变量y，这样所有的节点上的随机变量就构成一组随机变量Y，图G上有联合概率分布P(Y)。边e表示相邻节点的变量存在某种神秘的联系。
图G上的随机变量Y满足马尔科夫性，即两个不相邻的节点上的随机变量yi，yj条件独立。这就是马尔科夫随机场。




CRF建模公式


CRF特征函数











</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/CRF">CRF</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E8%AF%8D%E5%90%91%E9%87%8F_n-gram/">
        <p class="h4 index-header">0.概念/NLP_词向量_n-gram</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">n-gram语言模型1.Statistical Language Model
在自然语言处理中的一个基本问题,如何计算一段文本序列在某某种语言下出现的概率?
例子

我经常会去图书馆＿＿＿？
预测该句后面的词，我们通常会根据已有的语料的上下文，来统计预测这句话可以填某个词汇的概率，将最大的概率作为结果返回


机器翻译中,I like  Tomc so much,将单词逐个翻译—-{我,喜欢,汤姆,非常},这个集合中的字词排列组合成句子,然后用语言模型去计算组成句子概率的大小,概率越大越流畅

2.n-gram语言模型
理解:
n-gram语言模型的思想,可以追溯到香农的问题:给定一串字母,比如”for ex”,下一个最可能出现的字母是什么?从训练语料中,我们可以通过极大似然估计的方法,得到N个概率分布,是”a”的概率是0.4,是”b”的概率是0.0001,是c的概率是….,and 别忘记约束条件:所有N个概率的分布总和为1
如下图,运用条件概率和乘法公式推倒:
直接这么计算比较困难,需要引入马尔科夫假设,即,一个item的出现,只与前m个items有关,m = 0时,就是unigra</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F">词向量</a>&nbsp;
          
            <a href="/tags/n-gram">n-gram</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E4%B8%89%E4%B8%AA%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">
        <p class="h4 index-header">2.比赛/指导_三个集成学习模型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">三个常用的集成学习模型常见集成学习模型一览图
集成学习的优点采用多个分类器对数据集预测,提高整体分类器的泛化能力
三种常见的集成学框架
bagging 装袋
boosting 提升
stacking 堆栈

bagging–装袋
子训练集一般是各不相同的
基模型一般采用SVM或者朴素贝叶斯(大家一般采用同一种模型)
测试集扔给基模型们,然后各个基模型投票表决,简单多数为最终结果

Boosting提升第一次训练得到返回结果,然后给每一个结果分配权值,分类正确的权值降低,错误的权值上升
分类错误权值升高,在第二次训练时被重点关照
测试–测试集扔给各个样本,最后根据投票权值分配投票权,最终得到分配结果
Stacking–堆叠

训练集分出n个基模型
集成方法:
基础模型比如有100个,每个输出三维向量,一共就输出300维的向量
这个向量在堆叠模型那里训练
测试集也有三百维,最后生成测试数据让模型训练,得到最终结果



集成模型的偏差与方差

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/2.%E6%AF%94%E8%B5%9B">2.比赛</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0">集成学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2&%E9%A2%84%E5%A4%84%E7%90%86_CrowdFlower/">
        <p class="h4 index-header">2.比赛/指导_数据探索&amp;预处理_CrowdFlower</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">以CrowdFlower比赛为例讲解数据探索与预处理比赛目标​    衡量搜索结果的相关性

比赛数据集
CrowdFlower平台丰富的查询结果配对创建的
为了评估搜索相关性,CrowdFlower已经将261个搜索词与产品列表放在一起,要求人群对每个搜索结果评分,1,2,3,4分别表示搜索结果从完全不相关到完全相关



数据集
train.csv训练集数据
id 产品id
query 搜索词语
product_title 产品标题
product_description 产品描述文本
median_relevance 三位评分员的相关性评分中位数
relevance_variance 评分员的相关性评分方差


test.csv
id 产品id
query 搜索词语
product_description 产品描述文本


目标变量
median_relevance



数据预处理

首先本数据以文字为主,文字只能输入进分类树模型,所以首先要把文字转换成数字
Dropping HTML标签
Word Replacement:然后要把拼写错误的单词替换掉
stemming:词干化</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/2.%E6%AF%94%E8%B5%9B">2.比赛</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">数据预处理</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E4%B8%8E%E5%B7%A5%E5%85%B7/">
        <p class="h4 index-header">2.比赛/指导_常见算法与工具</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">比赛常用算法与工具1.1 本文提纲
机器学习应用领域
机器学习常见算法
常用工具
建模与问题解决流程
数据处理
特征工程
模型选择
寻找最佳超参数:交叉验证
模型分析与模型融合


kaggle wiki
简单案例讲解

1.2机器学习常见算法
1.3机器学习常见工具

scikit - learn :速度不快,但是全面,封装的好,只需要造出来基本参数就可以自动去跑
gensim - 自然语言处理会用
NUmPy - 科学计算(封装到其他工具里了)
matplotlib - 绘图
pandas - 数据清洗,产出特征,缺省值,填充等
xgboost - 基于boost的库,分类和回归都可以完成
Natural Language Toolkit多用于英文的自然语言处理,中文用的很少
Jieba - 多用于中文语言处理
TensorFlow - 深度学习库,对显存的占用较高,速度不算太快
Caffe -深度学习库, 图像用的很多
Keras - 深度学习库,接口简单,本视频deep learning部分用Keras

1.4解决问题流程
了解场景和目标
了解评估准则
认识数据
数据预处理(</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/2.%E6%AF%94%E8%B5%9B">2.比赛</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%AF%94%E8%B5%9B">比赛</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/">
        <p class="h4 index-header">0.概念/NLP_极大似然估计</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">极大似然估计极大似然估计是确定机器学习模型的参数的一种办法。确定参数值的过程，是找到能最大化“模型产生真实观察数据可能性“的那一组参数，略抽象，如下是一个例子：
从某过程观察了如下十个数据点，每个数据点代表了学生回答问题使用的秒数。

这些数据的生成过程可以使用高斯分布（正态分布）进行充分描述。高斯分布有两个参数，西格玛和μ，如何确定参数？如下示意图表示了使用不同参数的不同高斯分布（方差大的中心函数更扁平）。
注：蓝色曲线是正确曲线N(10,2.25)

OK，如何反编译确定正确参数？我们把这个例子再次简化，同样的情境，这次只存在三个数据点：9,9.5,11
如何使用最大似然估计确定这个高斯分布的参数？
高斯分布中，单个数据点x的边缘概率如下

同时观察到上边所提三个点（9,9.5,11）的联合概率是带入上边三个数据的连乘积：

我们只要能找到最大化上述连乘积的参数μ和西格玛就ok了。也就是说，最大似然估计是一个通过确定参数得到函数最大值的优化问题。
那么，如何求出上述函数的最大值？
easy，二元函数求偏导标准步骤，加以两边套上对数等数学小技巧就完事儿了。
SOP:


</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1">极大似然估计</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E6%A2%AF%E6%AE%B5%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">
        <p class="h4 index-header">0.概念/NLP_梯段下降算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">梯度下降算法对于优化问题，机器学习的目标是使得某个损失函数最小。也就是找到一个x = min f(x)。但并不是所有的问题都能找到解析解，部分问题只能通过数值计算的方法逼近最优解 —— 一阶导数的梯度下降算法和二阶导数的牛顿方法。

问题描述:有一个代价函数，它有两个参数，想让这个代价函数的值最小化。
做法：持续把这个两个参数向着梯度下降最快的方向迭代。



梯度下降算法的学习率α设置:
α过小,收敛太慢
α过大,在最小值附近震荡


梯度下降缺点:可能求的是局部最优解，解决办法是多次随机初始化起点。

1.多特征值的回归问题

单特征回归:只有房子面积一个特征,求预测房价

单特征回归的假设函数:h(x) = θ0 + θ1x


多特征回归:有房子面积,卧室数量,几层高,使用年限四个特征,求预测房价

四特征回归的假设函数:h(x) = θ0 + θ1x1+θ2x2+θ3x3+θ4x4    —-&gt;   缩写h = θ(XT) :向量θ乘以向量X的转置
只考虑最简单的一次线性多项式


多特征回归的梯度下降算法:

每次对一个参数求偏导,并对其迭代.
所有参数都迭代这么一圈</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95">梯度下降算法</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E5%88%A4%E5%AE%9A%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/">
        <p class="h4 index-header">0.概念/NLP_判定模型和生成模型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">判定模型和生成模型的区别
机器学习的任务是从属性X预测标记Y，即是求概率P（Y|X）

判别式模型是上图左边示例，有个明显的边界，新来一个值需要判断他属于哪一类的时候直接算出他的score，当score大于threshold时为正类，反之为负类。线性回归，SVM模型都是典型的判别式模型
生成式模型是上图右边示例，无明显边界，新来一个值要判断他是哪一类的时候，首先求该值与两个不同标记的不同联合概率分布，然后大的获胜。朴素贝叶斯模型，HMM模型都是生成式模型。

一个生动的例子说明两者的区别:

判别式模型：要确定一个羊是山羊还是绵羊，用判别式的方法是从历史数据中学到模型（运行同一个模型得到确定的结果），然后通过提取这只羊的特征来预测出羊的类型。
生成式模型：根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型。然后提取这只待判定羊的特征，放到山羊模型中看看概率是多少，再放到绵羊模型中看看概率是多少。哪个大就是哪个。（两个模型，两个结果，最后比比数值大小得出结论）

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E5%88%A4%E5%AE%9A%E6%A8%A1%E5%9E%8B">判定模型</a>&nbsp;
          
            <a href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">生成模型</a>&nbsp;
          
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/page/14/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><span class="page-number current">15</span><a class="page-number" href="/page/16/">16</a><a class="page-number" href="/page/17/">17</a><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/16/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "暗影疾行&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
