<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/index.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_Git/">
        <p class="h4 index-header">0.概念/技术_Git</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Git1.四个区域Workplace : 工作区，自己的电脑存放代码的地方
Index，Stage ： 暂存区，存放临时的改动，事实上它是一个文件，保存即将提交到文件列表的信息
Repository  :  仓库区（版本库），存放数据的地方，有所有提交版本的地方，其中head指向最新放入仓库的版本
Remote ：远程仓库，托管代码的服务器，可以简单理解为项目组的一台用于远程数据交换的电脑
四者关系如下

2.常用命令常用
# 本地推至暂存区
git add .
# 删除暂存区/分支，但本地保留文件（不被版本控制）
git rm --cached file_path
# 为本地代码切换版本
git checkout
# 暂存区代码推至版本库
git commit -m &quot;提交说明&quot;
# 移除暂存区文件
git reset HEAD 文件名
# 去掉上次的提交(变成add前状态)
git reset HEAD^
# 去掉上次的提交(变成commit前状态)
git reset --soft HEAD^
# 显示当前git配置
git config --lsit
# 编</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/0%20-%20%E6%80%BB%E4%BD%93%E6%80%9D%E8%B7%AF/">
        <p class="h4 index-header">1.科研/0 - 总体思路</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">0 - 总体思路
基础 ： Speech and Language Processing（完成）
早年经典NLP论文：遍历论文库（进行中）
了解机器学习的基本模型：
CS229（完成）
Pattern Recognition and Machine Learning


了解NLP其他子领域(MT,信息抽取,parsing,tagging,情感分析,MRC等)（进行中）
了解CV和数据挖掘领域的进展


学科调研：构建阅读列表和论文库；读近五年survey，近三年顶会，感兴趣方向热门论文和经典书单；输出互引DAG图，输出专有名词词典，输出调研文档。

   *构建文献库时遇到的困难：flood。目前资料：知识图谱80 + 深度学习100 + 生物医学CRF70 + ACL660 = 910篇论文，以及7本大部头。这还不包括所谓的5年survery100 + 三年顶会3000共约3100篇论文。 *
   我需要的：迅速了解整个学科发展大致现状，选择自己感兴趣的+有前途做的人少的领域迅速构建论文库精读切入
   初步解决方案：控制工作量，看优质survey，大部头只挑一本看，其余当工具书</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/4.%E5%AE%89%E8%A3%85%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/%E5%BF%AB%E6%8D%B7%E9%94%AE/">
        <p class="h4 index-header">4.安装调试记录/快捷键</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">PyCharmCTRL + -  = 折叠本行 
CTRL + + = 打开本行
CTRL + SHIFT + -  = 全部折叠
CTRL + SHIFT + + = 全部打开
ChromeCTRL + SHIFT + N = 打开匿名窗口
CTRL + SHIFT + I =  检查
CTRL + W  = 关闭当前标签页
CTRL + fn  + PgUp/PgDn = 上翻/下翻当前标签页
IDEACTRL + SHIFT + F12 =  编程窗口最大化
CTRL + SHIFT+ N = 查找文件
SHIFT + F6 = 全局替换
CTRL + ALT + L = 格式化代码
CTRL + ALT + V =快速赋值
Cookie[] cookeis数组遍历便捷写法  = cookies.for = for(Cookie cookie : cookies)
SHIFT + F6  = 文件重命名
CTRL + SHIFT + C = 拷贝文件路径
CTRL + D = 拷贝一行
SHIFT + ENTER = 换行
CTRL + P = 查看参数
CTRL + N = 查</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Java_5.%E7%B4%A2%E5%BC%95,%E8%B0%83%E4%BC%98/">
        <p class="h4 index-header">0.概念/0.文章/Java_5.索引,调优</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.sql索引,调优索引相关概念

索引原理
DBMS索引一般用b tree或者b+tree实现



带主键的数据库表的存储结构(正常查找)

构建索引后从非聚集索引直接查找

Sql语句执行流程
create index index_birthday on user_info(birthday)   //构建索引
select user_name from user_info where birthday = ‘1991-01-01’      //正常查找数据
create index index_birthday_and_user_name on user_info(birthday,user_name);   //构建双字段的覆盖索引



</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Java_7.%E5%8F%8D%E5%B0%84/">
        <p class="h4 index-header">0.概念/0.文章/Java_7.反射</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">反射
反射的定义

行状态中,能知道任何一个类的属性和方法
能调用任何一个对象的属性和方法
这种动态获取信息以及动态调用对象方法的功能称谓java的反射机制


反射的用途

第三方应用开发时,会遇到某个类的变量或方法是私有的,只对系统应用开放,这时候就利用java的反射机制通过反射来获取所需要的私有成员或者方法.


反射的相关类


class类





</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Java_6.jetty%E5%92%8Ctomcat/">
        <p class="h4 index-header">0.概念/0.文章/Java_6.jetty和tomcat</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.jetty和tomcat1.Jetty是什么
​    jetty是一个开源的HTTP服务器和Servlet引擎,可以为JSP和Servlet提供运行时环境,相对与Tomcat,,jetty更加轻量级,更加简易和灵活
2.jetty特点

异步,支持更高的并发量
灵活,更加轻量,更容易定制,更高的资源利用率
Jetty采用默认的NIO模型,jetty很好地支持长链接

3.应用场景

企业级应用tomcat占据了绝对优势
jetty默认使用NIO,在轻量级的,保持长连接的场景下使用很有优势,比如客服的聊天

4.jetty原理

提供了两种handlder
handlerWrapper
可以将一个Handler委托给另一个类执行,将handler加载到jetty中就是通过handler委托给server执行的


handlerCollection
将多个handler组装成handler链,可以方便地做扩展





2.tomcat
为了服务器生成动态页面,需要运行java Servlet,那么就需要提供Servlet容器
Tomcat正式支持运行Servlet/JSP应用程序</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Java_2.ClassLoader/">
        <p class="h4 index-header">0.概念/0.文章/Java_2.ClassLoader</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2.ClassLoader类加载器classloader作用:

负责将class加载到JVM中
审查每个类由谁加载
将class字节码重新编译成JVM统一要求的对象格式

2.1类加载时机与过程类从被加载到虚拟机内存开始,到卸载出内存为止,整个生命周期包括了七个部分:
加载,验证,准备,解析,初始化,使用,卸载

如下几种情况会对类进行初始化

创建类的实例
对类进行反射调用
当初始化类,发现父类没有没初始化
jvm启动,用户指定一个要执行的主类,虚拟机会先初始化这个主类
java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic,REF_putstatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。

2.2类加载器的双亲委派模型

双亲委派模型好处

避免重复加载,当父类已经加载了该类的时候,就没有必要classloader再加载一次考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Java_4.%E8%A1%A8%E9%93%BE%E6%8E%A5/">
        <p class="h4 index-header">0.概念/0.文章/Java_4.表链接</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.表链接5.1外链接外链接就是A B两个表,以左右链接的方式选择一个主表,然后附表加入主表的过程
AB两个表的图示


左外链接

select * from TableA left join TableB on TableA.id=TableB.id






右外链接

select * from TableA right join TableB on TableA.id=TableB.id






全外链接

select * from TableA full join TableB on TableA.id=TableB.id




内链接

select * from TableA JOIN TableB on TableA.id=TableB.id
结果是只链接两者共有的数据






交叉链接

select * from TableA cross join TableB

结果是两个表以基础序号为乘积的笛卡尔积的排列





</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Java_3.%E6%B3%9B%E5%9E%8B/">
        <p class="h4 index-header">0.概念/0.文章/Java_3.泛型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">泛型泛型就是扩展了方法的适用范围:
例子:
原本有一个SUM(y) = (a + b)的两元素相加的方法

在两数字相加或两字符串拼接的场景下本来都可以用它

但是如果y提前规定了数据类型就不能用了,两个场景必有其一要重写

这时候使用泛型,&lt;T&gt;当做占位符,就可以实现代码复用了 


之所以不用Object实现参数的任意化是因为要做显式的强制转换,这种转换是要求开发者对实际参数可预知的情况下进行的,而很多时候开发者不能预知程序运行时有哪样的类型需要强转
如果强转错误,程序员也无从得知,是一个安全隐患
引入泛型不用object后所有任意化的参数类型都是隐式自动进行的,保证了效率和安全性
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%92%8C%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">
        <p class="h4 index-header">0.概念/NLP_知识图谱和推荐系统</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.知识图谱知识图谱是语义网络semantic network的知识库，可理解为理解为多关系图，多关系图一般包含多种类型的节点和边。
知识图谱的场景

社交网络，人和公司都可以是实体，人是节点，公司是节点的集合，人与人之间的关系是边，边可以是朋友也可是同事等，关系可以是单向也可以是双向的

数据库是结构化数据，网页是非结构化数据，处理非结构化数据是信息抽取的难点。
四个难点

实体命名识别  
关系抽取()
实体统一(武汉,江城)
指代消解  (it)

知识图谱的存储方式
RDF

存储三元组(triple)
推理引擎
W3C标准
易于发布数据,多为学术界场景

2.推荐系统评分预测:系统预测用户对电影的评分,根据此给用户推荐,这种是显示反馈
还有一种是点击率预测,新闻类应用中,根据用户点击某概率来优化推荐方案,这种场景下用户反馈信息的行为特征,而不能反映用户的喜爱成都,这是隐式反馈
传统的推系统只能使用用户和物品的历史交互信息,作为输入,有两个问题:
用户和物品之间的交互信息是非常稀疏的,几万个电影只看了几个可能过拟合,
或者新用户没有看过电影,这问题也叫冷启动问题
解决冷启动问题</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_Docker/">
        <p class="h4 index-header">0.概念/技术_Docker</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">DockerDocker是个虚拟机，主要运行在linux上，和VMware Workstation Pro有很多相似的地方。

镜像，是创建虚拟机之前需要下载的系统镜像文件，比如iso和img文件等
容器，是正在运行中的虚拟机
tar文件，就是镜像的压缩文件，压缩传送解压缩安装
dockerfile，配置文件，写完后通过docker bulid指令将dockerfile构建成一个镜像
仓库，类似于github，和镜像是pull和push的关系，里边有做好的ubuntu，mysql，tomcat镜像等

基本操作安装docker
docker pull nginx : 从仓库下载nginx
docker images : 查看本地镜像
docker run -d -p 80:80 nginx 后台将镜像运行为容器nginx，端口映射80-80
docker ps查看正在运行的容器有哪些，例如它会输出正在运行的容器是nginx，id是92a68b3fe02e
docker exec -it 92,进入运行的id开头是92的容器
cd /usr/share/nginx/html/,进入ngi</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Java_1.JVM,%E6%96%B9%E6%B3%95%E5%8C%BA,%E5%A0%86/">
        <p class="h4 index-header">0.概念/0.文章/Java_1.JVM,方法区,堆</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">JVM
JAVA虚拟机的生命周期
java虚拟机用于执行java程序,一个java程序对应一个虚拟机
java虚拟机总是开始于一个main方法,返回void,接受一个args[]参数
main()方法是程序的起点,他被执行的线程初始化为程序的初始线程
java中的线程分两种
守护线程daemon:java虚拟机自己使用的,比如垃圾回收
非守护线程:non-daemon:包含main()方法的初始线程不是守护线程






运行时数据区域


1.程序计数器
内存空间小,线程私有,字节码解释器就是依赖程序计数器工作的:改变计数器的值来选取下一条需要执行的指令,分支,循环,跳转,异常处理等.
如果线程正在执行一个java方法,这个计数器就记录正在执行的虚拟机字节码地址.
如果这个方法是native方法,则计数器的值为underfined


程序计数器这个区域是java虚拟机中唯一没有规定任何OutOfMemoryError情况的区域


2.java虚拟机栈
线程私有,生命周期和线程一致
线程(thread)
是操作系统能够进行运算调度的最小单位
被包含在进程中,是进程的实际运作单位
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_D3NER/">
        <p class="h4 index-header">0.概念/NLP_D3NER</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">D3NER:biomedical named entity recognition using CRF-biLSTM improved with fine-tuned embedding of various linguistic information找有代码的论文读，复现作者的工作
1.标题D3NER:一种使用[被精细调整过”多种语言信息embedding”所提升性能的条件随机场-双向长短时记忆网络]的生物医学命名实体识别工具

embedding

CRF

biLSTM
均另起文章讨论


2.abstract2.1Motivation
生物医学命名实体识别技术,是从生物医学文本信息(unstructured text)中提取知识的先决条件,最近LSTM网络被应用到这个问题上,表现很好,不过我们有更改进的地方.
2.2Result
我们使用D3NER,一种使用了CRF+biLSTM网络+精调语言信息embedding的生物医学命名实体识别技术
D3NER和同方向的七种实体识别技术做了充分对比,结论是性能确实有提高
3.Introduction
特征工程做NER
Named En</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_CRF%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/">
        <p class="h4 index-header">0.概念/NLP_CRF条件随机场</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">条件随机场
概率统计图概览


马尔科夫假设/马尔科夫性

马尔科夫假设
马尔科夫链  里的  总是只受  一个人的影响。马尔科夫假设这里相当于就是个2-gram。
马尔科夫过程
在一个过程中，每个状态的转移只依赖于前n个状态




马尔科夫性
马尔科夫性是保证或者判断概率图是否为概率无向图的条件
成对性
局部性
全局性






条件随机场定义

条件随机场是在给定的随机变量 （具体，对应观测序列  ）条件下，随机变量  （具体，对应隐状态序列  的马尔科夫随机场。
广义的CRF的定义是： 满足  的马尔科夫随机场叫做条件随机场（CRF）
条件随机场是一种特殊的马尔科夫随机场
马尔科夫随机场
首先我们有无向图G=(V,E)， 图G中每个节点v上都有一个随机变量y，这样所有的节点上的随机变量就构成一组随机变量Y，图G上有联合概率分布P(Y)。边e表示相邻节点的变量存在某种神秘的联系。
图G上的随机变量Y满足马尔科夫性，即两个不相邻的节点上的随机变量yi，yj条件独立。这就是马尔科夫随机场。




CRF建模公式


CRF特征函数











</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E8%AF%8D%E5%90%91%E9%87%8F_n-gram/">
        <p class="h4 index-header">0.概念/NLP_词向量_n-gram</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">n-gram语言模型1.Statistical Language Model
在自然语言处理中的一个基本问题,如何计算一段文本序列在某某种语言下出现的概率?
例子

我经常会去图书馆＿＿＿？
预测该句后面的词，我们通常会根据已有的语料的上下文，来统计预测这句话可以填某个词汇的概率，将最大的概率作为结果返回


机器翻译中,I like  Tomc so much,将单词逐个翻译—-{我,喜欢,汤姆,非常},这个集合中的字词排列组合成句子,然后用语言模型去计算组成句子概率的大小,概率越大越流畅

2.n-gram语言模型
理解:
n-gram语言模型的思想,可以追溯到香农的问题:给定一串字母,比如”for ex”,下一个最可能出现的字母是什么?从训练语料中,我们可以通过极大似然估计的方法,得到N个概率分布,是”a”的概率是0.4,是”b”的概率是0.0001,是c的概率是….,and 别忘记约束条件:所有N个概率的分布总和为1
如下图,运用条件概率和乘法公式推倒:
直接这么计算比较困难,需要引入马尔科夫假设,即,一个item的出现,只与前m个items有关,m = 0时,就是unigra</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E4%B8%89%E4%B8%AA%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">
        <p class="h4 index-header">2.比赛/指导_三个集成学习模型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">三个常用的集成学习模型常见集成学习模型一览图
集成学习的优点采用多个分类器对数据集预测,提高整体分类器的泛化能力
三种常见的集成学框架
bagging 装袋
boosting 提升
stacking 堆栈

bagging–装袋
子训练集一般是各不相同的
基模型一般采用SVM或者朴素贝叶斯(大家一般采用同一种模型)
测试集扔给基模型们,然后各个基模型投票表决,简单多数为最终结果

Boosting提升第一次训练得到返回结果,然后给每一个结果分配权值,分类正确的权值降低,错误的权值上升
分类错误权值升高,在第二次训练时被重点关照
测试–测试集扔给各个样本,最后根据投票权值分配投票权,最终得到分配结果
Stacking–堆叠

训练集分出n个基模型
集成方法:
基础模型比如有100个,每个输出三维向量,一共就输出300维的向量
这个向量在堆叠模型那里训练
测试集也有三百维,最后生成测试数据让模型训练,得到最终结果



集成模型的偏差与方差

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2&%E9%A2%84%E5%A4%84%E7%90%86_CrowdFlower/">
        <p class="h4 index-header">2.比赛/指导_数据探索&amp;预处理_CrowdFlower</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">以CrowdFlower比赛为例讲解数据探索与预处理比赛目标​    衡量搜索结果的相关性

比赛数据集
CrowdFlower平台丰富的查询结果配对创建的
为了评估搜索相关性,CrowdFlower已经将261个搜索词与产品列表放在一起,要求人群对每个搜索结果评分,1,2,3,4分别表示搜索结果从完全不相关到完全相关



数据集
train.csv训练集数据
id 产品id
query 搜索词语
product_title 产品标题
product_description 产品描述文本
median_relevance 三位评分员的相关性评分中位数
relevance_variance 评分员的相关性评分方差


test.csv
id 产品id
query 搜索词语
product_description 产品描述文本


目标变量
median_relevance



数据预处理

首先本数据以文字为主,文字只能输入进分类树模型,所以首先要把文字转换成数字
Dropping HTML标签
Word Replacement:然后要把拼写错误的单词替换掉
stemming:词干化</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E4%B8%8E%E5%B7%A5%E5%85%B7/">
        <p class="h4 index-header">2.比赛/指导_常见算法与工具</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">比赛常用算法与工具1.1 提纲
机器学习应用领域
机器学习常见算法
常用工具
建模与问题解决流程
数据处理
特征工程
模型选择
寻找最佳超参数:交叉验证
模型分析与模型融合


kaggle wiki
简单案例讲解

1.2机器学习常见算法
1.3机器学习常见工具

scikit - learn :速度不快,但是全面,封装的好,只需要造出来基本参数就可以自动去跑
gensim - 自然语言处理会用
NUmPy - 科学计算(封装到其他工具里了)
matplotlib - 绘图
pandas - 数据清洗,产出特征,缺省值,填充等
xgboost - 基于boost的库,分类和回归都可以完成
Natural Language Toolkit多用于英文的自然语言处理,中文用的很少
Jieba - 多用于中文语言处理
TensorFlow - 深度学习库,对显存的占用较高,速度不算太快
Caffe -深度学习库, 图像用的很多
Keras - 深度学习库,接口简单,本视频deep learning部分用Keras

1.4解决问题流程
了解场景和目标
了解评估准则
认识数据
数据预处理(清洗</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/">
        <p class="h4 index-header">0.概念/NLP_极大似然估计</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">极大似然估计极大似然估计是确定机器学习模型的参数的一种办法。确定参数值的过程，是找到能最大化“模型产生真实观察数据可能性“的那一组参数，略抽象，如下是一个例子：
从某过程观察了如下十个数据点，每个数据点代表了学生回答问题使用的秒数。

这些数据的生成过程可以使用高斯分布（正态分布）进行充分描述。高斯分布有两个参数，西格玛和μ，如何确定参数？如下示意图表示了使用不同参数的不同高斯分布（方差大的中心函数更扁平）。
注：蓝色曲线是正确曲线N(10,2.25)

OK，如何反编译确定正确参数？我们把这个例子再次简化，同样的情境，这次只存在三个数据点：9,9.5,11
如何使用最大似然估计确定这个高斯分布的参数？
高斯分布中，单个数据点x的边缘概率如下

同时观察到上边所提三个点（9,9.5,11）的联合概率是带入上边三个数据的连乘积：

我们只要能找到最大化上述连乘积的参数μ和西格玛就ok了。也就是说，最大似然估计是一个通过确定参数得到函数最大值的优化问题。
那么，如何求出上述函数的最大值？
easy，二元函数求偏导标准步骤，加以两边套上对数等数学小技巧就完事儿了。
SOP:


</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E6%A2%AF%E6%AE%B5%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">
        <p class="h4 index-header">0.概念/NLP_梯段下降算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">梯度下降算法对于优化问题，机器学习的目标是使得某个损失函数最小。也就是找到一个x = min f(x)。但并不是所有的问题都能找到解析解，部分问题只能通过数值计算的方法逼近最优解 —— 一阶导数的梯度下降算法和二阶导数的牛顿方法。

问题描述:有一个代价函数，它有两个参数，想让这个代价函数的值最小化。
做法：持续把这个两个参数向着梯度下降最快的方向迭代。



梯度下降算法的学习率α设置:
α过小,收敛太慢
α过大,在最小值附近震荡


梯度下降缺点:可能求的是局部最优解，解决办法是多次随机初始化起点。

1.多特征值的回归问题

单特征回归:只有房子面积一个特征,求预测房价

单特征回归的假设函数:h(x) = θ0 + θ1x


多特征回归:有房子面积,卧室数量,几层高,使用年限四个特征,求预测房价

四特征回归的假设函数:h(x) = θ0 + θ1x1+θ2x2+θ3x3+θ4x4    —-&gt;   缩写h = θ(XT) :向量θ乘以向量X的转置
只考虑最简单的一次线性多项式


多特征回归的梯度下降算法:

每次对一个参数求偏导,并对其迭代.
所有参数都迭代这么一圈</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E5%88%A4%E5%AE%9A%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/">
        <p class="h4 index-header">0.概念/NLP_判定模型和生成模型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">判定模型和生成模型的区别
机器学习的任务是从属性X预测标记Y，即是求概率P（Y|X）

判别式模型是上图左边示例，有个明显的边界，新来一个值需要判断他属于哪一类的时候直接算出他的score，当score大于threshold时为正类，反之为负类。线性回归，SVM模型都是典型的判别式模型
生成式模型是上图右边示例，无明显边界，新来一个值要判断他是哪一类的时候，首先求该值与两个不同标记的不同联合概率分布，然后大的获胜。朴素贝叶斯模型，HMM模型都是生成式模型。

一个生动的例子说明两者的区别:

判别式模型：要确定一个羊是山羊还是绵羊，用判别式的方法是从历史数据中学到模型（运行同一个模型得到确定的结果），然后通过提取这只羊的特征来预测出羊的类型。
生成式模型：根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型。然后提取这只待判定羊的特征，放到山羊模型中看看概率是多少，再放到绵羊模型中看看概率是多少。哪个大就是哪个。（两个模型，两个结果，最后比比数值大小得出结论）

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">
        <p class="h4 index-header">0.概念/NLP_支持向量机</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">支持向量机SVM9.1SVM的优化目标从逻辑回归展示如何一点点修改得到本质上的支持向量机

逻辑回归的假设函数




9.2核函数对支持向量机算法做一些修改,以构造复杂的非线性分类器
我们用”核函数”来达到此目的
问题的提出:
使用高级数的多项式模型来解决无法使用直线进行分割的分类问题,如何确定模式中的每一项的参数?
支持向量机的假设函数和代价函数

9.3 SVM的使用不建议自己写代码求解参数θ,就像没有人会写代码自己去求解平方根一样,可以直接调用现有的库
除了高斯核函数之外还有其他核函数可以用:
多项式核函数（Polynomial Kernel）
字符串核函数（String kernel）
卡方核函数（ chi-square kernel）
直方图交集核函数（histogram intersection kernel）
等等
SVM模型 和 逻辑回归模型之间的取舍:

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS229_8.%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/">
        <p class="h4 index-header">3.课程/CS229_8.应用机器学习的建议</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">8.应用机器学习的建议8.1如何提高一个算法/机器学习模型的性能问题:预测房价的机器学习模型性能遇见瓶颈,如何提升性能?

很多人是凭感觉去解决问题,他们有如下猜想并随便选一个去做

随便某个猜想都是耗时耗力巨大的项目,人们常常选择的是一条不归路

如何尽量排除无效的道路?



获得更多的训练样本——解决高方差   
尝试减少特征的数量——解决高方差
尝试获得更多的特征——解决高偏差
尝试增加多项式特征——解决高偏差
尝试减少正则化程度λ——解决高偏差
尝试增加正则化程度λ——解决高方差

8.2如何评估一个模型表现
模型的代价函数非常小未必是好事,因为可能存在过拟合的现象
为了检验模型是否过拟合,可以采用交叉验证的方法
可以把数据集分为训练集和测试集,然后重复洗牌交叉验证

高偏差与高方差

高偏差是欠拟合

高方差是过拟合




增加模型的多项式次数导致的过/欠拟合问题

训练集上:
增加模型多项式的次数会导致代价函数单调递减


交叉验证集上:
增加模型多项式的次数会导致代价函数先减后增
先减是改善了欠拟合的问题
后增就是过拟合越来越严重


结论:
交叉验证是评估过/欠拟合</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS229_5.%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96/">
        <p class="h4 index-header">3.课程/CS229_5.过拟合和正则化</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.过拟合和欠拟合问题两张插图说明白


解决办法:
过拟合就丢弃不能正确预测的特征,欠拟合就加特征
2.代价函数的惩罚项由下图可以看出,过拟合由于高维项造成



给高维项设置惩罚项

代价函数里给三次项和四次项增加一些重量,梯度下降的时候系统就会更急切想把三次项和四次项降下来

增加了惩罚项的代价函数





</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS229_6.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(%E8%A1%A8%E8%BF%B0)/">
        <p class="h4 index-header">3.课程/CS229_6.神经网络(表述)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">#
6.神经网络(表述)6.1问题的由来
特征爆炸无法处理
例如,智能识别一个图片是不是汽车的问题
假设使用50*50小黑白照片
那么就有2500个像素灰度作为特征
2500个特征两两组合就是3000000项,这的多项式处理不了
这时候就需要神经网络



6.2直观理解和逻辑运算符的构建
直观理解

神经网络能够通过自身学习得到一些列特征,这些特征是使用数据的原始特征经过拆分组合和一系列逻辑运算得到的
这样的一系列特征比普通的逻辑回归的表层特征要深刻的多
最后做决定的神经元依据上一层传进来的特征,这些特征已经经过多层传导,内化为自己的特征了


神经元可以通过增加一个固定权重神经元构建逻辑运算符(与,非,或,抑或等)

如下图




6.3神经网络的形态
6.4神经网络基本概念的定义from CS224N如图，神经网络有输入，有偏置单元，有激活函数，以及对后续神经网络的输出。
输入x，w是乘以输入的权重，b是偏置值，f是sigmod函数。
输入乘以权重加上偏置值后，进入sigmod函数，输出一个分类值。
有了神经网络，让我们再回到之前的单窗口分类器。代替之前直接将softmax应用</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS229_7.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(%E5%AD%A6%E4%B9%A0)/">
        <p class="h4 index-header">3.课程/CS229_7.神经网络(学习)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.神经网络(学习)7.1神经网络的代价函数

第一项是在K个输出项上(比如四分类就是K=4),累加逻辑回归的代价函数
第二项就是更高维的罚函数

代价函数的目的:找到使得J(θ)最小化的θ
7.2单个训练数据如何通过神经网络    

z(2) = θ(1)a(1) 

z(2)是第二层神经元的输入项,共五项,是a(1)的三项经过θ(1)矩阵拆分后的结果


a(2) = g[z(2)]

a(2)是第二层神经元的输出项,共五项,是z(2)五项经过第二层神经元的sigmod函数变换后的结果



后边的几层同理
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_PCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/">
        <p class="h4 index-header">0.概念/NLP_PCA主成分分析</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">PCA主成分分析问题定义机器学习有一类问题是有损压缩，即我们对原数据进行一些压缩以减少存储空间，这个过程不可避免的会损失一些原有的信息，希望能尽量减少信息丢失。
假设有三个三维空间的点x1，x2，x3，希望找到降维后二维空间的点t1，t2，t3。
将三个点从三维空间映射到二维空间的是压缩函数f（x）= t
将三个点从二维空间映射到回三维空间的是解压函数g（t）= x，对应的，若使用矩阵乘法来解压缩，则g(t) = Dt = x
其中D就是解压缩矩阵。
例如                           
x1   [1,2,3                t1  [1,2
x2    1,2,3     =   D  *   t2   1,2
x3    1,2,3]               t3   1,2]​              ↑压缩前数据   ↑解压缩矩阵    ↑压缩后数据
​           【  ↑ X      】      【               g(t)               】              
为了简化问题，PCA规</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS229_10.%E8%81%9A%E7%B1%BBClustering/">
        <p class="h4 index-header">3.课程/CS229_10.聚类Clustering</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">10.聚类Clustering10.1无监督学习简介无监督学习是让计算机学习无标签数据,而不是之前的标签数据
如图就是聚类问题
左上第一张图是市场分割,就是根据数据库里沉淀的客户信息来对客户分类,做知识图谱和推荐系统
10.2 K-mean (K均值算法)K均值是最普及的一个聚类算法,算法接受一个数据集,将数据聚类为不同的组

K-均值是一个迭代算法

设想我们将数据聚集成n组,选择k个随机的点为聚类中心

对数据集中的每个数据,按照距离k个中心点的距离,将其与距离最近的点关联起来,与这个点聚为一类

然后开始迭代:

每次计算一个组的平均值,将中心点移动到平均值的位置
如此反复几次中心点的位置就不再变化
如下图所示





10.3优化目标K-均值的优化目标就是最小化所有的数据点与其关联的聚类中心点之间的距离之和
因此K均值的代价函数为:

10.4随机初始化在运行k均值算法之前,需要随机初始化所有的聚类中心点
1.选择K &lt; m ,即聚类中心点的个数要小于所有训练集实例的数量
2.随机选择K个训练实例,然后令K个聚类中心等于他们
K-均值算法的一个问题在于,他可能停留在某个</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS229_2.%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/">
        <p class="h4 index-header">3.课程/CS229_2.正规方程</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">CS229—正规方程1.定义
​    正规方程(Normal Equation)是通过对训练数据/训练答案/待求参数之间的矩阵变换得到答案

正规方程求解参数矩阵的公式:

2.正规方程法和梯度下降法的对比

梯度下降的特点

要设置学习率α
多次迭代
工作地非常均衡
适合特征变量很多的时候用
要求参数归一化


正规方程法

不用设置学习率
不用迭代
需要计算
适合特征变量不超过1000时用
不要求参数归一化,如下图



有些较复杂问题不能使用正规方程法,只能使用梯度下降



</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS229_4.%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">
        <p class="h4 index-header">3.课程/CS229_4.逻辑回归</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">4.逻辑回归(logistics regression)1.逻辑回归模型
分类问题输出一个结果”正确”或者”错误”

逻辑回归模型:




当hθ(x) 在区间[0.5,1]时,预测是”正确”,越贴近1越确信
当hθ(x) 在区间[0,0.5)时,预测是”错误”,越贴近0越确信

2.逻辑回归的代价函数

简单点一句话讲:
答案是1,你预测了1,无误差
答案是1,你预测的数字离0越近误差就越大,完全是0误差就是无限大(不可能情况)
答案是0的情况与答案是1的情况同理



3.对逻辑回归的代价函数使用梯度下降算法,以得到最优参数/最优解
4.高级优化
一些建议

不需要写代码实现代价函数的迭代

从技术来讲,其实我们不需要自己手动写程序来计算刚才提到的梯度下降算法的代价函数以及其迭代过程,就像我们不需要自己手动写求平方根和创建数组一样,这些问题早都有非常成熟的库来调用


更高级的算法

除了梯度下降算法,还有共轭梯度法 BFGS (变尺度法) 和L-BFGS (限制变尺度法)这种更高级算法可调用
吴恩达本人已经使用如上提到的算法很多年了,也才是最近才搞清楚他们的内部实现细节



</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS224n_9%20-%20RNN,LSTM,GRU/">
        <p class="h4 index-header">3.课程/CS224n_9 - RNN,LSTM,GRU</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">助教分享：建立一个更好的语言模型语言模型是NLP中最经典的任务，这里有三种方式可以让其变得更好，第一是更好的输入表达，第二是更好的正则化或者预处理，第三是有更好的模型。
第一种是改进输入，例如Glove是一个词层面的表示，事实上可以把单词进一步编码为子词阶段，可以采用语素解码方式，可以采用BPE，最终也可以采用字母级的嵌入，他的作用是大大减少所用到的词汇量，让模型预测变得更简单，如下图展示的论文就是对输入端的改进。

第二种办法是采用正则化技巧，来改善过拟合的问题，有一堆论文在讲如何做正则化，今天聚焦的点是在预处理阶段，通过和计算机视觉类似的替换技巧来构建更合理的语料库，比如把频繁和罕见的词语的评率都往平均值上拉一拉，就会使得曲线更显平滑，平滑的分布能让系统获得更好的语言模型和更好的实验结果。
第三是更好的模型，etc。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS229_1.%E7%BB%AA%E8%AE%BA/">
        <p class="h4 index-header">3.课程/CS229_1.绪论</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">CS229–绪论1.监督学习和无监督学习
监督学习定义
部分数据集已经有答案.比如房价信息集,知道了正确的房价,需要预测出更多的房价
回归问题,预测连续值的输出(房价)
聚类问题,预测离散值的输出(肿瘤是良性还是恶性?)




无监督学习

无监督学习没有答案,自动聚类:比如google搜索BP油井泄露,会把CNN,ABC,BBC新闻放一起



2.线性回归算法
监督学习的典型过程

Training set –[喂食给]—&gt;Learning Algorithm –[生成]–&gt;hypothesis(假设函数)

size of house–[输入]—-&gt;hypothesis(函数)—-[输出]—-&gt;Estimate price





线性回归

预测房价的假设函数:h(x) = θ0 + θ1x
根据训练集生成一元一次方程,输入房间大小得到房价预测



3.代价函数
代价函数有利于弄清楚如何把最有可能的直线与我们的数据相拟合

最小化代价函数就可得到最好的预测函数

如何选择假设函数hypothesis “h(x) = θ0 + θ1x” 中的两个参数</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS224n_6%20-%20%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90/">
        <p class="h4 index-header">3.课程/CS224n_6 - 依存分析</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Lecture6 依存分析本节课综述

这节课主要讲句法 + 语法 + 依存分析
基于转移的依存关系分析语法
神经网络内容
TensorFlow + 实际的nlp内容例如构建神经依存关系分析器

1.依存分析的概念和一个例子句子或句子的一部分有一种结构，人们可以用特定的方式将他们组合起来，我们可以从非常简单的并不构成句子的东西入手。

一个冠词 + 名字 通常被语言学家称为名词短语



有一些规则可以用来扩展他们：比如在冠词和名词之间加一个形容词
the large cat
a beautiful dog等

你也可以在名词后边添加介词短语
the large cat in a crate
the barking dog on the table等


传统上，语言学家和自然语言处理器想做的是描述人类语言结构，人们过去有两个关键工具来做到这点，一种是上下文无关文法的方法，这种方法经常被语言学家引用为短语结构文法。我们现在要做的就是写出这些上下文无关文法的规则。

还有一种了解语言结构的不同角度，就是依存句法结构。它通过找到句子当中每一个词所依赖的部分来描述句子结构。如果一个词修饰另一</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS224n_7%20-%20Tensorflow/">
        <p class="h4 index-header">3.课程/CS224n_7 - Tensorflow</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Lecture7 TensorFlow为什么要使用深度学习框架？

有助于扩展机器学习代码
自动计算梯度（通常梯度计算并不重要，这些框架可以自动处理梯度，使得我们把重点放在更高层次的数学上）
在很多领域使机器学习更标准化
这些框架提供了GPU接口

1.TensorFlow是什么？是一个谷歌开发的深度学习框架，使用流式图进行数值计算的开源软件库。TensorFlow是用于表示机器学习算法的接口，以及用于执行这种算法的实现。
TensorFlow的一个big idea就是数值计算表示为计算图来进行。 图的节点是操作，每个节点都有一个输入和输出，节点之间的边表示他们之间流动的张量，在实践中最好的方法就是认为，张量是一个n维数组。
使用流式图作为深度学习框架主干的优点在于它允许你使用小而简单的操作建立复杂的模型，当我们这样做的时候，会使得梯度计算变得极其简单。
此框架可以自动求导，而且图方法的每一个操作都是可以在其所在点被评估的一个函数。变量将成为输出其当前值的有状态节点。
占位符是那些在执行期间才会接收值的节点，如果在你的网络中有依赖外部数据的一些输入，你并不想在建立图时依赖任何实际的值。</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS224n_8%20-%20RNN%E5%92%8C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%BC%8F/">
        <p class="h4 index-header">3.课程/CS224n_8 - RNN和语言模式</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Lecture8 RNN和语言模式本节讲简单的循环神经网络模型，这个模型家族是大多数人现在在实际训练环境中使用的。
 概览：
1.传统的语言模型
2.RNNs
3.语言模型建模来驱动循环神经网络（RNN）
4.重要的训练时的问题和技巧
​    梯度消失问题
​    梯度爆炸问题
5.用于队列处理的RNN
6.双向深度RNN
1. 传统的语言模型和现在的词向量模型对比传统语言模型中，理想情况下预测一个语序是根据前n-1个词出现的条件概率下，第n个词出现的概率。实际中这么做不可行，一个是语序有无限多个，而且计算每一个w(n)都要把之前所有的词都遍历一遍这个成本太大了。
如上条件概率公式也就是表示在词语w1出现的条件下，w2出现的概率是由在整个语料库中的count(w1,w2)/count(w1)决定的。
如果我想提高精度，将预测w1的工作加上了w2和w3.那么我就需要统计出语料库中，所有三元组三三组合出现的概率，假设物料库有10万个词，那么这个统计和存储的工作量就是10万的三次方。要求有140G的内存仅仅用来存放1260亿的记号语料库计算所有的计数。所以从内存的角度看，这种方法非常低效</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS224n_2,-%20%E6%B3%A8%E9%87%8A%E4%B9%8Bsoftmax/">
        <p class="h4 index-header">3.课程/CS224n_2,- 注释之softmax</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">softmax定义：
假如有一个数组V，Vi表示V中的第i个元素，这个元素的softmax值如下，也就是该元素的指数值和所有元素指数值之和的比值。softmax通常希望特征对概率的影响是乘性的。

softmax VS k个二元分类器：如果你在开发一个音乐分类的应用，需要对k种类型的音乐进行识别，那么是选择使用 softmax 分类器呢，还是使用 logistic 回归算法建立 k 个独立的二元分类器呢？这一选择取决于你的类别之间是否互斥，例如，如果你有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐，那么你可以假设每个训练样本只会被打上一个标签（即：一首歌只能属于这四种音乐类型的其中一种），此时你应该使用类别数 k = 4 的softmax回归。（如果在你的数据集中，有的歌曲不属于以上四类的其中任何一类，那么你可以添加一个“其他类”，并将类别数 k 设为5。）如果你的四个类别如下：人声音乐、舞曲、影视原声、流行歌曲，那么这些类别之间并不是互斥的。例如：一首歌曲可以来源于影视原声，同时也包含人声 。这种情况下，使用4个二分类的 logistic 回归分类器更为合适。这样，对于</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS224n_5%20-%20%E9%A1%B9%E7%9B%AE%E5%BB%BA%E8%AE%AE/">
        <p class="h4 index-header">3.课程/CS224n_5 - 项目建议</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Lecture5 项目建议1.一层神经网络过渡到多层神经网络
2.项目建议老师推荐的文章和会议

1.定义你的任务：
例如：summarization
2.定义数据集：
最好使用现成的数据集，因为他们已经有baselines
3.建立baseline
他可以是一个非常简单的一元线性回归，然后在你的训练数据集上计算你的评价标准，看看模型是过拟合还是欠拟合
4.选做题：自己发明新的模型
首先，你需要做好以上说的几个步骤.

然后你需要知道已经存在的模型上有哪些问题。然后你就可以设计出自己的模型。如果你想要这样做的话，你真的需要和你的导师和其他研究者保持沟通，除非你自己就是研究者并且已经获得了博士文凭。

你需要实现你的模型，然后根据你的新点子去对它快速迭代。（也许在某个位置新加一层？然后看看他起不起作用？）

那么在迭代的过程中，拥有足够多的的软件工程技能来配置高效的实验框架，从而能收集到这些结果就很重要。

建议从一个和你的真实想法比起来相对容易很多的模型做起。先把简单模型建立起来。然后逐步尝试更复杂的模型。

对于终极任务：summarization任务。

一开始你可能尝试一些非常简</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS224n_4%20-%20wordWindow%E5%92%8C%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
        <p class="h4 index-header">3.课程/CS224n_4 - wordWindow和神经网络</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Lecture4  wordWindow和神经网络1.分类背景知识对分类的直觉感受是什么？在机器学习领域，在还没有达到深度学习领域的情况下，我们通常将分类理解为简单的逻辑回归，也就是定义一个简单的决策边界。

2.窗口分类在一般的机器学习中，我们假设输入是固定的。输入X都是固定的，我们只训练参数W，也就是softmax的权值，然后计算给定输入X时输出Y的概率。
3.交叉熵我们假设正确类别的概率为1，其余的概率为0.举个例子，假设共有5个类别，正确类别是中间的第三个，那么第三个的概率为1，其他都是0.我们把理想的概率定义为p，softmax计算的概率为q，这里给出了交叉熵的定义，就是对所有类别的求和
正则化项：里边包含的参数θ如果是标准逻辑回归中的矩阵W，实际上目标函数加入这个正则化项的目的就是是为了鼓励模型中的所有权值尽可能地小。
可以假设你想要一个贝叶斯模型，你可以有一个先验的高斯分布，理想情况下这些参数的值都很小，但是如果没有这个正则化项，通常情况下你得到的模型参数会爆炸，他会越来越过拟合。如果没有正则化项，我们会专注于如何拟合我们的模型。
通常的机器学习优化就是只优化模型的参数W</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E8%AF%8D%E5%90%91%E9%87%8F_Word2vec/">
        <p class="h4 index-header">0.概念/NLP_词向量_Word2vec</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Word2Vecfrom笔记ofCS224N
这节课深入语言的底层，做一些向量和计算，这节课提到的数学是后边内容的基础。这节课将用很慢的速度来仔细讲解一些基础，以便大家可以使用神经网络来学习词语表征这样的简单任务。
1.语言学和NLP对词语释义的不同做法语言学用如下词典释义来解释“meaning”这个词的意思

the idea that is represented by a word,phrase,etc
the idea that i person wants to express by using words,signs,etc
the idea that is expressed in a work of writing,art,etc

NLP同义词描述词汇
如下图左侧，用一段代码演示nltk如何抓取wordnet中”panda“这个词的分类信息，panda是一种肉食动物，一种有胎盘的哺乳动物，再往上上溯可抽象为动物，物体，物理实体等等。
如下图右侧，抓取“good“的同义词，这里显示的就是wordnet的答案。

同义词描述词汇本义毕竟是离散的方法，会有如下的问题：

同</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/CS224n_16%20-%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8NLP%E4%B8%AD%E7%9A%84%E9%99%90%E5%88%B6/">
        <p class="h4 index-header">3.课程/CS224n_16 - 深度学习在NLP中的限制</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Lecture16 - 深度学习在NLP中的限制对于语言，如果你想要一个合适的语言系统，你可能需要一些对于输入的情感理解，在逻辑上推理某些事实，在数据库中检索一些事实，或者基于数据库中的逻辑原因，再做一些内存检索。还有一些时候，你需要对谈论的内容做一些奖励。在现实世界中这些过程是由很多不同的成分组成的。我们想要一个更好的理解语言的系统，理想情况下这个系统应该包括很多内容，以一种更科学的方式呈现。
现在联合多任务学习仍然非常困难，迄今为止，人们谈论多任务学习时，他们假设有一个源任务和一个目标任务，他们希望神经网络在源任务的预训练可以加强另一个目标任务的表现。就我而言，理想的情况是让他们共同训练，而不是分开训练不同的解码器。例如不同语言中，不同的分类问题。理想情况下，我们只有一个很大的不同种类的数据集，我们想根据输入来预测，他们有完全一样的解码器，但是很多时候人们做多任务学习的时候他们只是共享低层的参数，共同训练他们，但是不能共享高层的参数。
也就是说，在自然语言处理的过程中，我们通常只是共享了词向量，我们没有共享其他高层的比如LSTM层，这种层能解决更多的任务，其实计算机视觉在这方面有挺</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/page/4/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/6/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "暗影疾行&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
