<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/index.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_8%20-%20Speech%20Synthesis/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_8 - Speech Synthesis</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">8. Speech Synthesis - 语音合成（文字转语音）Speech Synthesis detail is as following:

本单元讲解如何将文本转换成语音，主要分成如下四个任务：

text normalization  文本标准化
phonetic analysis 语音分析（把token化的词汇转换成音标）
prosodic analysis 韵律分析( 把音标组成的集合拼凑地和谐一点)


waveform synthesis 波形合成（让拼凑好的音标们-IR转wave-发音）

8.1) Text NormalizationText normalization was combined as follwoing:

sentence tokenization
non-standard words
homograph disambiguation

8.1.1)Sentence tokenizationtokenization理解为把句子拆分成小块（token），token之间可以是被空格键分隔，也可以是被句号，逗号，或者单纯是被语义分隔，被token化</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_6%20-%20HMM%20&%20HEMM/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_6 - HMM &amp; HEMM</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">6.Hidden Markov and Maximum Entropy Models（HMM,MEMM）HMM and HEMM are both sequence classifiers.
Sequence classifier or sequence labeler is a model whose job is to assign some label or class to each unit in a sequence.The FST we studied in Chapter 3 is a kind of non-probabilisitic sequence classifier.
We have seen on important sequence classification task:POS tagging.
This chapter is roughtly divided into 2 section:HMM , MEMM.
6.1) Markov Chains - 马尔科夫链 - 详见概念6 - 马尔科夫链
6.2)The Hidden Markov Model</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_5%20-%20Part-of-Speech%20Tagging/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_5 - Part-of-Speech Tagging</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.Part-of-Speech TaggingIntroduce three algorithms:

rule-based tagging
HMM tagging
transformation-based tagging

词性标注是一项消歧任务，很多情况下词具有多于一个的意思，我们的工作是为这种情况找到正确的标签。
5.2）Tagset for EnglishThere are 3 different tagset.

45-tag Penn Treebank tagset
61-tag C5 tagset
87-tag tagset 


Small Tagset:



Middle Tagset



Large Tagset



5.3) Part-of-Speech TaggingSometimes,tagging can be difficult（unambiguous）,For example ,book is ambiguous.Book can be a noun as a read book,or be a verb, as booking a hotel.</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_4%20-%20N-Grams/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_4 - N-Grams</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">4 - N-GramsN-gram is a language model,is a N-token sequence of words.
1.the way to calculate conditional probability.For example,how can we calculate P(the|its water is so transparent that) ?
Method1): counting 2 sentences
Counting the times of “its water is so transparent that the” and “its water is so transparent that” in the whole corpus.It works sometime,but language is creative,many sentences is not exist.
 
Method2): chain rule of probability,then use method 1.

notice that:

means  P(w1w2</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_3%20-%20Word%20&%20Transducers/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_3 - Word &amp; Transducers</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">3.Word &amp; Transducers3.1)Word
Before processing, words in speech should be Stemming、lemmatization and tokenization.
Tokenization means put”New York”in one word,separate “I`m” into “I” and “am”。
Using FSA to build Stemming net of words

3.2)FST : Finite state transducers.
I define it my way:
If you input “aa”,”b”will be output,and the state in still “q0”,if you input “b”,”a or b”will out put,state will be “q1”.For example,if you input “aa aa b a”，output is “b b a ba”.

Defination with details </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_24%20-%20%E5%AF%B9%E8%AF%9Dagent/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_24 - 对话agent</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">24 - Dialogue and Conversational Agents这一章介绍问答助手的基本结构+算法。Session24.1介绍人类对话的基本概念，如对话的交替，表达技巧，grounding，对话结构等。Session24.2介绍口语系统的组件和评价标准。Session24.5和Session24.6介绍信息状态架构和马尔科夫对话代理模型，以及高阶话题如BDI范式（belief - desire -intention）信念 - 渴望 - 意图范式。
24.1 人类对话的Properties24.1.1 Turns and turn-talking人类对话的模式是一个人说完了之后另一人说，交替进行，通常情况下，两人对话的重叠部分不超过5%。两个人交替间的停顿时间在100ms左右。为了实现这种模式，人类对话通常有如下三个规律来规范交替的进行，非常显而易见。

通常一个比正常情况更长的听读怒会有额外的表达效果，如下所示一个长停顿代表了不想积极回应问题。

24.1.2 Language as Action:Speech Acts 语言是会产生后果的行动语言能对现实世界产生具体影响</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_23%20-%20QA/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_23 - QA</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">23 - Question Answering and Summarization本章介绍基于事实的回答问题系统+文章的总结系统。如果我们查找的是结构化的数据，可用上一章介绍的信息提取算法来词查找。如果查找的是非结构化的信息，则需要用本章介绍的“回答问题系统”处理，非结构化信息的查找就是一种“使用非正式的单词或句子”来表达查找需求的场景，这种场景下客户通常期望能返回一些回答or一些文本，或something in between。
第一个session介绍向量空间模型，第二个session介绍基于事实的一问一答系统。第六个session介绍基于句子的总结系统/基于注意力机制的总结系统。
23.1 Information Retrieval 信息检索术语定义
文档document指的是一个有索引的，可被检索系统直接定位的最小单元，对应到web就是一个网页
集合collection指的是一系列用来满足用户需求的文档documents
term指的是一个词汇元素。
query指的是一系列terms

词向量空间
词义相近的在向量空间中距也近，概念在CS224N中学过了。空间和点积的直观图如下</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_22%20-%20Information%20Extraction/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_22 - Information Extraction</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">22 - Information Extraction本章主要概念：

NER：命名实体识别
relation detection and classification：关系检测与分类
event detection and classification：事件检测与分类
temporal expression recognition：事件表达式识别
template filling：模板填充

22.1)NER : 命名实体识别命名实体识别分类的举例

22.1.2）NER as Sequence Labeling
标准的命名实体识别的步骤是使用word-by-word sequence labeling任务。其实进行NER的方法与第五章的POS tagging和十三章的syntactic chunking方法相同。
PS：提一下第五章的POS tagging：使用的还是HMM base 的 维特比算法（decoding）。

问题的本质如下所示，观察到句子/词语，猜测对应的词性/NER类型。也就是观察到结果，猜测其隐状态。


具体的 word-by-word IOB-style t</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_2%20-%20Regular%20expressions%20and%20automata/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_2 - Regular expressions and automata</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2 - Regular expressions and automata2.2) Relationship between FSA and RE
Any regular expression(RE) can be implemented as a finite state automata(FSA),symmetrically,any finite-state automata can be described with a regular expression.
Both RE and FSA can be used to describe regular languages:

Using FSA to understand sheep talk
sheep language can be defined as any string from the following set:
baa!
baaaa!
baaaaa!
baaaaaa!
baaaaaaa!
baaaaaaaa!
baaaaaaaaa!
…
Sheep language can be described as fol</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_11%20-%20Computational%20Phonology/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_11 - Computational Phonology</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">11. Computational Phonology本章较艰涩，对NLP发文帮助不大，Skip，以后需用再补。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_12%20-%2016,17%20-%2021%E8%AF%AD%E6%B3%95%E5%AD%A6%EF%BC%8C%E8%AF%AD%E4%B9%89%E8%AF%AD%E7%94%A8%E5%AD%A6/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_12 - 16,17 - 21语法学，语义语用学</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">12 - 16语法学，17 - 21语义语用学以上几章主要侧重于对英语这门语言本身的讲解，对发表论文帮助不大。先跳过，回头需用再补。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_10%20-%20Automatic%20Speech%20RecongnitionAdvanced%20Topics/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_10 - Automatic Speech RecongnitionAdvanced Topics</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">10. Auto Speech Recognition Advanced Topic ：语音转文字进阶话题之前企图对输入的语音转换成音素的处理办法是：构建一个由全体语言组成的HMM状态网络，然后在网络中采用维特比算法进行全局搜索。这种算法太expensive了。
改进思路是采用多路编码的decoding技术，使用新的上下文相关声学模型(triphone)。本章还会介绍判别训练(discriminative training)和模型的一些变体；
10.1）多路编码decoding : N-Best List and Lattices
首先，维特比算法在进行对语音输入的decoding的时候，有如下两个问题：

在应对一词多音/一音多词的语言时，维特比算法表现很差
维特比算法很难take advantage of 复杂的语言模型：2-gram还行，3-gram就不行了。因为3-gram violates the dynamic programming invariant

改进如上两个问题的思路有：

改进维特比算法，将原本只返回单一值，变成返回多值。以改进一词多音的问题。
使用其他的的d</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_%E7%88%AC%E8%99%AB/">
        <p class="h4 index-header">0.概念/技术_爬虫</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">爬虫目的:掌握定向网络数据爬取和网页解析的基本能力
传达的理念:website is the API
基本内容介绍

request库  自动爬取HTML页面,自动网络请求提交
robots.txt  网络爬虫排除标准
Beautiful Soup解析HTML页面
实战项目
正则表达式
Scrapy专业爬虫框架

1.Request库
安装request:pip install requests
import requestsr = requests.get(“http://www.baidu.com&quot;)r.status_code
r.encoding = ‘utf-8’r.text

Request库的七个主要方法

requests.request()    构造请求,支撑如下方法的基础方法
requests.get()              获取HTML的主要方法,对应HTTP的GET
requests.head()          获取HTML的网页头信息
requests.post()            向HTML网页提交POST请求
requests.p</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_1%20-%20Introdution/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_1 - Introdution</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.Introduction1.1) Required knowledge for NLP:

Phonetics and Phonology : knowledge about linguistic sounds
Morphology : knowledge of meaningful components of words
Syntax :knowledge of the structural relationships between words
Pragmatics :knowledge of the relationship of meaning to the goals and intentions of speaker(what is )
Semantics :knowledge of meaning(what is said)
Discourse : knowledge about linguistic units larger than a single utterance

1.2) Key task : Disambiguation at variety leve</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E8%AF%BE%E9%A2%98%E7%BB%84%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/">
        <p class="h4 index-header">1.科研/课题组信息搜集</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">NLP课题组信息搜集20191218作者：cstghitpku
链接：https://zhuanlan.zhihu.com/p/48529628
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
根据这几年的积累，整理了一份国内外学术界和工业界的牛人和大牛团队，供大家申请硕士、博士、博士后和找工作参考。
学校（排名不分先后）：
哈工大社会计算与信息检索实验室：刘挺老师坐镇，教师包括：秦兵、张宇、车万翔、赵妍妍、刘铭、张伟男、丁效等老师，实验室共7个组，另外王海峰老师也是实验室兼职博导。
哈工大智能技术与自然语言处理实验室：王晓龙老师坐镇，教师包括刘秉权、刘远超、孙承杰等老师
哈工大机器智能与翻译研究室：赵铁军老师坐镇，教师包括杨沐昀、郑德权、徐冰老师等，另外周明老师是实验室兼职博导。
哈工大深圳智能计算研究中心：王晓龙老师坐镇，包括陈清才、汤步洲、徐睿峰、刘滨等老师，实力很强。
哈工大深圳人类语言技术组：徐睿峰老师坐镇，情感原因发现做的比较好。
哈工大另外做NLP的老师包括：关毅、王轩等。
清华大学自然语言处理与社会人文计算实验室：孙茂松老师坐镇，包括刘</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/4.%E5%AE%89%E8%A3%85%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/%E4%BF%AE%E6%94%B9conda%E6%BA%90_%E4%B8%8B%E8%BD%BD%E9%97%AE%E9%A2%98/">
        <p class="h4 index-header">4.安装调试记录/修改conda源_下载问题</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">首次改为国内源：打开cmd
conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forgeconda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forg</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E8%AF%AD%E8%A8%80%E5%AD%A6%E8%8D%90%E4%B9%A6/">
        <p class="h4 index-header">1.科研/语言学荐书</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">语言学方向书籍推荐–Serena Gao首先，做nlp不一定要很懂语言学，也不一定要跟语言学扯上关系。nlp可以仅是data mining，features engineering, 也的确有很多work目前在用文本或者对话做为数据集，然后用统计学方法实现目的，比如deep learning 。在某些任务上统计学模型功不可没，比如machine translation, speech recognition, question answering, etc. 
如果题主只是对nlp的应用感兴趣，想泛泛了解一下目前进展的话，以上几个回答已经非常详细了，我接下来的回答可以不用看。许多主流大公司目前的力度都在deep learning, 学好nlp基本知识，做工程就够了(当然你还需要cs的background)， 语言学的东西不用太深入研究。
————————————-3.17 update——————————-
看了一下其他答案，大家的讨论和见解都很有趣，上来更新一点。
大多数人对nlp和语言学联系的了解，在于认为rule-based的nlp就是基于语言学。的确rule-based是语言学</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%9B%86%5BDone%5D/">
        <p class="h4 index-header">1.科研/深度学习论文集[Done]</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1 深度学习历史和基础1.0 书籍█[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. “Deep learning.” An MIT Press book. (2015). [pdf] (Ian Goodfellow 等大牛所著的教科书，乃深度学习圣经。你可以同时研习这本书以及以下论文) ★★★★★
地址：https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf
1.1 调查█[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. [pdf] (三巨头做的调查)  ★★★★★
地址：http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf
1.2 深度置信网络 (DBN，深度学习前夜的里程碑)█[2] Hinto</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/WebScience%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/">
        <p class="h4 index-header">1.科研/WebScience讲座笔记</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Web Science讲座笔记
写论文步骤
在感兴趣的方向提出问题和假设
验证前人是否已经做过？
设计实验
做实验,收集数据
写论文


开题案例
案例:人工智能
阅读中科院，工程院前沿报告,阅读各种综述，阅读下文专项报告
两个月更新一次:ESI Reaserach front专项报告
在web产品里找到,网页右边可以关键词聚类
AI子课题:自然语言处理,主页可显示高被引用论文(数据结构网络的核心)
能顺便找到本学科的raising star

在web science里写检索式,如何寻找文章引用网络
https://www.clarivate.com.cn/e-clarivate/wos_video_wos_research.htm



如何在上行的检索之后筛选自己需要的信息?(上个结果返回30w+文章)

检索结果:
这个功能能找到哪些基金在资助哪些项目
哪些导师在做,找导师/合伙人利器

分析机构:
能找到哪些机构近几年发表了哪些文章

分析机构中的作者








几个产品按钮
在网页上方有个文章被引用次数的功能,发布在哪个期刊



左侧功能栏:
review是学科综述</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/4%20-%20%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1/">
        <p class="h4 index-header">1.科研/4 - 模型设计</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">模型设计确定进入____领域后，如何快速学会第一个技能？仔细研究一般现有的主要工具，流派和方法，先入门。我的建议是：找到一个开源项目，比如机器翻译或者深度学习的项目。理解开源项目的任务，编译通过该项目发布的示范程序，得到与项目示范程序一致的结果。然后再深入理解开源项目示范程序的算法。自己编程实现一下这个示范程序的算法。再按照项目提供的标准测试集测试自己实现的程序。如果输出的结果与项目中出现的结果不一致，就要仔细查验自己的程序，反复修改，直到结果与示范程序基本一致。如果还是不行，就大胆给项目的作者写信请教。在此基础上，再看看自己能否进一步完善算法或者实现，取得比示范程序更好的结果。
如何改进别人的模型
反复阅读本领域最新发表的文章，多阅读本领域牛人发表的文章。在深入了解已有工作的基础上，探讨还有没有一些地方可以推翻、改进、综合、迁移。注意做实验的时候，不要贪多，每次实验只需要验证一个想法。

每次实验之后必须要进行分析存在的错误，找出原因。



对成功的实验，进一步探讨如何改进算法。注意实验数据必须是业界公认的数据。
与已有的算法进行比较，体会能够得出比较一般性的结论。如果有，则去写一</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/7%20-%20%E8%AE%BA%E6%96%87%E7%BB%93%E6%9E%84/">
        <p class="h4 index-header">1.科研/7 - 论文结构</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.论文结构学术研究是一项系统工程
在这个系统工程中，论文的作用则是，向学术界同行清晰准确地描述成果的创新点、技术思路、算法细节和验证结果。明白这一点，才能正确的对待论文写作：一项乏善可陈的工作，很难通过写作变得众星捧月；一项充满创新的成果，却有可能因为糟糕的写作而无法向审稿人准确传递重要价值所在，延误成果发表。


一篇NLP论文的典型结构
NLP学术会议（甚至包括期刊）论文已经形成比较固定的结构。绝大部分论文由以下六大部分构成：摘要（Abstract）、介绍（Introduction）、相关工作（Related Work）、方法（Method）、实验（Experiment）、结论（Conclusion）。少数论文会根据创新成果形式不同而略有不同，例如提出新数据集的论文，可能会把Method部分调整为Dataset的标注与分析，但不影响论文整体构成。每个部分作用不同：

摘要：用100-200词简介研究任务与挑战、解决思路与方法、实验效果与结论。
介绍：用1页左右篇幅，比摘要更详细地介绍研究任务、已有方法、主要挑战、解决思路、具体方法、实验结果。
相关工作：用0.5-1页左右篇幅介绍</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/3%20-%20%E9%80%89%E9%A2%98/">
        <p class="h4 index-header">1.科研/3 - 选题</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">论文选题
经过调研，已对本领域有基本认识，具备了得到idea的条件。
idea要新颖，要能推动科学的发展，同时要有可复现性和可实现性。
把握好与现存结果之间的delta
要因时而动，像语音识别和人脸识别这种已经落地的项目，可能已经没有什么突破的空间了，现在在业界拼的是数据和算力。而常识，知识推理，复杂语境，跨模态理解，可解释智能。这些点目测不能通过数据驱动的方式解决。更高层次的联想、创造、顿悟等认知能力，更是连边还没碰到。这些问题是有远见的研究者应该关注的方向。

补全了相关知识，阅读了大量的文献，走访了各位前辈，观察了各圈风向标，调整首文合理预期后，
我的idea是：_____.
建议2：如何选择第一个好题目？
什么算是好的idea作者：刘知远 
2015年，我在微博上写过一个调侃的小段子：

ML派坐落美利坚合众山中，百年来武学奇才辈出，隐然成江湖第一大名门正派，门内有三套入门武功，曰：图模型加圈，神经网加层，优化目标加正则。有童谣为证：熟练ML入门功，不会作文也会诌。

到了2018年，我又续了一小段：

不期数年，北方DL神教异军突起，内修表示学习，外练神经网络，心法众多，曰门</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/2%20-%20%E8%AE%A1%E5%88%92/">
        <p class="h4 index-header">1.科研/2 - 计划</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">计划比赛 -  改进模型 - 得奖 - 阅读论文 - 写作论文
比赛得奖同时也是进入行业的必要条件
进入行业是了解行业和理解科研的必要条件
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/1%20-%20B%E5%AD%A6%E7%A7%91%E8%B0%83%E7%A0%94%E7%BB%93%E8%AE%BA/">
        <p class="h4 index-header">1.科研/1 - B学科调研结论</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.学科调研结论简要结论经过对上文阅读列表+论文库的调研，得出如下结论，可以开始选题。

近年来,我感兴趣的关于_____的研究方向,全球呈现__趋势,其中较多的论文来自\国家\地区,发表相关论文的研究机构有___.蓝海领域比较新，容易出成果，我选择的这个方向是否是蓝海领域_____.
为了充分了解这个领域目前的发展状况，需要如下几个方面的调研：方法方面，是否有一套比较清晰的数学体系和机器学习体系_；数据方面，有没有一个大家公认的标准训练集和测试集__；研究团队，是否有著名团队和人士参加___。如果以上几个方面的调研结论不是太清晰，作为初学者可能不要轻易进入。
全球的研究人员主要从____等领域对课题进行研究,同时我们也注意到___等领域的研究可能会给我们带来不一样的视角和灵感
相关课题的研究成果目前主要发表在____等期刊上,在相关研究领域中,_____等几位学者有较多的论文产出.
影响力较高的几篇论文分别来自于___(国家/地区)的_(机构)的___学者
近半年来___方向引起了较多科研人员的关注
选择____综述文章作为快速了解这个课题的切入点
最新的研究进展指出,该研究方向__</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/1%20-%20A%E5%AD%A6%E7%A7%91%E8%B0%83%E7%A0%94%E8%B5%84%E6%96%99%E5%BA%93/">
        <p class="h4 index-header">1.科研/1 - A学科调研资料库</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.阅读列表+文献库想当GrandMaster，以下提到的所有材料都绕不过去。在还没入行时间紧迫的情况下，须有所取舍。具体取舍规则办法见2 - 计划.md
阅读列表







CS224N - 自然语言处理



CS229 - 机器学习（核心课）



CS229A - 机器学习应用课，数学少，应用多



CS231N - 计算机视觉



CS230 - 专注深度学习，只包含一点点机器学习（which最难的那一部分）



CS221 - AI导论



CS228 - 概率图模型



机器之心



PaperWeekly



NeurIPS 2019公布获奖论文



深度学习所需数学知识



EE转CS成功案例



Jeff Dean谈2020机器学习趋势



从Word2Vec到BERT    done



kaggle竞赛宝典



NIPS2019



斯坦福2019全球AI报告



2020学术会议list



因果推演



ACL2019知识图谱总结



概率论与数理统计



线性代数



高等数学



优化理论



Bubeck</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_Git/">
        <p class="h4 index-header">0.概念/技术_Git</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Git1.四个区域Workplace : 工作区，自己的电脑存放代码的地方
Index，Stage ： 暂存区，存放临时的改动，事实上它是一个文件，保存即将提交到文件列表的信息
Repository  :  仓库区（版本库），存放数据的地方，有所有提交版本的地方，其中head指向最新放入仓库的版本
Remote ：远程仓库，托管代码的服务器，可以简单理解为项目组的一台用于远程数据交换的电脑
四者关系如下

2.常用命令常用
# 本地推至暂存区
git add .
# 删除暂存区/分支，但本地保留文件（不被版本控制）
git rm --cached file_path
# 为本地代码切换版本
git checkout
# 暂存区代码推至版本库
git commit -m &quot;提交说明&quot;
# 移除暂存区文件
git reset HEAD 文件名
# 去掉上次的提交(变成add前状态)
git reset HEAD^
# 去掉上次的提交(变成commit前状态)
git reset --soft HEAD^
# 显示当前git配置
git config --lsit
# 编</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/0%20-%20%E6%80%BB%E4%BD%93%E6%80%9D%E8%B7%AF/">
        <p class="h4 index-header">1.科研/0 - 总体思路</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">0 - 总体思路
基础 ： Speech and Language Processing（完成）
早年经典NLP论文：遍历论文库（进行中）
了解机器学习的基本模型：
CS229（完成）
Pattern Recognition and Machine Learning


了解NLP其他子领域(MT,信息抽取,parsing,tagging,情感分析,MRC等)（进行中）
了解CV和数据挖掘领域的进展


学科调研：构建阅读列表和论文库；读近五年survey，近三年顶会，感兴趣方向热门论文和经典书单；输出互引DAG图，输出专有名词词典，输出调研文档。

   *构建文献库时遇到的困难：flood。目前资料：知识图谱80 + 深度学习100 + 生物医学CRF70 + ACL660 = 910篇论文，以及7本大部头。这还不包括所谓的5年survery100 + 三年顶会3000共约3100篇论文。 *
   我需要的：迅速了解整个学科发展大致现状，选择自己感兴趣的+有前途做的人少的领域迅速构建论文库精读切入
   初步解决方案：控制工作量，看优质survey，大部头只挑一本看，其余当工具书</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/4.%E5%AE%89%E8%A3%85%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/%E5%BF%AB%E6%8D%B7%E9%94%AE/">
        <p class="h4 index-header">4.安装调试记录/快捷键</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">PyCharmCTRL + -  = 折叠本行 
CTRL + + = 打开本行
CTRL + SHIFT + -  = 全部折叠
CTRL + SHIFT + + = 全部打开
ChromeCTRL + SHIFT + N = 打开匿名窗口
CTRL + SHIFT + I =  检查
CTRL + W  = 关闭当前标签页
CTRL + fn  + PgUp/PgDn = 上翻/下翻当前标签页
IDEACTRL + SHIFT + F12 =  编程窗口最大化
CTRL + SHIFT+ N = 查找文件
SHIFT + F6 = 全局替换
CTRL + ALT + L = 格式化代码
CTRL + ALT + V =快速赋值
Cookie[] cookeis数组遍历便捷写法  = cookies.for = for(Cookie cookie : cookies)
SHIFT + F6  = 文件重命名
CTRL + SHIFT + C = 拷贝文件路径
CTRL + D = 拷贝一行
SHIFT + ENTER = 换行
CTRL + P = 查看参数
CTRL + N = 查</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_5.%E7%B4%A2%E5%BC%95,%E8%B0%83%E4%BC%98/">
        <p class="h4 index-header">0.文章/Java_5.索引,调优</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.sql索引,调优索引相关概念

索引原理
DBMS索引一般用b tree或者b+tree实现



带主键的数据库表的存储结构(正常查找)

构建索引后从非聚集索引直接查找

Sql语句执行流程
create index index_birthday on user_info(birthday)   //构建索引
select user_name from user_info where birthday = ‘1991-01-01’      //正常查找数据
create index index_birthday_and_user_name on user_info(birthday,user_name);   //构建双字段的覆盖索引



</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_6.jetty%E5%92%8Ctomcat/">
        <p class="h4 index-header">0.文章/Java_6.jetty和tomcat</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.jetty和tomcat1.Jetty是什么
​    jetty是一个开源的HTTP服务器和Servlet引擎,可以为JSP和Servlet提供运行时环境,相对与Tomcat,,jetty更加轻量级,更加简易和灵活
2.jetty特点

异步,支持更高的并发量
灵活,更加轻量,更容易定制,更高的资源利用率
Jetty采用默认的NIO模型,jetty很好地支持长链接

3.应用场景

企业级应用tomcat占据了绝对优势
jetty默认使用NIO,在轻量级的,保持长连接的场景下使用很有优势,比如客服的聊天

4.jetty原理

提供了两种handlder
handlerWrapper
可以将一个Handler委托给另一个类执行,将handler加载到jetty中就是通过handler委托给server执行的


handlerCollection
将多个handler组装成handler链,可以方便地做扩展





2.tomcat
为了服务器生成动态页面,需要运行java Servlet,那么就需要提供Servlet容器
Tomcat正式支持运行Servlet/JSP应用程序</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_7.%E5%8F%8D%E5%B0%84/">
        <p class="h4 index-header">0.文章/Java_7.反射</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">反射
反射的定义

行状态中,能知道任何一个类的属性和方法
能调用任何一个对象的属性和方法
这种动态获取信息以及动态调用对象方法的功能称谓java的反射机制


反射的用途

第三方应用开发时,会遇到某个类的变量或方法是私有的,只对系统应用开放,这时候就利用java的反射机制通过反射来获取所需要的私有成员或者方法.


反射的相关类


class类





</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_2.ClassLoader/">
        <p class="h4 index-header">0.文章/Java_2.ClassLoader</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2.ClassLoader类加载器classloader作用:

负责将class加载到JVM中
审查每个类由谁加载
将class字节码重新编译成JVM统一要求的对象格式

2.1类加载时机与过程类从被加载到虚拟机内存开始,到卸载出内存为止,整个生命周期包括了七个部分:
加载,验证,准备,解析,初始化,使用,卸载

如下几种情况会对类进行初始化

创建类的实例
对类进行反射调用
当初始化类,发现父类没有没初始化
jvm启动,用户指定一个要执行的主类,虚拟机会先初始化这个主类
java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic,REF_putstatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。

2.2类加载器的双亲委派模型

双亲委派模型好处

避免重复加载,当父类已经加载了该类的时候,就没有必要classloader再加载一次考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_3.%E6%B3%9B%E5%9E%8B/">
        <p class="h4 index-header">0.文章/Java_3.泛型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">泛型泛型就是扩展了方法的适用范围:
例子:
原本有一个SUM(y) = (a + b)的两元素相加的方法

在两数字相加或两字符串拼接的场景下本来都可以用它

但是如果y提前规定了数据类型就不能用了,两个场景必有其一要重写

这时候使用泛型,&lt;T&gt;当做占位符,就可以实现代码复用了 


之所以不用Object实现参数的任意化是因为要做显式的强制转换,这种转换是要求开发者对实际参数可预知的情况下进行的,而很多时候开发者不能预知程序运行时有哪样的类型需要强转
如果强转错误,程序员也无从得知,是一个安全隐患
引入泛型不用object后所有任意化的参数类型都是隐式自动进行的,保证了效率和安全性
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_4.%E8%A1%A8%E9%93%BE%E6%8E%A5/">
        <p class="h4 index-header">0.文章/Java_4.表链接</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.表链接5.1外链接外链接就是A B两个表,以左右链接的方式选择一个主表,然后附表加入主表的过程
AB两个表的图示


左外链接

select * from TableA left join TableB on TableA.id=TableB.id






右外链接

select * from TableA right join TableB on TableA.id=TableB.id






全外链接

select * from TableA full join TableB on TableA.id=TableB.id




内链接

select * from TableA JOIN TableB on TableA.id=TableB.id
结果是只链接两者共有的数据






交叉链接

select * from TableA cross join TableB

结果是两个表以基础序号为乘积的笛卡尔积的排列





</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%92%8C%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">
        <p class="h4 index-header">0.概念/NLP_知识图谱和推荐系统</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.知识图谱知识图谱是语义网络semantic network的知识库，可理解为理解为多关系图，多关系图一般包含多种类型的节点和边。
知识图谱的场景

社交网络，人和公司都可以是实体，人是节点，公司是节点的集合，人与人之间的关系是边，边可以是朋友也可是同事等，关系可以是单向也可以是双向的

数据库是结构化数据，网页是非结构化数据，处理非结构化数据是信息抽取的难点。
四个难点

实体命名识别  
关系抽取()
实体统一(武汉,江城)
指代消解  (it)

知识图谱的存储方式
RDF

存储三元组(triple)
推理引擎
W3C标准
易于发布数据,多为学术界场景

2.推荐系统评分预测:系统预测用户对电影的评分,根据此给用户推荐,这种是显示反馈
还有一种是点击率预测,新闻类应用中,根据用户点击某概率来优化推荐方案,这种场景下用户反馈信息的行为特征,而不能反映用户的喜爱成都,这是隐式反馈
传统的推系统只能使用用户和物品的历史交互信息,作为输入,有两个问题:
用户和物品之间的交互信息是非常稀疏的,几万个电影只看了几个可能过拟合,
或者新用户没有看过电影,这问题也叫冷启动问题
解决冷启动问题</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_Docker/">
        <p class="h4 index-header">0.概念/技术_Docker</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">DockerDocker是个虚拟机，主要运行在linux上，和VMware Workstation Pro有很多相似的地方。

镜像，是创建虚拟机之前需要下载的系统镜像文件，比如iso和img文件等
容器，是正在运行中的虚拟机
tar文件，就是镜像的压缩文件，压缩传送解压缩安装
dockerfile，配置文件，写完后通过docker bulid指令将dockerfile构建成一个镜像
仓库，类似于github，和镜像是pull和push的关系，里边有做好的ubuntu，mysql，tomcat镜像等

基本操作安装docker
docker pull nginx : 从仓库下载nginx
docker images : 查看本地镜像
docker run -d -p 80:80 nginx 后台将镜像运行为容器nginx，端口映射80-80
docker ps查看正在运行的容器有哪些，例如它会输出正在运行的容器是nginx，id是92a68b3fe02e
docker exec -it 92,进入运行的id开头是92的容器
cd /usr/share/nginx/html/,进入ngi</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_1.JVM,%E6%96%B9%E6%B3%95%E5%8C%BA,%E5%A0%86/">
        <p class="h4 index-header">0.文章/Java_1.JVM,方法区,堆</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">JVM
JAVA虚拟机的生命周期
java虚拟机用于执行java程序,一个java程序对应一个虚拟机
java虚拟机总是开始于一个main方法,返回void,接受一个args[]参数
main()方法是程序的起点,他被执行的线程初始化为程序的初始线程
java中的线程分两种
守护线程daemon:java虚拟机自己使用的,比如垃圾回收
非守护线程:non-daemon:包含main()方法的初始线程不是守护线程






运行时数据区域


1.程序计数器
内存空间小,线程私有,字节码解释器就是依赖程序计数器工作的:改变计数器的值来选取下一条需要执行的指令,分支,循环,跳转,异常处理等.
如果线程正在执行一个java方法,这个计数器就记录正在执行的虚拟机字节码地址.
如果这个方法是native方法,则计数器的值为underfined


程序计数器这个区域是java虚拟机中唯一没有规定任何OutOfMemoryError情况的区域


2.java虚拟机栈
线程私有,生命周期和线程一致
线程(thread)
是操作系统能够进行运算调度的最小单位
被包含在进程中,是进程的实际运作单位
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_D3NER/">
        <p class="h4 index-header">0.概念/NLP_D3NER</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">D3NER:biomedical named entity recognition using CRF-biLSTM improved with fine-tuned embedding of various linguistic information找有代码的论文读，复现作者的工作
1.标题D3NER:一种使用[被精细调整过”多种语言信息embedding”所提升性能的条件随机场-双向长短时记忆网络]的生物医学命名实体识别工具

embedding

CRF

biLSTM
均另起文章讨论


2.abstract2.1Motivation
生物医学命名实体识别技术,是从生物医学文本信息(unstructured text)中提取知识的先决条件,最近LSTM网络被应用到这个问题上,表现很好,不过我们有更改进的地方.
2.2Result
我们使用D3NER,一种使用了CRF+biLSTM网络+精调语言信息embedding的生物医学命名实体识别技术
D3NER和同方向的七种实体识别技术做了充分对比,结论是性能确实有提高
3.Introduction
特征工程做NER
Named En</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_CRF%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/">
        <p class="h4 index-header">0.概念/NLP_CRF条件随机场</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">条件随机场
概率统计图概览


马尔科夫假设/马尔科夫性

马尔科夫假设
马尔科夫链  里的  总是只受  一个人的影响。马尔科夫假设这里相当于就是个2-gram。
马尔科夫过程
在一个过程中，每个状态的转移只依赖于前n个状态




马尔科夫性
马尔科夫性是保证或者判断概率图是否为概率无向图的条件
成对性
局部性
全局性






条件随机场定义

条件随机场是在给定的随机变量 （具体，对应观测序列  ）条件下，随机变量  （具体，对应隐状态序列  的马尔科夫随机场。
广义的CRF的定义是： 满足  的马尔科夫随机场叫做条件随机场（CRF）
条件随机场是一种特殊的马尔科夫随机场
马尔科夫随机场
首先我们有无向图G=(V,E)， 图G中每个节点v上都有一个随机变量y，这样所有的节点上的随机变量就构成一组随机变量Y，图G上有联合概率分布P(Y)。边e表示相邻节点的变量存在某种神秘的联系。
图G上的随机变量Y满足马尔科夫性，即两个不相邻的节点上的随机变量yi，yj条件独立。这就是马尔科夫随机场。




CRF建模公式


CRF特征函数











</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E8%AF%8D%E5%90%91%E9%87%8F_n-gram/">
        <p class="h4 index-header">0.概念/NLP_词向量_n-gram</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">n-gram语言模型1.Statistical Language Model
在自然语言处理中的一个基本问题,如何计算一段文本序列在某某种语言下出现的概率?
例子

我经常会去图书馆＿＿＿？
预测该句后面的词，我们通常会根据已有的语料的上下文，来统计预测这句话可以填某个词汇的概率，将最大的概率作为结果返回


机器翻译中,I like  Tomc so much,将单词逐个翻译—-{我,喜欢,汤姆,非常},这个集合中的字词排列组合成句子,然后用语言模型去计算组成句子概率的大小,概率越大越流畅

2.n-gram语言模型
理解:
n-gram语言模型的思想,可以追溯到香农的问题:给定一串字母,比如”for ex”,下一个最可能出现的字母是什么?从训练语料中,我们可以通过极大似然估计的方法,得到N个概率分布,是”a”的概率是0.4,是”b”的概率是0.0001,是c的概率是….,and 别忘记约束条件:所有N个概率的分布总和为1
如下图,运用条件概率和乘法公式推倒:
直接这么计算比较困难,需要引入马尔科夫假设,即,一个item的出现,只与前m个items有关,m = 0时,就是unigra</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/page/4/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/6/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "暗影疾行&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
