<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/index.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/15/0.%E6%A6%82%E5%BF%B5/NLP_%E8%AF%8D%E5%90%91%E9%87%8F_Word_embedding%E8%AF%A6%E8%A7%A3/">
        <p class="h4 index-header">0.概念/NLP_词向量_Word_embedding详解</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Word_embedding之前词语数字化表示的几种思路和问题，以及WE的提出：

独热码离散表示：红橙黄绿青蓝紫大卡车和红橙黄绿青蓝紫中卡车是2 * 7 = 14个对象


构建特征的分布式表示：红橙黄绿青蓝紫大卡车和红橙黄绿青蓝紫中卡车是7 + 2 = 9个对象




邻接词的分布式表示：


离散表示太稀疏，使用一个词附近的词分布式表示是不错的折中方案。
WE的概念图（同义相近）：

WE的目标：把单词转换为数字（向量）。
这种转换是必要的，因为深度神经网络等技术都只能处理连续值的向量，不能处理文本和字符串。
把单词变成向量还有如下两个好处：

降维：更高效的表示方法
上下文相似性：更有表达力的表示方法

词向量的训练方法:
使用语料库和模型训练词向量，把嵌入矩阵embedding matrix当成模型参数的一部分，通过词语词之间的共现矩阵或者上下文关系来优化模型参数，最终得到的矩阵就是所有词的词向量。最初的词向量都是随机初始化的，后边采用标准训练和优化。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-15&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Word_Embedding">Word_Embedding</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/14/0.%E6%A6%82%E5%BF%B5/NLP_%E8%AF%8D%E5%90%91%E9%87%8F_SkipGram/">
        <p class="h4 index-header">0.概念/NLP_词向量_SkipGram</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">skip-gram算法详解Skip-gram算法是word2vec模型中两大生成词向量算法中的一个。
生成词汇向量的skip-gram算法的中心思想：给定中心词汇，预测单词们出现在它周围的概率，最终确定的这些单词们，要使概率分布值最大化。
如下，中心词是banking，Skip - gram会尝试去预测它一定范围内（m window）的上下文词汇。

Skip-gram的损失函数损失函数J`(θ)表示的是：一串很长的文本比如整个维基百科（which has足够长的词汇序列和足够多的词汇和真正的行文）然后遍历文本中的所有位置，对于每个位置，我们都会定义一个围绕输入词汇的大小为2m的窗口，窗口包括前后各m个单词，把每个词汇和周围的窗口的p(周围每一个词|中心词)都连乘起来。
这就是一个有监督学习，目标是使损失函数最小化，手段是通过对训练集的training动态调整模型的超参数们(窗口大小，容差系数等).

损失函数plus : 计算机中大量连乘容易误差累计和误差消失，给上边的损失函数整体套上log，将连乘转换为带log的连加。如下
要不是高中学的明白根本肝不到这里……answer the </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-14&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F">词向量</a>&nbsp;
          
            <a href="/tags/SkipGram">SkipGram</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/13/0.%E6%96%87%E7%AB%A0/NLP_word2vec%E5%BA%94%E7%94%A8/">
        <p class="h4 index-header">0.文章/NLP_word2vec应用</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">word2vec应用读取数据import pandas as pd

# Read data from files 
train = pd.read_csv( &quot;labeledTrainData.tsv&quot;, header=0, 
 delimiter=&quot;\t&quot;, quoting=3 )
test = pd.read_csv( &quot;testData.tsv&quot;, header=0, delimiter=&quot;\t&quot;, quoting=3 )
unlabeled_train = pd.read_csv( &quot;unlabeledTrainData.tsv&quot;, header=0, 
 delimiter=&quot;\t&quot;, quoting=3 )

# Verify the number of reviews that were read (100,000 in total)
print (&quot;Read %d labeled train reviews, %d labeled test</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-13&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%96%87%E7%AB%A0">文章</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Word2vec">Word2vec</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/12/0.%E6%A6%82%E5%BF%B5/NLP_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/">
        <p class="h4 index-header">0.概念/NLP_神经网络和反向传播算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">神经网络神经网络深入学习的网站：neuralnetworksanddeeplearning.com 
神经网络就是一个函数，本例中有764个输入，有10个输出 
总览图:
第一层(764)：
764个输入源于28 * 28的正方形格子，每个小格子都是0到1之间的值，越接近1就越白，越接近0就越黑。
隐藏层
隐藏层是干什么的？ 大体上说，隐藏层用于发掘模式。如上所示，隐藏层一识别小线段，隐藏层二识别小线段构成层的圈或者大线段
从这里看出深度神经网络其实就是模式识别的高级应用，所以要恶补pattern recognition。
如何训练神经网络？ 训练神经网络就是把训练集中的数据和label在神经网络中的(784 * 16 + 16 * 16 + 16 * 10) + (16+16+10) =13002    个参数通过动态调整来拟合。
从数学上来说，动态调整13002个参数以获得min(代价函数)的做法，本质上就是寻找函数的最小值，如下

w1和a1： 
a1就是输入的784个点中第一个点的亮暗情况
w1就是接受这第一个点a1刺激的第一层的第一个神经元对第二层的如图所示的神经元的兴奋程度</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-12&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">神经网络</a>&nbsp;
          
            <a href="/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95">反向传播算法</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/12/0.%E6%A6%82%E5%BF%B5/NLP_%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/">
        <p class="h4 index-header">0.概念/NLP_随机森林</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">随机森林随机森林就是用随机的方法建立一堆决策树。每棵树之间是没有关联的，当一个待分类样本输入森林中时，将此样本输入进每一个决策树然后看哪种分类结果最多，就最终输出哪种分类结果。
随机森林的构造过程：

假设有N个样本，有放回的随机选择N个样本，然后按照这N个样本训练一个决策树，这N个样本就是决策树根节点的样本
当每个样本有M个属性时，就需要在决策树中分裂节点以做进一步的判断。于是从M中随机选出m个(m &lt;&lt; M)个属性，然后从m个属性中采取某种策略（比如min信息熵）来选择一个属性来作为该节点的分裂属性。
然后就是重复上边的步骤。当下一次分裂选出来的属性还是父节点的属性时，说明已经穷尽属性，到达叶子节点。

按照如上三个步骤，可以构造大量决策树，例如movie sentiment tutor step1中的随机森林就是构造了100颗决策树。
注意：随机森林中的决策树并没有为了回避过拟合问题而剪枝，因为随机采样已经避免了过拟合。
此算法优点：

数据上表现好，两个随机性的引入避免了过拟合问题
抗噪声
能处理高维度数据，而且不用做特征选择。
对数据集的适应能力强，既能处理连续性</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-12&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97">随机森林</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/12/0.%E6%A6%82%E5%BF%B5/NLP_%E5%86%B3%E7%AD%96%E6%A0%91/">
        <p class="h4 index-header">0.概念/NLP_决策树</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">决策树决策树是一种树形结构分类器。每个节点都有一个表示属性的判断，每个分支都代表了一个判断结果的输出。
常见的决策树生成算法有ID3,C4.5,C5.0,CART等。
示例：如下图片是正确的分类集（train set）

如下是分类树的判断过程（演示了分类树其实可以有不同构型）


如上分类树的根节点都是判断分数是否大于A（90），如果是就是好学生。然后第二个节点就出现了不同，分别是判断分数是否小于70 OR 出勤率是否大于0.8。
这个分类器节点的构造其实很灵活，怎样构造最好的分类器呢？ID3,ID4.5算法都是倾向于迭代选择熵值最小化的那个分类器。但是ID3,ID4.5算法都有严重的过拟合问题。
CART算法也使用了类似熵的指数–GINI指数，CART算法迭代的目标也是向着GINI指数最小化的方向进行，不过CART算法为了解决过拟合的问题，使用了剪枝的策略，也就是将树中过长的枝叶剪去。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-12&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%A6%82%E5%BF%B5">概念</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91">决策树</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/12/0.%E6%A6%82%E5%BF%B5/NLP_%E8%AF%8D%E5%90%91%E9%87%8F_%E8%AF%8D%E8%A2%8BBOW/">
        <p class="h4 index-header">0.概念/NLP_词向量_词袋BOW</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">词袋算法详解词袋算法是word2vec中构建两大构建词向量算法中的一个。
kaggle tutor实战解读：具体操作如下：

清洗整个语料库by美丽汤
去掉停止词和非英语单词，去掉数组，大小写统一by正则表达式
将剩下的单词组成词典
词典按照词频降序排列
然后指定词袋的feature个数，以五千为例就是前5000个常用单词作为每一个词语/句子的向量表示。
每个向量都是5000维，第一维就是最常用的单词，第二维就是第二常用的单词，第一维是1说明被本向量表示的句子中最常用的单词出现了一次，第一维是2说明被表示的句子中最常用的单词出现了两次。


然后可以将例如25000条语料依次分别按照5000维的向量表示，集合到shape(25000 * 5000)的矩阵中

然后此矩阵带上label就可以用来训练model了
CS224N解读词袋的训练模型如下。

输入层：上下文的独热码，假设向量空间V维，上下文单词个数是C。

所有onehot分别乘以共享的W（V*N）初始化权重矩阵，V是向量维度，N自己设置。

因为是onehot向量，只有一个值为1，其他都是0，所以乘以权重矩阵后仍然是向量，然后</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-12&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F">词向量</a>&nbsp;
          
            <a href="/tags/%E8%AF%8D%E8%A2%8B">词袋</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/08/0.%E6%96%87%E7%AB%A0/NLP_%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/">
        <p class="h4 index-header">0.文章/NLP_词袋模型应用</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">词袋模型的应用1.引入训练数据
import pandas as pd
train = pd.read_csv(&quot;labeledTrainData.tsv&quot;, header=0,delimiter=&quot;\t&quot;, quoting=3)
2.确定引入数据是否正确 – 看一下shape和列标签
&gt;&gt;&gt; train.shape
(25000, 3)

&gt;&gt;&gt; train.columns.values
array([id, sentiment, review], dtype=object)
3.glipise
print train[&quot;review&quot;][0]
4.用beautiful soap清洗掉HTML标签
# Import BeautifulSoup into your workspace
from bs4 import BeautifulSoup             

# Initialize the BeautifulSoup object on a single movie revie</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-08&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%96%87%E7%AB%A0">文章</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B">词袋模型</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/07/0.%E6%96%87%E7%AB%A0/NLP_pre-trained-LM%E5%8F%91%E5%B1%95%E5%8F%B2WE2Bert/">
        <p class="h4 index-header">0.文章/NLP_pre-trained-LM发展史WE2Bert</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">从Word embedding到Bert：A brief history of nlp pre-train modelWord embeddingLM做word embedding –&gt; 使用的工具是word2vec –&gt; word2vec的训练方法：CBOW 和 SKIP - GRAM
word embedding的问题：无法解决一词多义。
​                                                两种不同的上下文信息经过word2vec都会预测相同的单词bank，因为同一个单词占                                                用的是同一行的参数空间。所以WE无法区分一词多义。
ELMO为解决WE一词多义问题，提出ELMO，其思路是事先用LM学好 一个单词的word embedding，后边根据上下文动态调整。WE是静态，ELMO是动态，所以ELMO可以解决一词多义问题。
ELMO工作方式分为两段，分别是利用语言模型进行预训练和做下游任务时将预训练网络中提取对应单词的网络的各层的wor</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-07&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/%E6%96%87%E7%AB%A0">文章</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/WordEmbedding">WordEmbedding</a>&nbsp;
          
            <a href="/tags/Bert">Bert</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/05/07/2.%E6%AF%94%E8%B5%9B/Toxic_%E6%80%9D%E8%B7%AF/">
        <p class="h4 index-header">2.比赛/Toxic_思路</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">思路ToDoList







bpe
跨语言编码


XLM-R + ERNIE
kaggle最热跨语言模型 + 注入特定知识toxic


transformer
特征抽取器(模型)要向匹配问题领域的特点去修改


lstm
transformer组件










选择正确的特征抽取器解决情感分类问题，从模型角度讲，最重要的是特征抽取器的能力。以前是研发人员设计抽取哪些特征，现在都是端到端的抽取，也就是特征抽取器Transformer自动抽取。根据今日阅读知乎和github上的观点，不要使用RNN和CNN，应该采用更加先进的Transformer。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-05-07&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/2.%E6%AF%94%E8%B5%9B">2.比赛</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Toxic">Toxic</a>&nbsp;
          
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/3/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "暗影疾行&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
