<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/index.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/%E6%A2%AF%E6%AE%B5%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">
        <p class="h4 index-header">CS229/梯段下降算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">梯度下降算法
特点：梯度下降算法可以自动将代价函数J最小化
问题描述:有一个代价函数，它有两个参数，想让这个代价函数的值最小化。
做法：持续把这个两个参数向着梯度下降最快的方向迭代。



梯度下降算法的学习率α设置:
α过小,收敛太慢
α过大,在最小值附近震荡


梯度下降缺点:可能求的是局部最优解，解决办法是多次随机初始化起点。

1.多特征值的回归问题

单特征回归:只有房子面积一个特征,求预测房价

单特征回归的假设函数:h(x) = θ0 + θ1x


多特征回归:有房子面积,卧室数量,几层高,使用年限四个特征,求预测房价

四特征回归的假设函数:h(x) = θ0 + θ1x1+θ2x2+θ3x3+θ4x4    —-&gt;   缩写h = θ(XT) :向量θ乘以向量X的转置
只考虑最简单的一次线性多项式


多特征回归的梯度下降算法:

每次对一个参数求偏导,并对其迭代.
所有参数都迭代这么一圈算完成一个回合.
多参数迭代过程如下图






2.梯度下降实用技巧–特征缩放(feature scaling)
如果参数 θ1和θ2大小相差太远,那么θ1的轻微改变都可</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95">梯度下降算法</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/9.%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">
        <p class="h4 index-header">CS229/9.支持向量机</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">9.支持向量机9.1SVM的优化目标从逻辑回归展示如何一点点修改得到本质上的支持向量机

逻辑回归的假设函数





9.2核函数对支持向量机算法做一些修改,以构造复杂的非线性分类器
我们用”核函数”来达到此目的
问题的提出:
使用高级数的多项式模型来解决无法使用直线进行分割的分类问题,如何确定模式中的每一项的参数?
支持向量机的假设函数和代价函数

9.3 SVM的使用不建议自己写代码求解参数θ,就像没有人会写代码自己去求解平方根一样,可以直接调用现有的库
除了高斯核函数之外还有其他核函数可以用:
多项式核函数（Polynomial Kernel）
字符串核函数（String kernel）
卡方核函数（ chi-square kernel）
直方图交集核函数（histogram intersection kernel）
等等
SVM模型 和 逻辑回归模型之间的取舍:

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/SVM">SVM</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/%E5%88%A4%E5%AE%9A%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8C%BA%E5%88%AB/">
        <p class="h4 index-header">CS229/判定模型和生成模型的区别</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">判定模型和生成模型的区别
机器学习的任务是从属性X预测标记Y，即是求概率P（Y|X）

判别式模型是上图左边示例，有个明显的边界，新来一个值需要判断他属于哪一类的时候直接算出他的score，当score大于threshold时为正类，反之为负类。线性回归，SVM模型都是典型的判别式模型
生成式模型是上图右边示例，无明显边界，新来一个值要判断他是哪一类的时候，首先求该值与两个不同标记的不同联合概率分布，然后大的获胜。朴素贝叶斯模型，HMM模型都是生成式模型。

一个生动的例子说明两者的区别:

判别式模型：要确定一个羊是山羊还是绵羊，用判别式的方法是从历史数据中学到模型（运行同一个模型得到确定的结果），然后通过提取这只羊的特征来预测出羊的类型。
生成式模型：根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型。然后提取这只待判定羊的特征，放到山羊模型中看看概率是多少，再放到绵羊模型中看看概率是多少。哪个大就是哪个。（两个模型，两个结果，最后比比数值大小得出结论）

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/%E5%88%A4%E5%AE%9A%E6%A8%A1%E5%9E%8B">判定模型</a>&nbsp;
          
            <a href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B">生成模型</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/8.%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/">
        <p class="h4 index-header">CS229/8.应用机器学习的建议</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">8.应用机器学习的建议8.1如何提高一个算法/机器学习模型的性能问题:预测房价的机器学习模型性能遇见瓶颈,如何提升性能?

很多人是凭感觉去解决问题,他们有如下猜想并随便选一个去做

随便某个猜想都是耗时耗力巨大的项目,人们常常选择的是一条不归路

如何尽量排除无效的道路?



获得更多的训练样本——解决高方差   
尝试减少特征的数量——解决高方差
尝试获得更多的特征——解决高偏差
尝试增加多项式特征——解决高偏差
尝试减少正则化程度λ——解决高偏差
尝试增加正则化程度λ——解决高方差

8.2如何评估一个模型表现
模型的代价函数非常小未必是好事,因为可能存在过拟合的现象
为了检验模型是否过拟合,可以采用交叉验证的方法
可以把数据集分为训练集和测试集,然后重复洗牌交叉验证

高偏差与高方差

高偏差是欠拟合

高方差是过拟合




增加模型的多项式次数导致的过/欠拟合问题

训练集上:
增加模型多项式的次数会导致代价函数单调递减


交叉验证集上:
增加模型多项式的次数会导致代价函数先减后增
先减是改善了欠拟合的问题
后增就是过拟合越来越严重


结论:
交叉验证是评估过/欠拟合</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E8%A1%A8%E7%8E%B0">评估模型表现</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/5.%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96/">
        <p class="h4 index-header">CS229/5.过拟合和正则化</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.过拟合和欠拟合问题两张插图说明白


解决办法:
过拟合就丢弃不能正确预测的特征,欠拟合就加特征
2.代价函数的惩罚项由下图可以看出,过拟合由于高维项造成



给高维项设置惩罚项

代价函数里给三次项和四次项增加一些重量,梯度下降的时候系统就会更急切想把三次项和四次项降下来

增加了惩罚项的代价函数





</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/6.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(%E8%A1%A8%E8%BF%B0)/">
        <p class="h4 index-header">CS229/6.神经网络(表述)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">#
6.神经网络(表述)6.1问题的由来
特征爆炸无法处理
例如,智能识别一个图片是不是汽车的问题
假设使用50*50小黑白照片
那么就有2500个像素灰度作为特征
2500个特征两两组合就是3000000项,这的多项式处理不了
这时候就需要神经网络



6.2直观理解和逻辑运算符的构建
直观理解

神经网络能够通过自身学习得到一些列特征,这些特征是使用数据的原始特征经过拆分组合和一系列逻辑运算得到的
这样的一系列特征比普通的逻辑回归的表层特征要深刻的多
最后做决定的神经元依据上一层传进来的特征,这些特征已经经过多层传导,内化为自己的特征了


神经元可以通过增加一个固定权重神经元构建逻辑运算符(与,非,或,抑或等)

如下图




6.3神经网络的形态
6.4神经网络基本概念的定义from CS224N如图，神经网络有输入，有偏置单元，有激活函数，以及对后续神经网络的输出。
输入x，w是乘以输入的权重，b是偏置值，f是sigmod函数。
输入乘以权重加上偏置值后，进入sigmod函数，输出一个分类值。
有了神经网络，让我们再回到之前的单窗口分类器。代替之前直接将softmax应用</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">神经网络</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/7.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(%E5%AD%A6%E4%B9%A0)/">
        <p class="h4 index-header">CS229/7.神经网络(学习)</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.神经网络(学习)7.1神经网络的代价函数

第一项是在K个输出项上(比如四分类就是K=4),累加逻辑回归的代价函数
第二项就是更高维的罚函数

代价函数的目的:找到使得J(θ)最小化的θ
7.2单个训练数据如何通过神经网络    

z(2) = θ(1)a(1) 

z(2)是第二层神经元的输入项,共五项,是a(1)的三项经过θ(1)矩阵拆分后的结果


a(2) = g[z(2)]

a(2)是第二层神经元的输出项,共五项,是z(2)五项经过第二层神经元的sigmod函数变换后的结果



后边的几层同理
7.3反向传播算法
定义

反向传播算法是利用链式法则递归计算表达式梯度的方法
理解反向传播过程的精妙之处,对理解/实现/设计/调试神经网络非常关键


理解

反向传播就是先正向走一遍,得到各个节点的计算结果

从最后一个节点开始,设置梯度是1

反向计算各个上层节点对他的局部梯度

[dz/dx                                 ]  = [dz/dy]   *  [dy/dx]
[最终结果与本层的梯度]  =上层梯度*本层局部梯度




</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">神经网络</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/10.%E8%81%9A%E7%B1%BBClustering/">
        <p class="h4 index-header">CS229/10.聚类Clustering</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">10.聚类Clustering10.1无监督学习简介无监督学习是让计算机学习无标签数据,而不是之前的标签数据
如图就是聚类问题
左上第一张图是市场分割,就是根据数据库里沉淀的客户信息来对客户分类,做知识图谱和推荐系统
10.2 K-mean (K均值算法)K均值是最普及的一个聚类算法,算法接受一个数据集,将数据聚类为不同的组

K-均值是一个迭代算法

设想我们将数据聚集成n组,选择k个随机的点为聚类中心

对数据集中的每个数据,按照距离k个中心点的距离,将其与距离最近的点关联起来,与这个点聚为一类

然后开始迭代:

每次计算一个组的平均值,将中心点移动到平均值的位置
如此反复几次中心点的位置就不再变化
如下图所示





10.3优化目标K-均值的优化目标就是最小化所有的数据点与其关联的聚类中心点之间的距离之和
因此K均值的代价函数为:

10.4随机初始化在运行k均值算法之前,需要随机初始化所有的聚类中心点
1.选择K &lt; m ,即聚类中心点的个数要小于所有训练集实例的数量
2.随机选择K个训练实例,然后令K个聚类中心等于他们
K-均值算法的一个问题在于,他可能停留在某个</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/%E8%81%9A%E7%B1%BB">聚类</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/11.%E9%99%8D%E7%BB%B4/">
        <p class="h4 index-header">CS229/11.降维</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">11.降维11.1 动机一：数据压缩例如有两个特征，一个是厘米，一个是英寸，这个时候可以抛弃其中一个特征，将二维降成一维
利用投影的方法可以将数据降低为任意想要的维度
11.2主成分分析问题PCA主成分分析是最常见的降维算法
步骤：
找到一个方向向量，当所有的数据投射到该向量时，我们希望投射的平均均方误差最小，方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向作垂线的长度
左边是线性回归，右边是PSA

计算方法

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/%E9%99%8D%E7%BB%B4">降维</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/CS229/4.%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">
        <p class="h4 index-header">CS229/4.逻辑回归</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">4.逻辑回归(logistics regression)1.逻辑回归模型
分类问题输出一个结果”正确”或者”错误”

逻辑回归模型:




当hθ(x) 在区间[0.5,1]时,预测是”正确”,越贴近1越确信
当hθ(x) 在区间[0,0.5)时,预测是”错误”,越贴近0越确信

2.逻辑回归的代价函数

简单点一句话讲:
答案是1,你预测了1,无误差
答案是1,你预测的数字离0越近误差就越大,完全是0误差就是无限大(不可能情况)
答案是0的情况与答案是1的情况同理



3.对逻辑回归的代价函数使用梯度下降算法,以得到最优参数/最优解
4.高级优化
一些建议

不需要写代码实现代价函数的迭代

从技术来讲,其实我们不需要自己手动写程序来计算刚才提到的梯度下降算法的代价函数以及其迭代过程,就像我们不需要自己手动写求平方根和创建数组一样,这些问题早都有非常成熟的库来调用


更高级的算法

除了梯度下降算法,还有共轭梯度法 BFGS (变尺度法) 和L-BFGS (限制变尺度法)这种更高级算法可调用
吴恩达本人已经使用如上提到的算法很多年了,也才是最近才搞清楚他们的内部实现细节



</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/CS229">CS229</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;
          
            <a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92">逻辑回归</a>&nbsp;
          
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/page/12/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="page-number" href="/page/12/">12</a><span class="page-number current">13</span><a class="page-number" href="/page/14/">14</a><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" href="/page/14/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "暗影疾行&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
