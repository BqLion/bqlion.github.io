<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/index.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_hadoop/">
        <p class="h4 index-header">0.概念/技术_hadoop</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">hadoop
大数据概念
无法在一定时间范围内用常规的工具进行捕捉管理和处理数据的集合
需要用新的处理模式才能有更强的决策力洞察力的海量高增长的多样化的信息资产


mysql:只能储存千万条数据,不能搭建大量的集群.处理海量数据时速度极慢


MapReduce定义
是一个分布式运算程序的编程框架
是用户基于hadoop的数据分析应用的核心框架
Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序,并发运行在一个hadoop集群上


MapReduce优点
易于编程
简单实现一些接口,就可以完成一个分布式程序,跟写一个串行程序一样


扩展性
计算资源得不到满足时,增加机器扩展计算能力


高容错性
其中一台机器down了,可把上边的计算任务转移到其他节点上去,不至于导致任务失败


适合PB级数据的离线处理


MapReduce缺点
不擅长实时计算
不能像mysql一样在毫秒内返回计算结果


不擅长流式计算
流计算的输入数据是动态的,MapReduce输入数据是静态的.这由MapReduce自身的设计特点决定
不擅长做DAG有向图计</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Flink_Calcite/">
        <p class="h4 index-header">0.概念/0.文章/Flink_Calcite</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Apache Calcitecalcite是数据库的解析器+优化器。
数据库的三大组件：

解析器

执行引擎

优化器—–&gt;数据库把关系表达式转换为执行计划的组件,决定数据库性能

基于规则的优化器

根据规则优化关系表达式,产生最终执行计划
只认规则,对数据不敏感,易局部优全局差


基于代价的优化器

根据规则优化关系表达式,产生多个执行计划,计算各计划cost,择优而动

灵活智能,多被采用






Calcite优化器是:

基于代价的优化器
组件有：
JDBC Client
JDBC Server
SQL Parser and validator
Operator Expression 
Query Optimizer
两个插拔组件
Metadata provider
Pluginable Rules










Calcite理解
是编程框架，因为有可插拔的优化rules，有对接底层数据源的Adaptor模式
是工具库，因为flink把它嵌入自身的sql处理流程中



优化器Optimizer的三个元件
planner rule            </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/0.%E6%96%87%E7%AB%A0/Flink_%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/">
        <p class="h4 index-header">0.概念/0.文章/Flink_培训笔记</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.1为什么要学习Apache FLink讲师:陈守元 阿里巴巴高级产品专家 

概念

framework框架定义:只写业务逻辑,其他交给框架就可以执行

有状态流计算
当前的计算需根据之前沉淀的数据进行,沉淀的数据就是状态

例如select操作就是无状态的,进来–计算–输出–下一个
例如计算一个小时内某商品的点击量就是有状态的计算
例如机器学习的训练等操作就是有状态的计算


四层flink API                (越往下越贴近底层)

SQL
Table  Api(dynamic tables)
DataStream Aip(streams,windows)
ProcessFunction(event,time,state)


flink和storm对比

fllink把含状态的计算完全抽象在了系统中,storm想要含状态计算需要在引擎外套reddis或Hbase     


Batch analytics

处理批数据时提到类似mapreduce        


学习方法

先实践再理论。尝试构建复杂的Flink Application项目
性学习更适</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_6_%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95/">
        <p class="h4 index-header">0.概念/NLP_SLP_6_维特比算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">维特比算法HMMs的解码算法为Viterbi算法，如图8.5所示。作为动态规划的一个实例，维特比类似于动态规划最小距离算法。维特比算法是一个通用的求序列最短路径的动态规划算法，维特比算法可以将HMM的状态序列作为一个整体来考虑，求给定观测序列O条件下，最可能出现的对应的状态序列  ,即  要最大化，从后向前计算的
用于寻找最优标签序列的维特比算法。给定一个观察序列和一个HMM λ= (A;B)，算法通过HMM返回状态路径，该状态路径为观察序列分配最大似然值。
维特比算法首先建立一个概率矩阵( ) )，每个观察  有一列，状态图中的每个状态有一行。因此，在单个组合自动机中，每个列都有一个用于每个状态  的单元。图8.6显示了这个格子的直觉，因为Janet will back the bill这句话。
网格的每个单元格 表示在看到第一个t观察值并且在给定HMM λ的情况下经过最可能的状态序列  之后HMM处于状态j的概率。 每个单元  的值通过递归地获取可能导致我们到达该单元的最可能路径来计算。 形式上，每个cell表达概率:

我们通过对所有可能的先前状态序列  取最大值来表示最可能的路</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_6_%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">
        <p class="h4 index-header">0.概念/NLP_SLP_6_动态规划</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">动态规划1. 贪心策略的不足先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，需要用到尽量少的钞票。
依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。
这种策略称为“贪心”：假设我们面对的局面是“需要凑出w”，贪心策略会尽快让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。
贪心策略的翻车
但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：15=1×11+4×1    （贪心策略使用了5张钞票）15=3×5               （正确的策略，只用3张钞票）为什么会这样呢？贪心策略错在了哪里？
鼠目寸光刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_6_HMM_%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE/">
        <p class="h4 index-header">0.概念/NLP_SLP_6_HMM_马尔科夫链</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">马尔科夫链马尔可夫链是一个模型，告诉我们关于随机变量序列的概率，状态。每个状态都可以从某个集合中获取值。 这些集合可以是单词，标签或代表任何东西的符号，例如天气。 下图左边是天气转换，右边是生成句子的单词序列。

考虑状态变量  ,HMM核心假设是:当预测未来时，过去并不重要，重要的是现在。

上图显示了一个马尔可夫链，用于为一系列天气事件分配概率，其中词汇表包括HOT, COLD,和 WARM，状态表示为图中的节点，转换以其概率表示为边。 转换是概率：离开给定状态的弧的值必须总和为1。上图右边用于为单词序列  分配一个概率，他其实是一个bigram的语言模型，每条边表示概率  。
在形式上，马尔可夫链由以下组件指定:


 ，N个状态的集合
A =  ,一个转移概率矩阵A，每个  代表从状态i移动到状态j的概率  ,  
 ，状态上的初始概率分布(某一时刻的所有可能的隐藏状态的分布(可能性))。是马尔可夫链从状态i开始的概率。一些状态j可能有  ，这意味着它们不可能是初始状态。  

马尔科夫链模型的状态转移矩阵收敛到的稳定概率分布与我们的初始状态概率分布无关：如果我们得到了这个稳定</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_6_HMM&HEMM&CRF%E7%9A%84%E6%AF%94%E8%BE%83/">
        <p class="h4 index-header">0.概念/NLP_SLP_6_HMM&amp;HEMM&amp;CRF的比较</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">HMM，HEMM,CRF的比较6.6.1)CRF的优点:

CRF没有HMM 那样严格的独立性假设条件，因此可以容纳任意的上下文内容。特征设计灵活。—— 与HMM比较。

由于CRF计算全局最优输出节点的条件概率，它还克服了最大熵马尔科夫模型标记偏置的问题（label-bias）。  —— 与MEMM的比较

CRF是在给定需要标记的观察序列的条件下，计算整个标记序列的联合概率分布。而不是在给定当前状态的条件下，定义一个状态的状态分布。 ——与ME的比较


  CRF缺点：

训练代价大，复杂度高

6.6.2）CRF解决的问题：
HMM模型中存在两个假设，一是输出观察值之间严格独立，二是状态转移过程中当前状态只与前一状态有关（一阶马尔科夫模型）。
MEMM模型克服了观察值之间严格独立产生的问题，但是由于状态之间的假设理论，使得该模型存在标注偏置问题。
CRF模型解决了标注偏置问题，去除了HMM中两个不合理的假设，当然，模型相应的变得更复杂了。
6.6.3）HMM模型，最大熵模型，CRF模型的优劣
HMM模型将标注看做是马尔科夫链，一阶马尔科夫链式针对相邻标注的关系进行建模，其中每个</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_6_HMM&HEMM&CRF%E7%9A%84%E6%AF%94%E8%BE%83pt2/">
        <p class="h4 index-header">0.概念/NLP_SLP_6_HMM&amp;HEMM&amp;CRF的比较pt2</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2.1.1 概览在统计概率图（probability graph models）中，参考宗成庆老师的书，是这样的体系结构（个人非常喜欢这种类型的图）：

在概率图模型中，数据(样本)由公式  建模表示： 

 表示节点，即随机变量（放在此处的，可以是一个token或者一个label），具体地，用  为随机变量建模，注意  现在是代表了一批随机变量（想象对应一条sequence，包含了很多的token），  为这些随机变量的分布；
 表示边，即概率依赖关系。具体咋理解，还是要在后面结合HMM或CRF的graph具体解释。

2.1.2 有向图 vs. 无向图上图可以看到，贝叶斯网络（信念网络）都是有向的，马尔科夫网络无向。所以，贝叶斯网络适合为有单向依赖的数据建模，马尔科夫网络适合实体之间互相依赖的建模。具体地，他们的核心差异表现在如何求  ，即怎么表示  这个的联合概率。
1. 有向图
对于有向图模型，这么求联合概率： 
举个例子，对于下面的这个有向图的随机变量(注意，这个图我画的还是比较广义的)：

应该这样表示他们的联合概率:

应该很好理解吧。
2. 无向图
对于无向图，我看资料</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_6_HMM_%E4%B8%89%E4%B8%AA%E9%97%AE%E9%A2%98/">
        <p class="h4 index-header">0.概念/NLP_SLP_6_HMM_三个问题</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">HMM的三个核心问题的解本文首先对马尔科夫过程、隐形马尔科夫模型等概念做一次梳理性阐述，然后对HMM的三大问题依次给出解法。
1.马尔科夫网络，马尔科夫模型，马尔科夫过程，贝叶斯网络的区别有如下递进定义

将随机变量为节点，若两个随机变量相关或者不独立，则将两者链接一条边；若给定若干随机变量，则形成一个有向图，即构成一个网络
若该网络是有向无环图，则称这个网络为贝叶斯网络
如果这个图退化成线性链的方式，则得到马尔科夫模型，因为每个节点都是随机变量，将其看成各个时刻或空间的相关变化，以随机过程的视角，则可以看成是马尔科夫过程。
若上述网络是无向的，则是无向图模型，又称马尔科夫随机场或者马尔科夫网络。
若给定某些条件，研究这个马尔科夫随机场，则得到条件随机场。
如果使用条件随机场解决标注问题，并且进一步将条件随机场中的网络拓扑变成线性的，则得到线性链条件随机场

2.马尔科夫模型2.1马尔科夫过程马尔科夫过程是一类随机过程，他的原始模型马尔科夫链，由俄罗斯数学家A.A.马尔科夫提出，该过程有如下性质：在已知现在的条件下，他未来的演变过程不依赖于他过去的状态。例如森林中动物的数量演变过程，液</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_6_EM%E7%AE%97%E6%B3%95/">
        <p class="h4 index-header">0.概念/NLP_SLP_6_EM算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">EM算法2.1 基础知识2.1.1 凸函数设是定义在实数域上的函数，如果对于任意的实数，都有： 那么是凸函数。若不是单个实数，而是由实数组成的向量，此时，如果函数的 Hesse 矩阵是半正定的，即 是凸函数。特别地，如果  或者   ，称为严格凸函数。
2.1.2 Jensen不等式如下图，如果函数  是凸函数，  是随机变量，有 0.5 的概率是 a，有 0.5 的概率是 b，  的期望值就是 a 和 b 的中值了那么： 其中， ，这里 a 和 b 的权值为 0.5,    与 a 的权值相等， 与 b 的权值相等。
特别地，如果函数   是严格凸函数，当且仅当：   (即随机变量是常量) 时等号成立。

注：若函数    是凹函数，Jensen不等式符号相反。
2.1.3 期望对于离散型随机变量 X 的概率分布为   ，数学期望   为： 
 是权值，满足两个条件   。
若连续型随机变量X的概率密度函数为  ，则数学期望  为： 设 ， 若  是离散型随机变量，则： 若    是连续型随机变量，则：  
2.2 EM算法的推导对于  个相互独立的样本  ，对应的隐含数据  ，此时</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_6_HMM_%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/">
        <p class="h4 index-header">0.概念/NLP_SLP_6_HMM_马尔科夫模型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">隐性马尔可夫模型(HMM):1. 什么样的问题需要HMM模型首先我们来看看什么样的问题可以用HMM模型。使用HMM模型时我们的问题一般有这两个特征：
​    １）我们的问题是基于序列的，比如时间序列，或者状态序列。
​    ２）我们的问题中有两类数据，一类序列数据是可以观测到的，即观测序列；而另一类数据是不能观察到        的，即隐藏状态序列，简称状态序列。（Hidden state）
有了这两个特征，那么这个问题一般可以用HMM模型来尝试解决。这样的问题在实际生活中是很多的。比如：我现在在打字写博客，我在键盘上敲出来的一系列字符就是观测序列，而我实际想写的一段话就是隐藏序列，输入法的任务就是从敲入的一系列字符尽可能的猜测我要写的一段话，并把最可能的词语放在最前面让我选择，这就可以看做一个HMM模型了。再举一个，我在和你说话，我发出的一串连续的声音就是观测序列，而我实际要表达的一段话就是状态序列，你大脑的任务，就是从这一串连续的声音中判断出我最可能要表达的话的内容。
2. HMM模型的定义

Q是各个状态，图示的节点

A是状态转换矩阵，是各个状态不变/互相转换的概率，图示边</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_3_%E4%B8%80%E9%98%B6%E9%80%BB%E8%BE%91/">
        <p class="h4 index-header">0.概念/NLP_SLP_3_一阶逻辑</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">概念：一阶逻辑（first order logic）一阶二阶这类的词, 一是表达量化的程度, 二是表达逻辑系统多有表达能力. 

0阶逻辑： 每一个字母就代表一个命题, 所以命题逻辑只能表达句子之间的关系, 比如“p&amp;q”, “if p then q”等等的真值如何从p和q的真值中计算出来.
1阶逻辑则引入了两个量词, 即universal quantifier(倒A，所有)和existential quantifier(倒E，存在), 并且加入了一阶谓词和individual variables（变量）和individual constants（常量）. 这些导致一阶逻辑可以量化individuals in the domain. 比如经典的


三段论就可以被一阶逻辑表达：For all x, Hx-&gt;MxHs-—Ms

其中for all x就是量化了所有individuals, 即domain里的任意一对象, 用individual variable x来表示. Hx则是表示x属于H(Human)这个谓词的extension, Mx表示x属于M(Mortal)的e</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_5_FSD%E7%8A%B6%E6%80%81%E4%BC%A0%E6%84%9F%E5%99%A8/">
        <p class="h4 index-header">0.概念/NLP_SLP_5_FSD状态传感器</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">状态传感器FST概念状态传感器是有限状态机的一种。有限状态机适合处理正则语言，有限状态传感器适合处理正则关系。
他是一种类似于字典树/自动机的数据结构。
转自豆瓣-巴扎黑
有限状态转移机在自然语言处理上的应用
原文地址：
http://infolocata.com/mirovia/finite-state-transducers-for-natural-language-processing/
在自然语言处理中，经常会遇到一些针对某些内容法则做出修改的操作，比如说：如果c的后面紧接x的话，则把c变为b，FST则是基于这些规则上的mathematical操作，比如说把若干个规则整合成一个single pass或mega rule，这样做呢，就可以很有效的提高rule-based system的效率。
首先，先来大概的了解一下有限状态机（FSM）
有限状态机呢就是一个由一堆状态（当然啦，有限的嘛），还有一堆转移条件组成的‘鸡’。英文定义是这样的：a FSM is an abstract mathematical model of computation that is capable of</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_SLP_5_FST%E7%8A%B6%E6%80%81%E6%9C%BA/">
        <p class="h4 index-header">0.概念/NLP_SLP_5_FST状态机</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">状态机概念FSM 解决一个输入序列，经过 FSM，最终停留在什么状态这样一个问题。

作者：陈天
链接：https://zhuanlan.zhihu.com/p/28142401
来源：知乎
在谈论一般意义的状态机时，我们先看看有限状态机，Finite State Machine，简称 FSM。
在计算理论（Theory of computation）中，FSM 是一切的基础，也是能力最为有限的机器。在其能力之上是 CFL（Context Free Language），然后是 Turing Machine。
FSM 解决一个输入序列，经过 FSM，最终停留在什么状态这样一个问题。对于一个字符串是否以 \0 结尾（C 语言的字符串结构），FSM 可以给出答案。
CFL 是一切编程语言的基础。你写的一段 python 代码是否语法正确，CFL 能够给出答案。
Turing Machine 就是我们日常用各种算法写代码解决各种问题的基础。不较真地说，JVM 就是一个 Turing Machine。
再往上，就是未知的世界 —— Turing Machine 也解决不了的问题。
如果你工作多年</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_Dic/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_Dic</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">







Phonetics
语音学


Phonology
音韵学


Morphology
形态学


orthographic
正字法


Syntax
语法


Pragmatics
语用学


Semantics
语义学


Ambiguity
一词多义，模棱两可


Dative pronoun
与格代词


Possessive pronoun
所有格代词


part-of-speech
词性


lexical disambiguation
词义消歧


speech act interpretation
言语行为解释


regular grammars
正则文法


critical role
关键角色


crucial
重要的


symbolic
象征的


stochastic
随机的


retrieval
检索


corpora
语料库


finite-state automaton
有限状态自动机


punctuation
标点符号


appendix
附录


Disjunction
析取


Precedence
优先级


Sym</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_9%20-%20Automatic%20Speech%20Recognition/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_9 - Automatic Speech Recognition</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">9. Auto Speech Recognition - 语音转文字Spoken language understanding is a difficult task.The goal of Automatic speech recognition（ASR）is to address this this task computationally by building system  that map from an acoustic signal to a string of word.And Automatic speech understanding(ASU) extends this goal to understand more than just words,also sentences.
影响语音转文字系统性能表现的几个参数：

需要转换的词汇量：如果只是判断对错/数字，容易。判断词汇库是整体英语，难。
speech的流畅度：如果是切分好的单个单词，容易。流畅长篇幅对话，难。
声音质量：apparently，噪音少识别起来容易。
讲话者的类型：apparently，nat</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_%E6%80%BB%E7%BB%93/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_总结</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">自然语言是表达者对某状态(state)[比如“饥饿”]的编码(encode)[比如“我饿了,I`m hungry,Я голоден”],接收者会对这段音波/文字进行解码(decode)来揣测表达者的状态(state)。
自然语言处理是对state转换、code、encode/decode过程的一系列数学建模，通常基于规则+机器学习的模型效果不错。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_7%20-%20Phonetics/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_7 - Phonetics</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.Phonetics(语音学) – 本章对研究帮助不大，跳过A speech recognition system needs to have a pronunciation for every word it can recognize,and a text-to-speech system needs to have a pronunciation for every word it can say.

In this chapter,we introduces phonetic alphabets音标字母 for describing these pronunciations.

Then we introduces two main areas of phonetics, articulatory phonetics发音语音学,and acoustic phonetics声学语音学。

Also briefly touch on phonology音韵学


7.1）Speech sounds and phonetic transciption
音标表格如下：

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_8%20-%20Speech%20Synthesis/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_8 - Speech Synthesis</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">8. Speech Synthesis - 语音合成（文字转语音）Speech Synthesis detail is as following:

本单元讲解如何将文本转换成语音，主要分成如下四个任务：

text normalization  文本标准化
phonetic analysis 语音分析（把token化的词汇转换成音标）
prosodic analysis 韵律分析( 把音标组成的集合拼凑地和谐一点)


waveform synthesis 波形合成（让拼凑好的音标们-IR转wave-发音）

8.1) Text NormalizationText normalization was combined as follwoing:

sentence tokenization
non-standard words
homograph disambiguation

8.1.1)Sentence tokenizationtokenization理解为把句子拆分成小块（token），token之间可以是被空格键分隔，也可以是被句号，逗号，或者单纯是被语义分隔，被token化</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_6%20-%20HMM%20&%20HEMM/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_6 - HMM &amp; HEMM</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">6.Hidden Markov and Maximum Entropy Models（HMM,MEMM）HMM and HEMM are both sequence classifiers.
Sequence classifier or sequence labeler is a model whose job is to assign some label or class to each unit in a sequence.The FST we studied in Chapter 3 is a kind of non-probabilisitic sequence classifier.
We have seen on important sequence classification task:POS tagging.
This chapter is roughtly divided into 2 section:HMM , MEMM.
6.1) Markov Chains - 马尔科夫链 - 详见概念6 - 马尔科夫链
6.2)The Hidden Markov Model</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_5%20-%20Part-of-Speech%20Tagging/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_5 - Part-of-Speech Tagging</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.Part-of-Speech TaggingIntroduce three algorithms:

rule-based tagging
HMM tagging
transformation-based tagging

词性标注是一项消歧任务，很多情况下词具有多于一个的意思，我们的工作是为这种情况找到正确的标签。
5.2）Tagset for EnglishThere are 3 different tagset.

45-tag Penn Treebank tagset
61-tag C5 tagset
87-tag tagset 


Small Tagset:



Middle Tagset



Large Tagset



5.3) Part-of-Speech TaggingSometimes,tagging can be difficult（unambiguous）,For example ,book is ambiguous.Book can be a noun as a read book,or be a verb, as booking a hotel.</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_3%20-%20Word%20&%20Transducers/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_3 - Word &amp; Transducers</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">3.Word &amp; Transducers3.1)Word
Before processing, words in speech should be Stemming、lemmatization and tokenization.
Tokenization means put”New York”in one word,separate “I`m” into “I” and “am”。
Using FSA to build Stemming net of words

3.2)FST : Finite state transducers.
I define it my way:
If you input “aa”,”b”will be output,and the state in still “q0”,if you input “b”,”a or b”will out put,state will be “q1”.For example,if you input “aa aa b a”，output is “b b a ba”.

Defination with details </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_4%20-%20N-Grams/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_4 - N-Grams</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">4 - N-GramsN-gram is a language model,is a N-token sequence of words.
1.the way to calculate conditional probability.For example,how can we calculate P(the|its water is so transparent that) ?
Method1): counting 2 sentences
Counting the times of “its water is so transparent that the” and “its water is so transparent that” in the whole corpus.It works sometime,but language is creative,many sentences is not exist.
 
Method2): chain rule of probability,then use method 1.

notice that:

means  P(w1w2</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_23%20-%20QA/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_23 - QA</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">23 - Question Answering and Summarization本章介绍基于事实的回答问题系统+文章的总结系统。如果我们查找的是结构化的数据，可用上一章介绍的信息提取算法来词查找。如果查找的是非结构化的信息，则需要用本章介绍的“回答问题系统”处理，非结构化信息的查找就是一种“使用非正式的单词或句子”来表达查找需求的场景，这种场景下客户通常期望能返回一些回答or一些文本，或something in between。
第一个session介绍向量空间模型，第二个session介绍基于事实的一问一答系统。第六个session介绍基于句子的总结系统/基于注意力机制的总结系统。
23.1 Information Retrieval 信息检索术语定义
文档document指的是一个有索引的，可被检索系统直接定位的最小单元，对应到web就是一个网页
集合collection指的是一系列用来满足用户需求的文档documents
term指的是一个词汇元素。
query指的是一系列terms

词向量空间
词义相近的在向量空间中距也近，概念在CS224N中学过了。空间和点积的直观图如下</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_24%20-%20%E5%AF%B9%E8%AF%9Dagent/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_24 - 对话agent</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">24 - Dialogue and Conversational Agents这一章介绍问答助手的基本结构+算法。Session24.1介绍人类对话的基本概念，如对话的交替，表达技巧，grounding，对话结构等。Session24.2介绍口语系统的组件和评价标准。Session24.5和Session24.6介绍信息状态架构和马尔科夫对话代理模型，以及高阶话题如BDI范式（belief - desire -intention）信念 - 渴望 - 意图范式。
24.1 人类对话的Properties24.1.1 Turns and turn-talking人类对话的模式是一个人说完了之后另一人说，交替进行，通常情况下，两人对话的重叠部分不超过5%。两个人交替间的停顿时间在100ms左右。为了实现这种模式，人类对话通常有如下三个规律来规范交替的进行，非常显而易见。

通常一个比正常情况更长的听读怒会有额外的表达效果，如下所示一个长停顿代表了不想积极回应问题。

24.1.2 Language as Action:Speech Acts 语言是会产生后果的行动语言能对现实世界产生具体影响</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_22%20-%20Information%20Extraction/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_22 - Information Extraction</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">22 - Information Extraction本章主要概念：

NER：命名实体识别
relation detection and classification：关系检测与分类
event detection and classification：事件检测与分类
temporal expression recognition：事件表达式识别
template filling：模板填充

22.1)NER : 命名实体识别命名实体识别分类的举例

22.1.2）NER as Sequence Labeling
标准的命名实体识别的步骤是使用word-by-word sequence labeling任务。其实进行NER的方法与第五章的POS tagging和十三章的syntactic chunking方法相同。
PS：提一下第五章的POS tagging：使用的还是HMM base 的 维特比算法（decoding）。

问题的本质如下所示，观察到句子/词语，猜测对应的词性/NER类型。也就是观察到结果，猜测其隐状态。


具体的 word-by-word IOB-style t</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_2%20-%20Regular%20expressions%20and%20automata/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_2 - Regular expressions and automata</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2 - Regular expressions and automata2.2) Relationship between FSA and RE
Any regular expression(RE) can be implemented as a finite state automata(FSA),symmetrically,any finite-state automata can be described with a regular expression.
Both RE and FSA can be used to describe regular languages:

Using FSA to understand sheep talk
sheep language can be defined as any string from the following set:
baa!
baaaa!
baaaaa!
baaaaaa!
baaaaaaa!
baaaaaaaa!
baaaaaaaaa!
…
Sheep language can be described as fol</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_11%20-%20Computational%20Phonology/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_11 - Computational Phonology</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">11. Computational Phonology本章较艰涩，对NLP发文帮助不大，Skip，以后需用再补。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_12%20-%2016,17%20-%2021%E8%AF%AD%E6%B3%95%E5%AD%A6%EF%BC%8C%E8%AF%AD%E4%B9%89%E8%AF%AD%E7%94%A8%E5%AD%A6/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_12 - 16,17 - 21语法学，语义语用学</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">12 - 16语法学，17 - 21语义语用学以上几章主要侧重于对英语这门语言本身的讲解，对发表论文帮助不大。先跳过，回头需用再补。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_10%20-%20Automatic%20Speech%20RecongnitionAdvanced%20Topics/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_10 - Automatic Speech RecongnitionAdvanced Topics</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">10. Auto Speech Recognition Advanced Topic ：语音转文字进阶话题之前企图对输入的语音转换成音素的处理办法是：构建一个由全体语言组成的HMM状态网络，然后在网络中采用维特比算法进行全局搜索。这种算法太expensive了。
改进思路是采用多路编码的decoding技术，使用新的上下文相关声学模型(triphone)。本章还会介绍判别训练(discriminative training)和模型的一些变体；
10.1）多路编码decoding : N-Best List and Lattices
首先，维特比算法在进行对语音输入的decoding的时候，有如下两个问题：

在应对一词多音/一音多词的语言时，维特比算法表现很差
维特比算法很难take advantage of 复杂的语言模型：2-gram还行，3-gram就不行了。因为3-gram violates the dynamic programming invariant

改进如上两个问题的思路有：

改进维特比算法，将原本只返回单一值，变成返回多值。以改进一词多音的问题。
使用其他的的d</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_%E7%88%AC%E8%99%AB/">
        <p class="h4 index-header">0.概念/技术_爬虫</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">爬虫目的:掌握定向网络数据爬取和网页解析的基本能力
传达的理念:website is the API
基本内容介绍

request库  自动爬取HTML页面,自动网络请求提交
robots.txt  网络爬虫排除标准
Beautiful Soup解析HTML页面
实战项目
正则表达式
Scrapy专业爬虫框架

1.Request库
安装request:pip install requests
import requestsr = requests.get(“http://www.baidu.com&quot;)r.status_code
r.encoding = ‘utf-8’r.text

Request库的七个主要方法

requests.request()    构造请求,支撑如下方法的基础方法
requests.get()              获取HTML的主要方法,对应HTTP的GET
requests.head()          获取HTML的网页头信息
requests.post()            向HTML网页提交POST请求
requests.p</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_1%20-%20Introdution/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_1 - Introdution</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.Introduction1.1) Required knowledge for NLP:

Phonetics and Phonology : knowledge about linguistic sounds
Morphology : knowledge of meaningful components of words
Syntax :knowledge of the structural relationships between words
Pragmatics :knowledge of the relationship of meaning to the goals and intentions of speaker(what is )
Semantics :knowledge of meaning(what is said)
Discourse : knowledge about linguistic units larger than a single utterance

1.2) Key task : Disambiguation at variety leve</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E8%AF%BE%E9%A2%98%E7%BB%84%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/">
        <p class="h4 index-header">1.科研/课题组信息搜集</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">NLP课题组信息搜集20191218作者：cstghitpku
链接：https://zhuanlan.zhihu.com/p/48529628
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
根据这几年的积累，整理了一份国内外学术界和工业界的牛人和大牛团队，供大家申请硕士、博士、博士后和找工作参考。
学校（排名不分先后）：
哈工大社会计算与信息检索实验室：刘挺老师坐镇，教师包括：秦兵、张宇、车万翔、赵妍妍、刘铭、张伟男、丁效等老师，实验室共7个组，另外王海峰老师也是实验室兼职博导。
哈工大智能技术与自然语言处理实验室：王晓龙老师坐镇，教师包括刘秉权、刘远超、孙承杰等老师
哈工大机器智能与翻译研究室：赵铁军老师坐镇，教师包括杨沐昀、郑德权、徐冰老师等，另外周明老师是实验室兼职博导。
哈工大深圳智能计算研究中心：王晓龙老师坐镇，包括陈清才、汤步洲、徐睿峰、刘滨等老师，实力很强。
哈工大深圳人类语言技术组：徐睿峰老师坐镇，情感原因发现做的比较好。
哈工大另外做NLP的老师包括：关毅、王轩等。
清华大学自然语言处理与社会人文计算实验室：孙茂松老师坐镇，包括刘</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/4.%E5%AE%89%E8%A3%85%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/%E4%BF%AE%E6%94%B9conda%E6%BA%90_%E4%B8%8B%E8%BD%BD%E9%97%AE%E9%A2%98/">
        <p class="h4 index-header">4.安装调试记录/修改conda源_下载问题</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">首次改为国内源：打开cmd
conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forgeconda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forg</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E8%AF%AD%E8%A8%80%E5%AD%A6%E8%8D%90%E4%B9%A6/">
        <p class="h4 index-header">1.科研/语言学荐书</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">语言学方向书籍推荐–Serena Gao首先，做nlp不一定要很懂语言学，也不一定要跟语言学扯上关系。nlp可以仅是data mining，features engineering, 也的确有很多work目前在用文本或者对话做为数据集，然后用统计学方法实现目的，比如deep learning 。在某些任务上统计学模型功不可没，比如machine translation, speech recognition, question answering, etc. 
如果题主只是对nlp的应用感兴趣，想泛泛了解一下目前进展的话，以上几个回答已经非常详细了，我接下来的回答可以不用看。许多主流大公司目前的力度都在deep learning, 学好nlp基本知识，做工程就够了(当然你还需要cs的background)， 语言学的东西不用太深入研究。
————————————-3.17 update——————————-
看了一下其他答案，大家的讨论和见解都很有趣，上来更新一点。
大多数人对nlp和语言学联系的了解，在于认为rule-based的nlp就是基于语言学。的确rule-based是语言学</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/WebScience%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/">
        <p class="h4 index-header">1.科研/WebScience讲座笔记</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Web Science讲座笔记
写论文步骤
在感兴趣的方向提出问题和假设
验证前人是否已经做过？
设计实验
做实验,收集数据
写论文


开题案例
案例:人工智能
阅读中科院，工程院前沿报告,阅读各种综述，阅读下文专项报告
两个月更新一次:ESI Reaserach front专项报告
在web产品里找到,网页右边可以关键词聚类
AI子课题:自然语言处理,主页可显示高被引用论文(数据结构网络的核心)
能顺便找到本学科的raising star

在web science里写检索式,如何寻找文章引用网络
https://www.clarivate.com.cn/e-clarivate/wos_video_wos_research.htm



如何在上行的检索之后筛选自己需要的信息?(上个结果返回30w+文章)

检索结果:
这个功能能找到哪些基金在资助哪些项目
哪些导师在做,找导师/合伙人利器

分析机构:
能找到哪些机构近几年发表了哪些文章

分析机构中的作者








几个产品按钮
在网页上方有个文章被引用次数的功能,发布在哪个期刊



左侧功能栏:
review是学科综述</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%9B%86%5BDone%5D/">
        <p class="h4 index-header">1.科研/深度学习论文集[Done]</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1 深度学习历史和基础1.0 书籍█[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. “Deep learning.” An MIT Press book. (2015). [pdf] (Ian Goodfellow 等大牛所著的教科书，乃深度学习圣经。你可以同时研习这本书以及以下论文) ★★★★★
地址：https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf
1.1 调查█[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. [pdf] (三巨头做的调查)  ★★★★★
地址：http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf
1.2 深度置信网络 (DBN，深度学习前夜的里程碑)█[2] Hinto</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/3%20-%20%E9%80%89%E9%A2%98/">
        <p class="h4 index-header">1.科研/3 - 选题</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">论文选题
经过调研，已对本领域有基本认识，具备了得到idea的条件。
idea要新颖，要能推动科学的发展，同时要有可复现性和可实现性。
把握好与现存结果之间的delta
要因时而动，像语音识别和人脸识别这种已经落地的项目，可能已经没有什么突破的空间了，现在在业界拼的是数据和算力。而常识，知识推理，复杂语境，跨模态理解，可解释智能。这些点目测不能通过数据驱动的方式解决。更高层次的联想、创造、顿悟等认知能力，更是连边还没碰到。这些问题是有远见的研究者应该关注的方向。

补全了相关知识，阅读了大量的文献，走访了各位前辈，观察了各圈风向标，调整首文合理预期后，
我的idea是：_____.
建议2：如何选择第一个好题目？
什么算是好的idea作者：刘知远 
2015年，我在微博上写过一个调侃的小段子：

ML派坐落美利坚合众山中，百年来武学奇才辈出，隐然成江湖第一大名门正派，门内有三套入门武功，曰：图模型加圈，神经网加层，优化目标加正则。有童谣为证：熟练ML入门功，不会作文也会诌。

到了2018年，我又续了一小段：

不期数年，北方DL神教异军突起，内修表示学习，外练神经网络，心法众多，曰门</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/4%20-%20%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1/">
        <p class="h4 index-header">1.科研/4 - 模型设计</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">模型设计确定进入____领域后，如何快速学会第一个技能？仔细研究一般现有的主要工具，流派和方法，先入门。我的建议是：找到一个开源项目，比如机器翻译或者深度学习的项目。理解开源项目的任务，编译通过该项目发布的示范程序，得到与项目示范程序一致的结果。然后再深入理解开源项目示范程序的算法。自己编程实现一下这个示范程序的算法。再按照项目提供的标准测试集测试自己实现的程序。如果输出的结果与项目中出现的结果不一致，就要仔细查验自己的程序，反复修改，直到结果与示范程序基本一致。如果还是不行，就大胆给项目的作者写信请教。在此基础上，再看看自己能否进一步完善算法或者实现，取得比示范程序更好的结果。
如何改进别人的模型
反复阅读本领域最新发表的文章，多阅读本领域牛人发表的文章。在深入了解已有工作的基础上，探讨还有没有一些地方可以推翻、改进、综合、迁移。注意做实验的时候，不要贪多，每次实验只需要验证一个想法。

每次实验之后必须要进行分析存在的错误，找出原因。



对成功的实验，进一步探讨如何改进算法。注意实验数据必须是业界公认的数据。
与已有的算法进行比较，体会能够得出比较一般性的结论。如果有，则去写一</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/7%20-%20%E8%AE%BA%E6%96%87%E7%BB%93%E6%9E%84/">
        <p class="h4 index-header">1.科研/7 - 论文结构</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.论文结构学术研究是一项系统工程
在这个系统工程中，论文的作用则是，向学术界同行清晰准确地描述成果的创新点、技术思路、算法细节和验证结果。明白这一点，才能正确的对待论文写作：一项乏善可陈的工作，很难通过写作变得众星捧月；一项充满创新的成果，却有可能因为糟糕的写作而无法向审稿人准确传递重要价值所在，延误成果发表。


一篇NLP论文的典型结构
NLP学术会议（甚至包括期刊）论文已经形成比较固定的结构。绝大部分论文由以下六大部分构成：摘要（Abstract）、介绍（Introduction）、相关工作（Related Work）、方法（Method）、实验（Experiment）、结论（Conclusion）。少数论文会根据创新成果形式不同而略有不同，例如提出新数据集的论文，可能会把Method部分调整为Dataset的标注与分析，但不影响论文整体构成。每个部分作用不同：

摘要：用100-200词简介研究任务与挑战、解决思路与方法、实验效果与结论。
介绍：用1页左右篇幅，比摘要更详细地介绍研究任务、已有方法、主要挑战、解决思路、具体方法、实验结果。
相关工作：用0.5-1页左右篇幅介绍</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/page/3/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/5/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "暗影疾行&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
