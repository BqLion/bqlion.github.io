<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/index.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_22%20-%20Information%20Extraction/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_22 - Information Extraction</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">22 - Information Extraction本章主要概念：

NER：命名实体识别
relation detection and classification：关系检测与分类
event detection and classification：事件检测与分类
temporal expression recognition：事件表达式识别
template filling：模板填充

22.1)NER : 命名实体识别命名实体识别分类的举例

22.1.2）NER as Sequence Labeling
标准的命名实体识别的步骤是使用word-by-word sequence labeling任务。其实进行NER的方法与第五章的POS tagging和十三章的syntactic chunking方法相同。
PS：提一下第五章的POS tagging：使用的还是HMM base 的 维特比算法（decoding）。

问题的本质如下所示，观察到句子/词语，猜测对应的词性/NER类型。也就是观察到结果，猜测其隐状态。


具体的 word-by-word IOB-style t</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_2%20-%20Regular%20expressions%20and%20automata/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_2 - Regular expressions and automata</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2 - Regular expressions and automata2.2) Relationship between FSA and RE
Any regular expression(RE) can be implemented as a finite state automata(FSA),symmetrically,any finite-state automata can be described with a regular expression.
Both RE and FSA can be used to describe regular languages:

Using FSA to understand sheep talk
sheep language can be defined as any string from the following set:
baa!
baaaa!
baaaaa!
baaaaaa!
baaaaaaa!
baaaaaaaa!
baaaaaaaaa!
…
Sheep language can be described as fol</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_11%20-%20Computational%20Phonology/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_11 - Computational Phonology</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">11. Computational Phonology本章较艰涩，对NLP发文帮助不大，Skip，以后需用再补。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_10%20-%20Automatic%20Speech%20RecongnitionAdvanced%20Topics/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_10 - Automatic Speech RecongnitionAdvanced Topics</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">10. Auto Speech Recognition Advanced Topic ：语音转文字进阶话题之前企图对输入的语音转换成音素的处理办法是：构建一个由全体语言组成的HMM状态网络，然后在网络中采用维特比算法进行全局搜索。这种算法太expensive了。
改进思路是采用多路编码的decoding技术，使用新的上下文相关声学模型(triphone)。本章还会介绍判别训练(discriminative training)和模型的一些变体；
10.1）多路编码decoding : N-Best List and Lattices
首先，维特比算法在进行对语音输入的decoding的时候，有如下两个问题：

在应对一词多音/一音多词的语言时，维特比算法表现很差
维特比算法很难take advantage of 复杂的语言模型：2-gram还行，3-gram就不行了。因为3-gram violates the dynamic programming invariant

改进如上两个问题的思路有：

改进维特比算法，将原本只返回单一值，变成返回多值。以改进一词多音的问题。
使用其他的的d</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_12%20-%2016,17%20-%2021%E8%AF%AD%E6%B3%95%E5%AD%A6%EF%BC%8C%E8%AF%AD%E4%B9%89%E8%AF%AD%E7%94%A8%E5%AD%A6/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_12 - 16,17 - 21语法学，语义语用学</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">12 - 16语法学，17 - 21语义语用学以上几章主要侧重于对英语这门语言本身的讲解，对发表论文帮助不大。先跳过，回头需用再补。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_%E7%88%AC%E8%99%AB/">
        <p class="h4 index-header">0.概念/技术_爬虫</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">爬虫目的:掌握定向网络数据爬取和网页解析的基本能力
传达的理念:website is the API
基本内容介绍

request库  自动爬取HTML页面,自动网络请求提交
robots.txt  网络爬虫排除标准
Beautiful Soup解析HTML页面
实战项目
正则表达式
Scrapy专业爬虫框架

1.Request库
安装request:pip install requests
import requestsr = requests.get(“http://www.baidu.com&quot;)r.status_code
r.encoding = ‘utf-8’r.text

Request库的七个主要方法

requests.request()    构造请求,支撑如下方法的基础方法
requests.get()              获取HTML的主要方法,对应HTTP的GET
requests.head()          获取HTML的网页头信息
requests.post()            向HTML网页提交POST请求
requests.p</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_1%20-%20Introdution/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_1 - Introdution</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.Introduction1.1) Required knowledge for NLP:

Phonetics and Phonology : knowledge about linguistic sounds
Morphology : knowledge of meaningful components of words
Syntax :knowledge of the structural relationships between words
Pragmatics :knowledge of the relationship of meaning to the goals and intentions of speaker(what is )
Semantics :knowledge of meaning(what is said)
Discourse : knowledge about linguistic units larger than a single utterance

1.2) Key task : Disambiguation at variety leve</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E8%AF%BE%E9%A2%98%E7%BB%84%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/">
        <p class="h4 index-header">1.科研/课题组信息搜集</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">NLP课题组信息搜集20191218作者：cstghitpku
链接：https://zhuanlan.zhihu.com/p/48529628
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
根据这几年的积累，整理了一份国内外学术界和工业界的牛人和大牛团队，供大家申请硕士、博士、博士后和找工作参考。
学校（排名不分先后）：
哈工大社会计算与信息检索实验室：刘挺老师坐镇，教师包括：秦兵、张宇、车万翔、赵妍妍、刘铭、张伟男、丁效等老师，实验室共7个组，另外王海峰老师也是实验室兼职博导。
哈工大智能技术与自然语言处理实验室：王晓龙老师坐镇，教师包括刘秉权、刘远超、孙承杰等老师
哈工大机器智能与翻译研究室：赵铁军老师坐镇，教师包括杨沐昀、郑德权、徐冰老师等，另外周明老师是实验室兼职博导。
哈工大深圳智能计算研究中心：王晓龙老师坐镇，包括陈清才、汤步洲、徐睿峰、刘滨等老师，实力很强。
哈工大深圳人类语言技术组：徐睿峰老师坐镇，情感原因发现做的比较好。
哈工大另外做NLP的老师包括：关毅、王轩等。
清华大学自然语言处理与社会人文计算实验室：孙茂松老师坐镇，包括刘</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/4.%E5%AE%89%E8%A3%85%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/%E4%BF%AE%E6%94%B9conda%E6%BA%90_%E4%B8%8B%E8%BD%BD%E9%97%AE%E9%A2%98/">
        <p class="h4 index-header">4.安装调试记录/修改conda源_下载问题</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">首次改为国内源：打开cmd
conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forgeconda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forg</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/WebScience%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/">
        <p class="h4 index-header">1.科研/WebScience讲座笔记</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Web Science讲座笔记
写论文步骤
在感兴趣的方向提出问题和假设
验证前人是否已经做过？
设计实验
做实验,收集数据
写论文


开题案例
案例:人工智能
阅读中科院，工程院前沿报告,阅读各种综述，阅读下文专项报告
两个月更新一次:ESI Reaserach front专项报告
在web产品里找到,网页右边可以关键词聚类
AI子课题:自然语言处理,主页可显示高被引用论文(数据结构网络的核心)
能顺便找到本学科的raising star

在web science里写检索式,如何寻找文章引用网络
https://www.clarivate.com.cn/e-clarivate/wos_video_wos_research.htm



如何在上行的检索之后筛选自己需要的信息?(上个结果返回30w+文章)

检索结果:
这个功能能找到哪些基金在资助哪些项目
哪些导师在做,找导师/合伙人利器

分析机构:
能找到哪些机构近几年发表了哪些文章

分析机构中的作者








几个产品按钮
在网页上方有个文章被引用次数的功能,发布在哪个期刊



左侧功能栏:
review是学科综述</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%9B%86%5BDone%5D/">
        <p class="h4 index-header">1.科研/深度学习论文集[Done]</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1 深度学习历史和基础1.0 书籍█[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. “Deep learning.” An MIT Press book. (2015). [pdf] (Ian Goodfellow 等大牛所著的教科书，乃深度学习圣经。你可以同时研习这本书以及以下论文) ★★★★★
地址：https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf
1.1 调查█[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. [pdf] (三巨头做的调查)  ★★★★★
地址：http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf
1.2 深度置信网络 (DBN，深度学习前夜的里程碑)█[2] Hinto</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E8%AF%AD%E8%A8%80%E5%AD%A6%E8%8D%90%E4%B9%A6/">
        <p class="h4 index-header">1.科研/语言学荐书</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">语言学方向书籍推荐–Serena Gao首先，做nlp不一定要很懂语言学，也不一定要跟语言学扯上关系。nlp可以仅是data mining，features engineering, 也的确有很多work目前在用文本或者对话做为数据集，然后用统计学方法实现目的，比如deep learning 。在某些任务上统计学模型功不可没，比如machine translation, speech recognition, question answering, etc. 
如果题主只是对nlp的应用感兴趣，想泛泛了解一下目前进展的话，以上几个回答已经非常详细了，我接下来的回答可以不用看。许多主流大公司目前的力度都在deep learning, 学好nlp基本知识，做工程就够了(当然你还需要cs的background)， 语言学的东西不用太深入研究。
————————————-3.17 update——————————-
看了一下其他答案，大家的讨论和见解都很有趣，上来更新一点。
大多数人对nlp和语言学联系的了解，在于认为rule-based的nlp就是基于语言学。的确rule-based是语言学</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/4%20-%20%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1/">
        <p class="h4 index-header">1.科研/4 - 模型设计</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">模型设计确定进入____领域后，如何快速学会第一个技能？仔细研究一般现有的主要工具，流派和方法，先入门。我的建议是：找到一个开源项目，比如机器翻译或者深度学习的项目。理解开源项目的任务，编译通过该项目发布的示范程序，得到与项目示范程序一致的结果。然后再深入理解开源项目示范程序的算法。自己编程实现一下这个示范程序的算法。再按照项目提供的标准测试集测试自己实现的程序。如果输出的结果与项目中出现的结果不一致，就要仔细查验自己的程序，反复修改，直到结果与示范程序基本一致。如果还是不行，就大胆给项目的作者写信请教。在此基础上，再看看自己能否进一步完善算法或者实现，取得比示范程序更好的结果。
如何改进别人的模型
反复阅读本领域最新发表的文章，多阅读本领域牛人发表的文章。在深入了解已有工作的基础上，探讨还有没有一些地方可以推翻、改进、综合、迁移。注意做实验的时候，不要贪多，每次实验只需要验证一个想法。

每次实验之后必须要进行分析存在的错误，找出原因。



对成功的实验，进一步探讨如何改进算法。注意实验数据必须是业界公认的数据。
与已有的算法进行比较，体会能够得出比较一般性的结论。如果有，则去写一</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/3%20-%20%E9%80%89%E9%A2%98/">
        <p class="h4 index-header">1.科研/3 - 选题</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">论文选题
经过调研，已对本领域有基本认识，具备了得到idea的条件。
idea要新颖，要能推动科学的发展，同时要有可复现性和可实现性。
把握好与现存结果之间的delta
要因时而动，像语音识别和人脸识别这种已经落地的项目，可能已经没有什么突破的空间了，现在在业界拼的是数据和算力。而常识，知识推理，复杂语境，跨模态理解，可解释智能。这些点目测不能通过数据驱动的方式解决。更高层次的联想、创造、顿悟等认知能力，更是连边还没碰到。这些问题是有远见的研究者应该关注的方向。

补全了相关知识，阅读了大量的文献，走访了各位前辈，观察了各圈风向标，调整首文合理预期后，
我的idea是：_____.
建议2：如何选择第一个好题目？
什么算是好的idea作者：刘知远 
2015年，我在微博上写过一个调侃的小段子：

ML派坐落美利坚合众山中，百年来武学奇才辈出，隐然成江湖第一大名门正派，门内有三套入门武功，曰：图模型加圈，神经网加层，优化目标加正则。有童谣为证：熟练ML入门功，不会作文也会诌。

到了2018年，我又续了一小段：

不期数年，北方DL神教异军突起，内修表示学习，外练神经网络，心法众多，曰门</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/7%20-%20%E8%AE%BA%E6%96%87%E7%BB%93%E6%9E%84/">
        <p class="h4 index-header">1.科研/7 - 论文结构</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.论文结构学术研究是一项系统工程
在这个系统工程中，论文的作用则是，向学术界同行清晰准确地描述成果的创新点、技术思路、算法细节和验证结果。明白这一点，才能正确的对待论文写作：一项乏善可陈的工作，很难通过写作变得众星捧月；一项充满创新的成果，却有可能因为糟糕的写作而无法向审稿人准确传递重要价值所在，延误成果发表。


一篇NLP论文的典型结构
NLP学术会议（甚至包括期刊）论文已经形成比较固定的结构。绝大部分论文由以下六大部分构成：摘要（Abstract）、介绍（Introduction）、相关工作（Related Work）、方法（Method）、实验（Experiment）、结论（Conclusion）。少数论文会根据创新成果形式不同而略有不同，例如提出新数据集的论文，可能会把Method部分调整为Dataset的标注与分析，但不影响论文整体构成。每个部分作用不同：

摘要：用100-200词简介研究任务与挑战、解决思路与方法、实验效果与结论。
介绍：用1页左右篇幅，比摘要更详细地介绍研究任务、已有方法、主要挑战、解决思路、具体方法、实验结果。
相关工作：用0.5-1页左右篇幅介绍</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/2%20-%20%E8%AE%A1%E5%88%92/">
        <p class="h4 index-header">1.科研/2 - 计划</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">计划比赛 -  改进模型 - 得奖 - 阅读论文 - 写作论文
比赛得奖同时也是进入行业的必要条件
进入行业是了解行业和理解科研的必要条件
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/1%20-%20B%E5%AD%A6%E7%A7%91%E8%B0%83%E7%A0%94%E7%BB%93%E8%AE%BA/">
        <p class="h4 index-header">1.科研/1 - B学科调研结论</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.学科调研结论简要结论经过对上文阅读列表+论文库的调研，得出如下结论，可以开始选题。

近年来,我感兴趣的关于_____的研究方向,全球呈现__趋势,其中较多的论文来自\国家\地区,发表相关论文的研究机构有___.蓝海领域比较新，容易出成果，我选择的这个方向是否是蓝海领域_____.
为了充分了解这个领域目前的发展状况，需要如下几个方面的调研：方法方面，是否有一套比较清晰的数学体系和机器学习体系_；数据方面，有没有一个大家公认的标准训练集和测试集__；研究团队，是否有著名团队和人士参加___。如果以上几个方面的调研结论不是太清晰，作为初学者可能不要轻易进入。
全球的研究人员主要从____等领域对课题进行研究,同时我们也注意到___等领域的研究可能会给我们带来不一样的视角和灵感
相关课题的研究成果目前主要发表在____等期刊上,在相关研究领域中,_____等几位学者有较多的论文产出.
影响力较高的几篇论文分别来自于___(国家/地区)的_(机构)的___学者
近半年来___方向引起了较多科研人员的关注
选择____综述文章作为快速了解这个课题的切入点
最新的研究进展指出,该研究方向__</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/1%20-%20A%E5%AD%A6%E7%A7%91%E8%B0%83%E7%A0%94%E8%B5%84%E6%96%99%E5%BA%93/">
        <p class="h4 index-header">1.科研/1 - A学科调研资料库</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.阅读列表+文献库想当GrandMaster，以下提到的所有材料都绕不过去。在还没入行时间紧迫的情况下，须有所取舍。具体取舍规则办法见2 - 计划.md
阅读列表







CS224N - 自然语言处理



CS229 - 机器学习（核心课）



CS229A - 机器学习应用课，数学少，应用多



CS231N - 计算机视觉



CS230 - 专注深度学习，只包含一点点机器学习（which最难的那一部分）



CS221 - AI导论



CS228 - 概率图模型



机器之心



PaperWeekly



NeurIPS 2019公布获奖论文



深度学习所需数学知识



EE转CS成功案例



Jeff Dean谈2020机器学习趋势



从Word2Vec到BERT    done



kaggle竞赛宝典



NIPS2019



斯坦福2019全球AI报告



2020学术会议list



因果推演



ACL2019知识图谱总结



概率论与数理统计



线性代数



高等数学



优化理论



Bubeck</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_Git/">
        <p class="h4 index-header">0.概念/技术_Git</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">Git1.四个区域Workplace : 工作区，自己的电脑存放代码的地方
Index，Stage ： 暂存区，存放临时的改动，事实上它是一个文件，保存即将提交到文件列表的信息
Repository  :  仓库区（版本库），存放数据的地方，有所有提交版本的地方，其中head指向最新放入仓库的版本
Remote ：远程仓库，托管代码的服务器，可以简单理解为项目组的一台用于远程数据交换的电脑
四者关系如下

2.常用命令常用
# 本地推至暂存区
git add .
# 删除暂存区/分支，但本地保留文件（不被版本控制）
git rm --cached file_path
# 为本地代码切换版本
git checkout
# 暂存区代码推至版本库
git commit -m &quot;提交说明&quot;
# 移除暂存区文件
git reset HEAD 文件名
# 去掉上次的提交(变成add前状态)
git reset HEAD^
# 去掉上次的提交(变成commit前状态)
git reset --soft HEAD^
# 显示当前git配置
git config --lsit
# 编</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/0%20-%20%E6%80%BB%E4%BD%93%E6%80%9D%E8%B7%AF/">
        <p class="h4 index-header">1.科研/0 - 总体思路</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">0 - 总体思路
基础 ： Speech and Language Processing（完成）
早年经典NLP论文：遍历论文库（进行中）
了解机器学习的基本模型：
CS229（完成）
Pattern Recognition and Machine Learning


了解NLP其他子领域(MT,信息抽取,parsing,tagging,情感分析,MRC等)（进行中）
了解CV和数据挖掘领域的进展


学科调研：构建阅读列表和论文库；读近五年survey，近三年顶会，感兴趣方向热门论文和经典书单；输出互引DAG图，输出专有名词词典，输出调研文档。

   *构建文献库时遇到的困难：flood。目前资料：知识图谱80 + 深度学习100 + 生物医学CRF70 + ACL660 = 910篇论文，以及7本大部头。这还不包括所谓的5年survery100 + 三年顶会3000共约3100篇论文。 *
   我需要的：迅速了解整个学科发展大致现状，选择自己感兴趣的+有前途做的人少的领域迅速构建论文库精读切入
   初步解决方案：控制工作量，看优质survey，大部头只挑一本看，其余当工具书</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/4.%E5%AE%89%E8%A3%85%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/%E5%BF%AB%E6%8D%B7%E9%94%AE/">
        <p class="h4 index-header">4.安装调试记录/快捷键</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">PyCharmCTRL + -  = 折叠本行 
CTRL + + = 打开本行
CTRL + SHIFT + -  = 全部折叠
CTRL + SHIFT + + = 全部打开
ChromeCTRL + SHIFT + N = 打开匿名窗口
CTRL + SHIFT + I =  检查
CTRL + W  = 关闭当前标签页
CTRL + fn  + PgUp/PgDn = 上翻/下翻当前标签页
IDEACTRL + SHIFT + F12 =  编程窗口最大化
CTRL + SHIFT+ N = 查找文件
SHIFT + F6 = 全局替换
CTRL + ALT + L = 格式化代码
CTRL + ALT + V =快速赋值
Cookie[] cookeis数组遍历便捷写法  = cookies.for = for(Cookie cookie : cookies)
SHIFT + F6  = 文件重命名
CTRL + SHIFT + C = 拷贝文件路径
CTRL + D = 拷贝一行
SHIFT + ENTER = 换行
CTRL + P = 查看参数
CTRL + N = 查</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_5.%E7%B4%A2%E5%BC%95,%E8%B0%83%E4%BC%98/">
        <p class="h4 index-header">0.文章/Java_5.索引,调优</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.sql索引,调优索引相关概念

索引原理
DBMS索引一般用b tree或者b+tree实现



带主键的数据库表的存储结构(正常查找)

构建索引后从非聚集索引直接查找

Sql语句执行流程
create index index_birthday on user_info(birthday)   //构建索引
select user_name from user_info where birthday = ‘1991-01-01’      //正常查找数据
create index index_birthday_and_user_name on user_info(birthday,user_name);   //构建双字段的覆盖索引



</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_6.jetty%E5%92%8Ctomcat/">
        <p class="h4 index-header">0.文章/Java_6.jetty和tomcat</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.jetty和tomcat1.Jetty是什么
​    jetty是一个开源的HTTP服务器和Servlet引擎,可以为JSP和Servlet提供运行时环境,相对与Tomcat,,jetty更加轻量级,更加简易和灵活
2.jetty特点

异步,支持更高的并发量
灵活,更加轻量,更容易定制,更高的资源利用率
Jetty采用默认的NIO模型,jetty很好地支持长链接

3.应用场景

企业级应用tomcat占据了绝对优势
jetty默认使用NIO,在轻量级的,保持长连接的场景下使用很有优势,比如客服的聊天

4.jetty原理

提供了两种handlder
handlerWrapper
可以将一个Handler委托给另一个类执行,将handler加载到jetty中就是通过handler委托给server执行的


handlerCollection
将多个handler组装成handler链,可以方便地做扩展





2.tomcat
为了服务器生成动态页面,需要运行java Servlet,那么就需要提供Servlet容器
Tomcat正式支持运行Servlet/JSP应用程序</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_7.%E5%8F%8D%E5%B0%84/">
        <p class="h4 index-header">0.文章/Java_7.反射</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">反射
反射的定义

行状态中,能知道任何一个类的属性和方法
能调用任何一个对象的属性和方法
这种动态获取信息以及动态调用对象方法的功能称谓java的反射机制


反射的用途

第三方应用开发时,会遇到某个类的变量或方法是私有的,只对系统应用开放,这时候就利用java的反射机制通过反射来获取所需要的私有成员或者方法.


反射的相关类


class类





</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_3.%E6%B3%9B%E5%9E%8B/">
        <p class="h4 index-header">0.文章/Java_3.泛型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">泛型泛型就是扩展了方法的适用范围:
例子:
原本有一个SUM(y) = (a + b)的两元素相加的方法

在两数字相加或两字符串拼接的场景下本来都可以用它

但是如果y提前规定了数据类型就不能用了,两个场景必有其一要重写

这时候使用泛型,&lt;T&gt;当做占位符,就可以实现代码复用了 


之所以不用Object实现参数的任意化是因为要做显式的强制转换,这种转换是要求开发者对实际参数可预知的情况下进行的,而很多时候开发者不能预知程序运行时有哪样的类型需要强转
如果强转错误,程序员也无从得知,是一个安全隐患
引入泛型不用object后所有任意化的参数类型都是隐式自动进行的,保证了效率和安全性
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_2.ClassLoader/">
        <p class="h4 index-header">0.文章/Java_2.ClassLoader</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2.ClassLoader类加载器classloader作用:

负责将class加载到JVM中
审查每个类由谁加载
将class字节码重新编译成JVM统一要求的对象格式

2.1类加载时机与过程类从被加载到虚拟机内存开始,到卸载出内存为止,整个生命周期包括了七个部分:
加载,验证,准备,解析,初始化,使用,卸载

如下几种情况会对类进行初始化

创建类的实例
对类进行反射调用
当初始化类,发现父类没有没初始化
jvm启动,用户指定一个要执行的主类,虚拟机会先初始化这个主类
java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic,REF_putstatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。

2.2类加载器的双亲委派模型

双亲委派模型好处

避免重复加载,当父类已经加载了该类的时候,就没有必要classloader再加载一次考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_4.%E8%A1%A8%E9%93%BE%E6%8E%A5/">
        <p class="h4 index-header">0.文章/Java_4.表链接</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.表链接5.1外链接外链接就是A B两个表,以左右链接的方式选择一个主表,然后附表加入主表的过程
AB两个表的图示


左外链接

select * from TableA left join TableB on TableA.id=TableB.id






右外链接

select * from TableA right join TableB on TableA.id=TableB.id






全外链接

select * from TableA full join TableB on TableA.id=TableB.id




内链接

select * from TableA JOIN TableB on TableA.id=TableB.id
结果是只链接两者共有的数据






交叉链接

select * from TableA cross join TableB

结果是两个表以基础序号为乘积的笛卡尔积的排列





</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%96%87%E7%AB%A0/Java_1.JVM,%E6%96%B9%E6%B3%95%E5%8C%BA,%E5%A0%86/">
        <p class="h4 index-header">0.文章/Java_1.JVM,方法区,堆</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">JVM
JAVA虚拟机的生命周期
java虚拟机用于执行java程序,一个java程序对应一个虚拟机
java虚拟机总是开始于一个main方法,返回void,接受一个args[]参数
main()方法是程序的起点,他被执行的线程初始化为程序的初始线程
java中的线程分两种
守护线程daemon:java虚拟机自己使用的,比如垃圾回收
非守护线程:non-daemon:包含main()方法的初始线程不是守护线程






运行时数据区域


1.程序计数器
内存空间小,线程私有,字节码解释器就是依赖程序计数器工作的:改变计数器的值来选取下一条需要执行的指令,分支,循环,跳转,异常处理等.
如果线程正在执行一个java方法,这个计数器就记录正在执行的虚拟机字节码地址.
如果这个方法是native方法,则计数器的值为underfined


程序计数器这个区域是java虚拟机中唯一没有规定任何OutOfMemoryError情况的区域


2.java虚拟机栈
线程私有,生命周期和线程一致
线程(thread)
是操作系统能够进行运算调度的最小单位
被包含在进程中,是进程的实际运作单位
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%92%8C%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">
        <p class="h4 index-header">0.概念/NLP_知识图谱和推荐系统</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.知识图谱知识图谱是语义网络semantic network的知识库，可理解为理解为多关系图，多关系图一般包含多种类型的节点和边。
知识图谱的场景

社交网络，人和公司都可以是实体，人是节点，公司是节点的集合，人与人之间的关系是边，边可以是朋友也可是同事等，关系可以是单向也可以是双向的

数据库是结构化数据，网页是非结构化数据，处理非结构化数据是信息抽取的难点。
四个难点

实体命名识别  
关系抽取()
实体统一(武汉,江城)
指代消解  (it)

知识图谱的存储方式
RDF

存储三元组(triple)
推理引擎
W3C标准
易于发布数据,多为学术界场景

2.推荐系统评分预测:系统预测用户对电影的评分,根据此给用户推荐,这种是显示反馈
还有一种是点击率预测,新闻类应用中,根据用户点击某概率来优化推荐方案,这种场景下用户反馈信息的行为特征,而不能反映用户的喜爱成都,这是隐式反馈
传统的推系统只能使用用户和物品的历史交互信息,作为输入,有两个问题:
用户和物品之间的交互信息是非常稀疏的,几万个电影只看了几个可能过拟合,
或者新用户没有看过电影,这问题也叫冷启动问题
解决冷启动问题</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_Docker/">
        <p class="h4 index-header">0.概念/技术_Docker</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">DockerDocker是个虚拟机，主要运行在linux上，和VMware Workstation Pro有很多相似的地方。

镜像，是创建虚拟机之前需要下载的系统镜像文件，比如iso和img文件等
容器，是正在运行中的虚拟机
tar文件，就是镜像的压缩文件，压缩传送解压缩安装
dockerfile，配置文件，写完后通过docker bulid指令将dockerfile构建成一个镜像
仓库，类似于github，和镜像是pull和push的关系，里边有做好的ubuntu，mysql，tomcat镜像等

基本操作安装docker
docker pull nginx : 从仓库下载nginx
docker images : 查看本地镜像
docker run -d -p 80:80 nginx 后台将镜像运行为容器nginx，端口映射80-80
docker ps查看正在运行的容器有哪些，例如它会输出正在运行的容器是nginx，id是92a68b3fe02e
docker exec -it 92,进入运行的id开头是92的容器
cd /usr/share/nginx/html/,进入ngi</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_D3NER/">
        <p class="h4 index-header">0.概念/NLP_D3NER</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">D3NER:biomedical named entity recognition using CRF-biLSTM improved with fine-tuned embedding of various linguistic information找有代码的论文读，复现作者的工作
1.标题D3NER:一种使用[被精细调整过”多种语言信息embedding”所提升性能的条件随机场-双向长短时记忆网络]的生物医学命名实体识别工具

embedding

CRF

biLSTM
均另起文章讨论


2.abstract2.1Motivation
生物医学命名实体识别技术,是从生物医学文本信息(unstructured text)中提取知识的先决条件,最近LSTM网络被应用到这个问题上,表现很好,不过我们有更改进的地方.
2.2Result
我们使用D3NER,一种使用了CRF+biLSTM网络+精调语言信息embedding的生物医学命名实体识别技术
D3NER和同方向的七种实体识别技术做了充分对比,结论是性能确实有提高
3.Introduction
特征工程做NER
Named En</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_CRF%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/">
        <p class="h4 index-header">0.概念/NLP_CRF条件随机场</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">条件随机场
概率统计图概览


马尔科夫假设/马尔科夫性

马尔科夫假设
马尔科夫链  里的  总是只受  一个人的影响。马尔科夫假设这里相当于就是个2-gram。
马尔科夫过程
在一个过程中，每个状态的转移只依赖于前n个状态




马尔科夫性
马尔科夫性是保证或者判断概率图是否为概率无向图的条件
成对性
局部性
全局性






条件随机场定义

条件随机场是在给定的随机变量 （具体，对应观测序列  ）条件下，随机变量  （具体，对应隐状态序列  的马尔科夫随机场。
广义的CRF的定义是： 满足  的马尔科夫随机场叫做条件随机场（CRF）
条件随机场是一种特殊的马尔科夫随机场
马尔科夫随机场
首先我们有无向图G=(V,E)， 图G中每个节点v上都有一个随机变量y，这样所有的节点上的随机变量就构成一组随机变量Y，图G上有联合概率分布P(Y)。边e表示相邻节点的变量存在某种神秘的联系。
图G上的随机变量Y满足马尔科夫性，即两个不相邻的节点上的随机变量yi，yj条件独立。这就是马尔科夫随机场。




CRF建模公式


CRF特征函数











</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E8%AF%8D%E5%90%91%E9%87%8F_n-gram/">
        <p class="h4 index-header">0.概念/NLP_词向量_n-gram</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">n-gram语言模型1.Statistical Language Model
在自然语言处理中的一个基本问题,如何计算一段文本序列在某某种语言下出现的概率?
例子

我经常会去图书馆＿＿＿？
预测该句后面的词，我们通常会根据已有的语料的上下文，来统计预测这句话可以填某个词汇的概率，将最大的概率作为结果返回


机器翻译中,I like  Tomc so much,将单词逐个翻译—-{我,喜欢,汤姆,非常},这个集合中的字词排列组合成句子,然后用语言模型去计算组成句子概率的大小,概率越大越流畅

2.n-gram语言模型
理解:
n-gram语言模型的思想,可以追溯到香农的问题:给定一串字母,比如”for ex”,下一个最可能出现的字母是什么?从训练语料中,我们可以通过极大似然估计的方法,得到N个概率分布,是”a”的概率是0.4,是”b”的概率是0.0001,是c的概率是….,and 别忘记约束条件:所有N个概率的分布总和为1
如下图,运用条件概率和乘法公式推倒:
直接这么计算比较困难,需要引入马尔科夫假设,即,一个item的出现,只与前m个items有关,m = 0时,就是unigra</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E4%B8%89%E4%B8%AA%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">
        <p class="h4 index-header">2.比赛/指导_三个集成学习模型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">三个常用的集成学习模型常见集成学习模型一览图
集成学习的优点采用多个分类器对数据集预测,提高整体分类器的泛化能力
三种常见的集成学框架
bagging 装袋
boosting 提升
stacking 堆栈

bagging–装袋
子训练集一般是各不相同的
基模型一般采用SVM或者朴素贝叶斯(大家一般采用同一种模型)
测试集扔给基模型们,然后各个基模型投票表决,简单多数为最终结果

Boosting提升第一次训练得到返回结果,然后给每一个结果分配权值,分类正确的权值降低,错误的权值上升
分类错误权值升高,在第二次训练时被重点关照
测试–测试集扔给各个样本,最后根据投票权值分配投票权,最终得到分配结果
Stacking–堆叠

训练集分出n个基模型
集成方法:
基础模型比如有100个,每个输出三维向量,一共就输出300维的向量
这个向量在堆叠模型那里训练
测试集也有三百维,最后生成测试数据让模型训练,得到最终结果



集成模型的偏差与方差

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2&%E9%A2%84%E5%A4%84%E7%90%86_CrowdFlower/">
        <p class="h4 index-header">2.比赛/指导_数据探索&amp;预处理_CrowdFlower</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">以CrowdFlower比赛为例讲解数据探索与预处理比赛目标​    衡量搜索结果的相关性

比赛数据集
CrowdFlower平台丰富的查询结果配对创建的
为了评估搜索相关性,CrowdFlower已经将261个搜索词与产品列表放在一起,要求人群对每个搜索结果评分,1,2,3,4分别表示搜索结果从完全不相关到完全相关



数据集
train.csv训练集数据
id 产品id
query 搜索词语
product_title 产品标题
product_description 产品描述文本
median_relevance 三位评分员的相关性评分中位数
relevance_variance 评分员的相关性评分方差


test.csv
id 产品id
query 搜索词语
product_description 产品描述文本


目标变量
median_relevance



数据预处理

首先本数据以文字为主,文字只能输入进分类树模型,所以首先要把文字转换成数字
Dropping HTML标签
Word Replacement:然后要把拼写错误的单词替换掉
stemming:词干化</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/2.%E6%AF%94%E8%B5%9B/%E6%8C%87%E5%AF%BC_%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E4%B8%8E%E5%B7%A5%E5%85%B7/">
        <p class="h4 index-header">2.比赛/指导_常见算法与工具</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">比赛常用算法与工具1.1 提纲
机器学习应用领域
机器学习常见算法
常用工具
建模与问题解决流程
数据处理
特征工程
模型选择
寻找最佳超参数:交叉验证
模型分析与模型融合


kaggle wiki
简单案例讲解

1.2机器学习常见算法
1.3机器学习常见工具

scikit - learn :速度不快,但是全面,封装的好,只需要造出来基本参数就可以自动去跑
gensim - 自然语言处理会用
NUmPy - 科学计算(封装到其他工具里了)
matplotlib - 绘图
pandas - 数据清洗,产出特征,缺省值,填充等
xgboost - 基于boost的库,分类和回归都可以完成
Natural Language Toolkit多用于英文的自然语言处理,中文用的很少
Jieba - 多用于中文语言处理
TensorFlow - 深度学习库,对显存的占用较高,速度不算太快
Caffe -深度学习库, 图像用的很多
Keras - 深度学习库,接口简单,本视频deep learning部分用Keras

1.4解决问题流程
了解场景和目标
了解评估准则
认识数据
数据预处理(清洗</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E6%A2%AF%E6%AE%B5%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">
        <p class="h4 index-header">0.概念/NLP_梯段下降算法</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">梯度下降算法对于优化问题，机器学习的目标是使得某个损失函数最小。也就是找到一个x = min f(x)。但并不是所有的问题都能找到解析解，部分问题只能通过数值计算的方法逼近最优解 —— 一阶导数的梯度下降算法和二阶导数的牛顿方法。

问题描述:有一个代价函数，它有两个参数，想让这个代价函数的值最小化。
做法：持续把这个两个参数向着梯度下降最快的方向迭代。



梯度下降算法的学习率α设置:
α过小,收敛太慢
α过大,在最小值附近震荡


梯度下降缺点:可能求的是局部最优解，解决办法是多次随机初始化起点。

1.多特征值的回归问题

单特征回归:只有房子面积一个特征,求预测房价

单特征回归的假设函数:h(x) = θ0 + θ1x


多特征回归:有房子面积,卧室数量,几层高,使用年限四个特征,求预测房价

四特征回归的假设函数:h(x) = θ0 + θ1x1+θ2x2+θ3x3+θ4x4    —-&gt;   缩写h = θ(XT) :向量θ乘以向量X的转置
只考虑最简单的一次线性多项式


多特征回归的梯度下降算法:

每次对一个参数求偏导,并对其迭代.
所有参数都迭代这么一圈</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/">
        <p class="h4 index-header">0.概念/NLP_极大似然估计</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">极大似然估计极大似然估计是确定机器学习模型的参数的一种办法。确定参数值的过程，是找到能最大化“模型产生真实观察数据可能性“的那一组参数，略抽象，如下是一个例子：
从某过程观察了如下十个数据点，每个数据点代表了学生回答问题使用的秒数。

这些数据的生成过程可以使用高斯分布（正态分布）进行充分描述。高斯分布有两个参数，西格玛和μ，如何确定参数？如下示意图表示了使用不同参数的不同高斯分布（方差大的中心函数更扁平）。
注：蓝色曲线是正确曲线N(10,2.25)

OK，如何反编译确定正确参数？我们把这个例子再次简化，同样的情境，这次只存在三个数据点：9,9.5,11
如何使用最大似然估计确定这个高斯分布的参数？
高斯分布中，单个数据点x的边缘概率如下

同时观察到上边所提三个点（9,9.5,11）的联合概率是带入上边三个数据的连乘积：

我们只要能找到最大化上述连乘积的参数μ和西格玛就ok了。也就是说，最大似然估计是一个通过确定参数得到函数最大值的优化问题。
那么，如何求出上述函数的最大值？
easy，二元函数求偏导标准步骤，加以两边套上对数等数学小技巧就完事儿了。
SOP:


</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">
        <p class="h4 index-header">0.概念/NLP_支持向量机</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">支持向量机SVM9.1SVM的优化目标从逻辑回归展示如何一点点修改得到本质上的支持向量机

逻辑回归的假设函数




9.2核函数对支持向量机算法做一些修改,以构造复杂的非线性分类器
我们用”核函数”来达到此目的
问题的提出:
使用高级数的多项式模型来解决无法使用直线进行分割的分类问题,如何确定模式中的每一项的参数?
支持向量机的假设函数和代价函数

9.3 SVM的使用不建议自己写代码求解参数θ,就像没有人会写代码自己去求解平方根一样,可以直接调用现有的库
除了高斯核函数之外还有其他核函数可以用:
多项式核函数（Polynomial Kernel）
字符串核函数（String kernel）
卡方核函数（ chi-square kernel）
直方图交集核函数（histogram intersection kernel）
等等
SVM模型 和 逻辑回归模型之间的取舍:

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/NLP_%E5%88%A4%E5%AE%9A%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/">
        <p class="h4 index-header">0.概念/NLP_判定模型和生成模型</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">判定模型和生成模型的区别
机器学习的任务是从属性X预测标记Y，即是求概率P（Y|X）

判别式模型是上图左边示例，有个明显的边界，新来一个值需要判断他属于哪一类的时候直接算出他的score，当score大于threshold时为正类，反之为负类。线性回归，SVM模型都是典型的判别式模型
生成式模型是上图右边示例，无明显边界，新来一个值要判断他是哪一类的时候，首先求该值与两个不同标记的不同联合概率分布，然后大的获胜。朴素贝叶斯模型，HMM模型都是生成式模型。

一个生动的例子说明两者的区别:

判别式模型：要确定一个羊是山羊还是绵羊，用判别式的方法是从历史数据中学到模型（运行同一个模型得到确定的结果），然后通过提取这只羊的特征来预测出羊的类型。
生成式模型：根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型。然后提取这只待判定羊的特征，放到山羊模型中看看概率是多少，再放到绵羊模型中看看概率是多少。哪个大就是哪个。（两个模型，两个结果，最后比比数值大小得出结论）

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/page/3/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "暗影疾行&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
