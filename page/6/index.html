<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <link rel="icon" type="image/png" href="http://bqlab-pic.test.upcdn.net/myicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="description" content="desc">
  <meta name="author" content="LiuBingqian">
  <meta name="keywords" content="">
  <title>刘秉乾的技术博客 :)</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"  >
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css"  >
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css"  >
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>LiuBingqian`s Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">主页</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">所有文章</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>


</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://bqlab-pic.test.upcdn.net/index.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_Dic/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_Dic</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">







Phonetics
语音学


Phonology
音韵学


Morphology
形态学


orthographic
正字法


Syntax
语法


Pragmatics
语用学


Semantics
语义学


Ambiguity
一词多义，模棱两可


Dative pronoun
与格代词


Possessive pronoun
所有格代词


part-of-speech
词性


lexical disambiguation
词义消歧


speech act interpretation
言语行为解释


regular grammars
正则文法


critical role
关键角色


crucial
重要的


symbolic
象征的


stochastic
随机的


retrieval
检索


corpora
语料库


finite-state automaton
有限状态自动机


punctuation
标点符号


appendix
附录


Disjunction
析取


Precedence
优先级


Sym</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_%E6%80%BB%E7%BB%93/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_总结</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">自然语言是表达者对某状态(state)[比如“饥饿”]的编码(encode)[比如“我饿了,I`m hungry,Я голоден”],接收者会对这段音波/文字进行解码(decode)来揣测表达者的状态(state)。
自然语言处理是对state转换、code、encode/decode过程的一系列数学建模，通常基于规则+机器学习的模型效果不错。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_7%20-%20Phonetics/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_7 - Phonetics</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">7.Phonetics(语音学) – 本章对研究帮助不大，跳过A speech recognition system needs to have a pronunciation for every word it can recognize,and a text-to-speech system needs to have a pronunciation for every word it can say.

In this chapter,we introduces phonetic alphabets音标字母 for describing these pronunciations.

Then we introduces two main areas of phonetics, articulatory phonetics发音语音学,and acoustic phonetics声学语音学。

Also briefly touch on phonology音韵学


7.1）Speech sounds and phonetic transciption
音标表格如下：

</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_8%20-%20Speech%20Synthesis/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_8 - Speech Synthesis</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">8. Speech Synthesis - 语音合成（文字转语音）Speech Synthesis detail is as following:

本单元讲解如何将文本转换成语音，主要分成如下四个任务：

text normalization  文本标准化
phonetic analysis 语音分析（把token化的词汇转换成音标）
prosodic analysis 韵律分析( 把音标组成的集合拼凑地和谐一点)


waveform synthesis 波形合成（让拼凑好的音标们-IR转wave-发音）

8.1) Text NormalizationText normalization was combined as follwoing:

sentence tokenization
non-standard words
homograph disambiguation

8.1.1)Sentence tokenizationtokenization理解为把句子拆分成小块（token），token之间可以是被空格键分隔，也可以是被句号，逗号，或者单纯是被语义分隔，被token化</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_6%20-%20HMM%20&%20HEMM/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_6 - HMM &amp; HEMM</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">6.Hidden Markov and Maximum Entropy Models（HMM,MEMM）HMM and HEMM are both sequence classifiers.
Sequence classifier or sequence labeler is a model whose job is to assign some label or class to each unit in a sequence.The FST we studied in Chapter 3 is a kind of non-probabilisitic sequence classifier.
We have seen on important sequence classification task:POS tagging.
This chapter is roughtly divided into 2 section:HMM , MEMM.
6.1) Markov Chains - 马尔科夫链 - 详见概念6 - 马尔科夫链
6.2)The Hidden Markov Model</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_5%20-%20Part-of-Speech%20Tagging/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_5 - Part-of-Speech Tagging</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">5.Part-of-Speech TaggingIntroduce three algorithms:

rule-based tagging
HMM tagging
transformation-based tagging

词性标注是一项消歧任务，很多情况下词具有多于一个的意思，我们的工作是为这种情况找到正确的标签。
5.2）Tagset for EnglishThere are 3 different tagset.

45-tag Penn Treebank tagset
61-tag C5 tagset
87-tag tagset 


Small Tagset:



Middle Tagset



Large Tagset



5.3) Part-of-Speech TaggingSometimes,tagging can be difficult（unambiguous）,For example ,book is ambiguous.Book can be a noun as a read book,or be a verb, as booking a hotel.</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_3%20-%20Word%20&%20Transducers/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_3 - Word &amp; Transducers</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">3.Word &amp; Transducers3.1)Word
Before processing, words in speech should be Stemming、lemmatization and tokenization.
Tokenization means put”New York”in one word,separate “I`m” into “I” and “am”。
Using FSA to build Stemming net of words

3.2)FST : Finite state transducers.
I define it my way:
If you input “aa”,”b”will be output,and the state in still “q0”,if you input “b”,”a or b”will out put,state will be “q1”.For example,if you input “aa aa b a”，output is “b b a ba”.

Defination with details </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_4%20-%20N-Grams/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_4 - N-Grams</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">4 - N-GramsN-gram is a language model,is a N-token sequence of words.
1.the way to calculate conditional probability.For example,how can we calculate P(the|its water is so transparent that) ?
Method1): counting 2 sentences
Counting the times of “its water is so transparent that the” and “its water is so transparent that” in the whole corpus.It works sometime,but language is creative,many sentences is not exist.
 
Method2): chain rule of probability,then use method 1.

notice that:

means  P(w1w2</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_23%20-%20QA/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_23 - QA</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">23 - Question Answering and Summarization本章介绍基于事实的回答问题系统+文章的总结系统。如果我们查找的是结构化的数据，可用上一章介绍的信息提取算法来词查找。如果查找的是非结构化的信息，则需要用本章介绍的“回答问题系统”处理，非结构化信息的查找就是一种“使用非正式的单词或句子”来表达查找需求的场景，这种场景下客户通常期望能返回一些回答or一些文本，或something in between。
第一个session介绍向量空间模型，第二个session介绍基于事实的一问一答系统。第六个session介绍基于句子的总结系统/基于注意力机制的总结系统。
23.1 Information Retrieval 信息检索术语定义
文档document指的是一个有索引的，可被检索系统直接定位的最小单元，对应到web就是一个网页
集合collection指的是一系列用来满足用户需求的文档documents
term指的是一个词汇元素。
query指的是一系列terms

词向量空间
词义相近的在向量空间中距也近，概念在CS224N中学过了。空间和点积的直观图如下</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_24%20-%20%E5%AF%B9%E8%AF%9Dagent/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_24 - 对话agent</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">24 - Dialogue and Conversational Agents这一章介绍问答助手的基本结构+算法。Session24.1介绍人类对话的基本概念，如对话的交替，表达技巧，grounding，对话结构等。Session24.2介绍口语系统的组件和评价标准。Session24.5和Session24.6介绍信息状态架构和马尔科夫对话代理模型，以及高阶话题如BDI范式（belief - desire -intention）信念 - 渴望 - 意图范式。
24.1 人类对话的Properties24.1.1 Turns and turn-talking人类对话的模式是一个人说完了之后另一人说，交替进行，通常情况下，两人对话的重叠部分不超过5%。两个人交替间的停顿时间在100ms左右。为了实现这种模式，人类对话通常有如下三个规律来规范交替的进行，非常显而易见。

通常一个比正常情况更长的听读怒会有额外的表达效果，如下所示一个长停顿代表了不想积极回应问题。

24.1.2 Language as Action:Speech Acts 语言是会产生后果的行动语言能对现实世界产生具体影响</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_22%20-%20Information%20Extraction/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_22 - Information Extraction</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">22 - Information Extraction本章主要概念：

NER：命名实体识别
relation detection and classification：关系检测与分类
event detection and classification：事件检测与分类
temporal expression recognition：事件表达式识别
template filling：模板填充

22.1)NER : 命名实体识别命名实体识别分类的举例

22.1.2）NER as Sequence Labeling
标准的命名实体识别的步骤是使用word-by-word sequence labeling任务。其实进行NER的方法与第五章的POS tagging和十三章的syntactic chunking方法相同。
PS：提一下第五章的POS tagging：使用的还是HMM base 的 维特比算法（decoding）。

问题的本质如下所示，观察到句子/词语，猜测对应的词性/NER类型。也就是观察到结果，猜测其隐状态。


具体的 word-by-word IOB-style t</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_2%20-%20Regular%20expressions%20and%20automata/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_2 - Regular expressions and automata</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">2 - Regular expressions and automata2.2) Relationship between FSA and RE
Any regular expression(RE) can be implemented as a finite state automata(FSA),symmetrically,any finite-state automata can be described with a regular expression.
Both RE and FSA can be used to describe regular languages:

Using FSA to understand sheep talk
sheep language can be defined as any string from the following set:
baa!
baaaa!
baaaaa!
baaaaaa!
baaaaaaa!
baaaaaaaa!
baaaaaaaaa!
…
Sheep language can be described as fol</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_11%20-%20Computational%20Phonology/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_11 - Computational Phonology</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">11. Computational Phonology本章较艰涩，对NLP发文帮助不大，Skip，以后需用再补。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_12%20-%2016,17%20-%2021%E8%AF%AD%E6%B3%95%E5%AD%A6%EF%BC%8C%E8%AF%AD%E4%B9%89%E8%AF%AD%E7%94%A8%E5%AD%A6/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_12 - 16,17 - 21语法学，语义语用学</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">12 - 16语法学，17 - 21语义语用学以上几章主要侧重于对英语这门语言本身的讲解，对发表论文帮助不大。先跳过，回头需用再补。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_10%20-%20Automatic%20Speech%20RecongnitionAdvanced%20Topics/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_10 - Automatic Speech RecongnitionAdvanced Topics</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">10. Auto Speech Recognition Advanced Topic ：语音转文字进阶话题之前企图对输入的语音转换成音素的处理办法是：构建一个由全体语言组成的HMM状态网络，然后在网络中采用维特比算法进行全局搜索。这种算法太expensive了。
改进思路是采用多路编码的decoding技术，使用新的上下文相关声学模型(triphone)。本章还会介绍判别训练(discriminative training)和模型的一些变体；
10.1）多路编码decoding : N-Best List and Lattices
首先，维特比算法在进行对语音输入的decoding的时候，有如下两个问题：

在应对一词多音/一音多词的语言时，维特比算法表现很差
维特比算法很难take advantage of 复杂的语言模型：2-gram还行，3-gram就不行了。因为3-gram violates the dynamic programming invariant

改进如上两个问题的思路有：

改进维特比算法，将原本只返回单一值，变成返回多值。以改进一词多音的问题。
使用其他的的d</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/0.%E6%A6%82%E5%BF%B5/%E6%8A%80%E6%9C%AF_%E7%88%AC%E8%99%AB/">
        <p class="h4 index-header">0.概念/技术_爬虫</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">爬虫目的:掌握定向网络数据爬取和网页解析的基本能力
传达的理念:website is the API
基本内容介绍

request库  自动爬取HTML页面,自动网络请求提交
robots.txt  网络爬虫排除标准
Beautiful Soup解析HTML页面
实战项目
正则表达式
Scrapy专业爬虫框架

1.Request库
安装request:pip install requests
import requestsr = requests.get(“http://www.baidu.com&quot;)r.status_code
r.encoding = ‘utf-8’r.text

Request库的七个主要方法

requests.request()    构造请求,支撑如下方法的基础方法
requests.get()              获取HTML的主要方法,对应HTTP的GET
requests.head()          获取HTML的网页头信息
requests.post()            向HTML网页提交POST请求
requests.p</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/3.%E8%AF%BE%E7%A8%8B/SpeechAndLanguageProcessing_1%20-%20Introdution/">
        <p class="h4 index-header">3.课程/SpeechAndLanguageProcessing_1 - Introdution</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1.Introduction1.1) Required knowledge for NLP:

Phonetics and Phonology : knowledge about linguistic sounds
Morphology : knowledge of meaningful components of words
Syntax :knowledge of the structural relationships between words
Pragmatics :knowledge of the relationship of meaning to the goals and intentions of speaker(what is )
Semantics :knowledge of meaning(what is said)
Discourse : knowledge about linguistic units larger than a single utterance

1.2) Key task : Disambiguation at variety leve</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E8%AF%BE%E9%A2%98%E7%BB%84%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/">
        <p class="h4 index-header">1.科研/课题组信息搜集</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">NLP课题组信息搜集20191218作者：cstghitpku
链接：https://zhuanlan.zhihu.com/p/48529628
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
根据这几年的积累，整理了一份国内外学术界和工业界的牛人和大牛团队，供大家申请硕士、博士、博士后和找工作参考。
学校（排名不分先后）：
哈工大社会计算与信息检索实验室：刘挺老师坐镇，教师包括：秦兵、张宇、车万翔、赵妍妍、刘铭、张伟男、丁效等老师，实验室共7个组，另外王海峰老师也是实验室兼职博导。
哈工大智能技术与自然语言处理实验室：王晓龙老师坐镇，教师包括刘秉权、刘远超、孙承杰等老师
哈工大机器智能与翻译研究室：赵铁军老师坐镇，教师包括杨沐昀、郑德权、徐冰老师等，另外周明老师是实验室兼职博导。
哈工大深圳智能计算研究中心：王晓龙老师坐镇，包括陈清才、汤步洲、徐睿峰、刘滨等老师，实力很强。
哈工大深圳人类语言技术组：徐睿峰老师坐镇，情感原因发现做的比较好。
哈工大另外做NLP的老师包括：关毅、王轩等。
清华大学自然语言处理与社会人文计算实验室：孙茂松老师坐镇，包括刘</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/4.%E5%AE%89%E8%A3%85%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/%E4%BF%AE%E6%94%B9conda%E6%BA%90_%E4%B8%8B%E8%BD%BD%E9%97%AE%E9%A2%98/">
        <p class="h4 index-header">4.安装调试记录/修改conda源_下载问题</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">首次改为国内源：打开cmd
conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forgeconda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forg</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2020/02/24/1.%E7%A7%91%E7%A0%94/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%9B%86%5BDone%5D/">
        <p class="h4 index-header">1.科研/深度学习论文集[Done]</p>
        
        
          
        
        <div class="index-excerpt" >
          <div class="index-text mb-1">1 深度学习历史和基础1.0 书籍█[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. “Deep learning.” An MIT Press book. (2015). [pdf] (Ian Goodfellow 等大牛所著的教科书，乃深度学习圣经。你可以同时研习这本书以及以下论文) ★★★★★
地址：https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf
1.1 调查█[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. [pdf] (三巨头做的调查)  ★★★★★
地址：http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf
1.2 深度置信网络 (DBN，深度学习前夜的里程碑)█[2] Hinto</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2020-02-24&nbsp;&nbsp;
        
        
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/page/5/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/7/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js" ></script>
<script src="/lib/popper/popper.min.js" ></script>
<script src="/lib/bootstrap/js/bootstrap.min.js" ></script>
<script src="/lib/mdbootstrap/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  

  

  

  




  <script src="/lib/prettify/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "暗影疾行&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 120,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>







</body>
</html>
